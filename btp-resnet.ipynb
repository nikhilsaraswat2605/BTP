{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "006dd1bc",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-31T14:41:34.191638Z",
     "iopub.status.busy": "2024-03-31T14:41:34.190710Z",
     "iopub.status.idle": "2024-03-31T14:41:35.502687Z",
     "shell.execute_reply": "2024-03-31T14:41:35.501772Z"
    },
    "papermill": {
     "duration": 1.324567,
     "end_time": "2024-03-31T14:41:35.505263",
     "exception": false,
     "start_time": "2024-03-31T14:41:34.180696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f86e1238",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T14:41:35.522198Z",
     "iopub.status.busy": "2024-03-31T14:41:35.521339Z",
     "iopub.status.idle": "2024-03-31T14:41:47.268029Z",
     "shell.execute_reply": "2024-03-31T14:41:47.267111Z"
    },
    "papermill": {
     "duration": 11.757654,
     "end_time": "2024-03-31T14:41:47.270543",
     "exception": false,
     "start_time": "2024-03-31T14:41:35.512889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, absolute_import\n",
    "import os\n",
    "import argparse\n",
    "import shutil\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d8ece09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T14:41:47.289206Z",
     "iopub.status.busy": "2024-03-31T14:41:47.288322Z",
     "iopub.status.idle": "2024-03-31T14:41:47.363742Z",
     "shell.execute_reply": "2024-03-31T14:41:47.362659Z"
    },
    "papermill": {
     "duration": 0.087169,
     "end_time": "2024-03-31T14:41:47.365988",
     "exception": false,
     "start_time": "2024-03-31T14:41:47.278819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51a79fc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T14:41:47.382333Z",
     "iopub.status.busy": "2024-03-31T14:41:47.381508Z",
     "iopub.status.idle": "2024-03-31T14:41:52.553114Z",
     "shell.execute_reply": "2024-03-31T14:41:52.552198Z"
    },
    "papermill": {
     "duration": 5.182543,
     "end_time": "2024-03-31T14:41:52.555649",
     "exception": false,
     "start_time": "2024-03-31T14:41:47.373106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data.cifar10/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:01<00:00, 88024372.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data.cifar10/cifar-10-python.tar.gz to ./data.cifar10\n"
     ]
    }
   ],
   "source": [
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "\n",
    "dataset = 'cifar10'\n",
    "batch_size = 64\n",
    "test_batch_size = 256\n",
    "\n",
    "if dataset == 'cifar10':\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10('./data.cifar10', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.Pad(4),\n",
    "                           transforms.RandomCrop(32),\n",
    "                           transforms.RandomHorizontalFlip(),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "                       ])),\n",
    "        batch_size=batch_size, shuffle=True, **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10('./data.cifar10', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "                       ])),\n",
    "        batch_size=test_batch_size, shuffle=True, **kwargs)\n",
    "else:\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR100('./data.cifar100', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.Pad(4),\n",
    "                           transforms.RandomCrop(32),\n",
    "                           transforms.RandomHorizontalFlip(),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "                       ])),\n",
    "        batch_size=batch_size, shuffle=True, **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR100('./data.cifar100', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "                       ])),\n",
    "        batch_size=test_batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b879d70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T14:41:52.577570Z",
     "iopub.status.busy": "2024-03-31T14:41:52.577178Z",
     "iopub.status.idle": "2024-03-31T14:41:52.610489Z",
     "shell.execute_reply": "2024-03-31T14:41:52.609408Z"
    },
    "papermill": {
     "duration": 0.047297,
     "end_time": "2024-03-31T14:41:52.612885",
     "exception": false,
     "start_time": "2024-03-31T14:41:52.565588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class channel_selection(nn.Module):\n",
    "    \"\"\"\n",
    "    Select channels from the output of BatchNorm2d layer. It should be put directly after BatchNorm2d layer.\n",
    "    The output shape of this layer is determined by the number of 1 in `self.indexes`.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_channels):\n",
    "        \"\"\"\n",
    "        Initialize the `indexes` with all one vector with the length same as the number of channels.\n",
    "        During pruning, the places in `indexes` which correpond to the channels to be pruned will be set to 0.\n",
    "        \"\"\"\n",
    "        super(channel_selection, self).__init__()\n",
    "        self.indexes = nn.Parameter(torch.ones(num_channels))\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        \"\"\"\n",
    "        Parameter\n",
    "        ---------\n",
    "        input_tensor: (N,C,H,W). It should be the output of BatchNorm2d layer.\n",
    "        \"\"\"\n",
    "        selected_index = np.squeeze(np.argwhere(self.indexes.data.cpu().numpy()))\n",
    "        if selected_index.size == 1:\n",
    "            selected_index = np.resize(selected_index, (1,)) \n",
    "        output = input_tensor[:, selected_index, :, :]\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "__all__ = ['resnet']\n",
    "\n",
    "\"\"\"\n",
    "preactivation resnet with bottleneck design.\n",
    "\"\"\"\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, cfg, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
    "        self.select = channel_selection(inplanes)\n",
    "        self.conv1 = nn.Conv2d(cfg[0], cfg[1], kernel_size=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(cfg[1])\n",
    "        self.conv2 = nn.Conv2d(cfg[1], cfg[2], kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(cfg[2])\n",
    "        self.conv3 = nn.Conv2d(cfg[2], planes * 4, kernel_size=1, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.bn1(x)\n",
    "        out = self.select(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv1(out)\n",
    "\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        out = self.bn3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "\n",
    "        return out\n",
    "\n",
    "class resnet(nn.Module):\n",
    "    def __init__(self, depth=164, dataset='cifar10', cfg=None):\n",
    "        super(resnet, self).__init__()\n",
    "        assert (depth - 2) % 9 == 0, 'depth should be 9n+2'\n",
    "\n",
    "        n = (depth - 2) // 9\n",
    "        block = Bottleneck\n",
    "\n",
    "        if cfg is None:\n",
    "            # Construct config variable.\n",
    "            cfg = [[16, 16, 16], [64, 16, 16]*(n-1), [64, 32, 32], [128, 32, 32]*(n-1), [128, 64, 64], [256, 64, 64]*(n-1), [256]]\n",
    "            cfg = [item for sub_list in cfg for item in sub_list]\n",
    "\n",
    "        self.inplanes = 16\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1,\n",
    "                               bias=False)\n",
    "        self.layer1 = self._make_layer(block, 16, n, cfg = cfg[0:3*n])\n",
    "        self.layer2 = self._make_layer(block, 32, n, cfg = cfg[3*n:6*n], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, n, cfg = cfg[6*n:9*n], stride=2)\n",
    "        self.bn = nn.BatchNorm2d(64 * block.expansion)\n",
    "        self.select = channel_selection(64 * block.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.avgpool = nn.AvgPool2d(8)\n",
    "\n",
    "        if dataset == 'cifar10':\n",
    "            self.fc = nn.Linear(cfg[-1], 10)\n",
    "        elif dataset == 'cifar100':\n",
    "            self.fc = nn.Linear(cfg[-1], 100)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(0.5)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, cfg, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, cfg[0:3], stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, cfg[3*i: 3*(i+1)]))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x = self.layer1(x)  # 32x32\n",
    "        x = self.layer2(x)  # 16x16\n",
    "        x = self.layer3(x)  # 8x8\n",
    "        x = self.bn(x)\n",
    "        x = self.select(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "520e68c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T14:41:52.633985Z",
     "iopub.status.busy": "2024-03-31T14:41:52.633557Z",
     "iopub.status.idle": "2024-03-31T14:41:53.066552Z",
     "shell.execute_reply": "2024-03-31T14:41:53.065432Z"
    },
    "papermill": {
     "duration": 0.446667,
     "end_time": "2024-03-31T14:41:53.069246",
     "exception": false,
     "start_time": "2024-03-31T14:41:52.622579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "refine = ''\n",
    "depth = 164\n",
    "lr = 0.1\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "\n",
    "if refine:\n",
    "    checkpoint = torch.load(refine)\n",
    "    model = resnet(dataset=dataset, depth=depth, cfg=checkpoint['cfg'])\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "else:\n",
    "    model = resnet(dataset=dataset, depth=depth)\n",
    "    \n",
    "if cuda:\n",
    "    model.cuda()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "resume = ''\n",
    "start_epoch = 0\n",
    "\n",
    "if resume:\n",
    "    if os.path.isfile(resume):\n",
    "        print(\"=> loading checkpoint '{}'\".format(resume))\n",
    "        checkpoint = torch.load(resume)\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        best_prec1 = checkpoint['best_prec1']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {}) Prec1: {:f}\"\n",
    "              .format(resume, checkpoint['epoch'], best_prec1))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(resume))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c890385",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T14:41:53.091643Z",
     "iopub.status.busy": "2024-03-31T14:41:53.091222Z",
     "iopub.status.idle": "2024-03-31T14:41:53.107514Z",
     "shell.execute_reply": "2024-03-31T14:41:53.106393Z"
    },
    "papermill": {
     "duration": 0.030248,
     "end_time": "2024-03-31T14:41:53.109785",
     "exception": false,
     "start_time": "2024-03-31T14:41:53.079537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "s = 0.0001\n",
    "sr = ''\n",
    "log_interval = 100\n",
    "\n",
    "# additional subgradient descent on the sparsity-induced penalty term\n",
    "def updateBN():\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.BatchNorm2d):\n",
    "            m.weight.grad.data.add_(s*torch.sign(m.weight.data))  # L1\n",
    "            \n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        with torch.no_grad():\n",
    "            data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        loss.backward()\n",
    "        if sr:\n",
    "            updateBN()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.1f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        if cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        with torch.no_grad():\n",
    "            data, target = Variable(data), Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += F.cross_entropy(output, target, reduction='sum').item() # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return correct / float(len(test_loader.dataset))\n",
    "\n",
    "def save_checkpoint(state, is_best, filepath):\n",
    "    torch.save(state, os.path.join(filepath, 'checkpoint.pth.tar'))\n",
    "    if is_best:\n",
    "        shutil.copyfile(os.path.join(filepath, 'checkpoint.pth.tar'), os.path.join(filepath, 'model_best.pth.tar'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52115ece",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T14:41:53.132191Z",
     "iopub.status.busy": "2024-03-31T14:41:53.131296Z",
     "iopub.status.idle": "2024-03-31T15:28:40.486886Z",
     "shell.execute_reply": "2024-03-31T15:28:40.485668Z"
    },
    "papermill": {
     "duration": 2807.381928,
     "end_time": "2024-03-31T15:28:40.501286",
     "exception": false,
     "start_time": "2024-03-31T14:41:53.119358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/50000 (0.0%)]\tLoss: 2.316646\n",
      "Train Epoch: 0 [6400/50000 (12.8%)]\tLoss: 1.868889\n",
      "Train Epoch: 0 [12800/50000 (25.6%)]\tLoss: 1.745639\n",
      "Train Epoch: 0 [19200/50000 (38.4%)]\tLoss: 1.661745\n",
      "Train Epoch: 0 [25600/50000 (51.2%)]\tLoss: 1.391387\n",
      "Train Epoch: 0 [32000/50000 (63.9%)]\tLoss: 1.334859\n",
      "Train Epoch: 0 [38400/50000 (76.7%)]\tLoss: 1.497894\n",
      "Train Epoch: 0 [44800/50000 (89.5%)]\tLoss: 1.224237\n",
      "\n",
      "Test set: Average loss: 1.5385, Accuracy: 4726/10000 (47.3%)\n",
      "\n",
      "Train Epoch: 1 [0/50000 (0.0%)]\tLoss: 1.073227\n",
      "Train Epoch: 1 [6400/50000 (12.8%)]\tLoss: 1.120586\n",
      "Train Epoch: 1 [12800/50000 (25.6%)]\tLoss: 1.110890\n",
      "Train Epoch: 1 [19200/50000 (38.4%)]\tLoss: 1.128029\n",
      "Train Epoch: 1 [25600/50000 (51.2%)]\tLoss: 0.998251\n",
      "Train Epoch: 1 [32000/50000 (63.9%)]\tLoss: 0.870343\n",
      "Train Epoch: 1 [38400/50000 (76.7%)]\tLoss: 0.916881\n",
      "Train Epoch: 1 [44800/50000 (89.5%)]\tLoss: 1.072088\n",
      "\n",
      "Test set: Average loss: 1.1484, Accuracy: 5797/10000 (58.0%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0.0%)]\tLoss: 0.943887\n",
      "Train Epoch: 2 [6400/50000 (12.8%)]\tLoss: 1.053368\n",
      "Train Epoch: 2 [12800/50000 (25.6%)]\tLoss: 0.877913\n",
      "Train Epoch: 2 [19200/50000 (38.4%)]\tLoss: 1.109784\n",
      "Train Epoch: 2 [25600/50000 (51.2%)]\tLoss: 1.098185\n",
      "Train Epoch: 2 [32000/50000 (63.9%)]\tLoss: 0.925456\n",
      "Train Epoch: 2 [38400/50000 (76.7%)]\tLoss: 0.869435\n",
      "Train Epoch: 2 [44800/50000 (89.5%)]\tLoss: 0.794576\n",
      "\n",
      "Test set: Average loss: 1.0945, Accuracy: 6212/10000 (62.1%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0.0%)]\tLoss: 0.792377\n",
      "Train Epoch: 3 [6400/50000 (12.8%)]\tLoss: 0.927902\n",
      "Train Epoch: 3 [12800/50000 (25.6%)]\tLoss: 0.798190\n",
      "Train Epoch: 3 [19200/50000 (38.4%)]\tLoss: 0.819988\n",
      "Train Epoch: 3 [25600/50000 (51.2%)]\tLoss: 0.984953\n",
      "Train Epoch: 3 [32000/50000 (63.9%)]\tLoss: 0.856209\n",
      "Train Epoch: 3 [38400/50000 (76.7%)]\tLoss: 0.905154\n",
      "Train Epoch: 3 [44800/50000 (89.5%)]\tLoss: 0.594109\n",
      "\n",
      "Test set: Average loss: 1.0256, Accuracy: 6605/10000 (66.1%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0.0%)]\tLoss: 0.833224\n",
      "Train Epoch: 4 [6400/50000 (12.8%)]\tLoss: 0.686666\n",
      "Train Epoch: 4 [12800/50000 (25.6%)]\tLoss: 0.878129\n",
      "Train Epoch: 4 [19200/50000 (38.4%)]\tLoss: 0.784270\n",
      "Train Epoch: 4 [25600/50000 (51.2%)]\tLoss: 0.656217\n",
      "Train Epoch: 4 [32000/50000 (63.9%)]\tLoss: 0.504444\n",
      "Train Epoch: 4 [38400/50000 (76.7%)]\tLoss: 0.748117\n",
      "Train Epoch: 4 [44800/50000 (89.5%)]\tLoss: 1.105577\n",
      "\n",
      "Test set: Average loss: 0.9461, Accuracy: 6780/10000 (67.8%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0.0%)]\tLoss: 0.957755\n",
      "Train Epoch: 5 [6400/50000 (12.8%)]\tLoss: 0.897368\n",
      "Train Epoch: 5 [12800/50000 (25.6%)]\tLoss: 0.532358\n",
      "Train Epoch: 5 [19200/50000 (38.4%)]\tLoss: 0.729106\n",
      "Train Epoch: 5 [25600/50000 (51.2%)]\tLoss: 0.581832\n",
      "Train Epoch: 5 [32000/50000 (63.9%)]\tLoss: 0.444061\n",
      "Train Epoch: 5 [38400/50000 (76.7%)]\tLoss: 0.464255\n",
      "Train Epoch: 5 [44800/50000 (89.5%)]\tLoss: 0.781794\n",
      "\n",
      "Test set: Average loss: 0.8119, Accuracy: 7336/10000 (73.4%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0.0%)]\tLoss: 0.682825\n",
      "Train Epoch: 6 [6400/50000 (12.8%)]\tLoss: 0.515521\n",
      "Train Epoch: 6 [12800/50000 (25.6%)]\tLoss: 0.677265\n",
      "Train Epoch: 6 [19200/50000 (38.4%)]\tLoss: 0.476007\n",
      "Train Epoch: 6 [25600/50000 (51.2%)]\tLoss: 0.667011\n",
      "Train Epoch: 6 [32000/50000 (63.9%)]\tLoss: 0.458447\n",
      "Train Epoch: 6 [38400/50000 (76.7%)]\tLoss: 0.766477\n",
      "Train Epoch: 6 [44800/50000 (89.5%)]\tLoss: 0.589989\n",
      "\n",
      "Test set: Average loss: 0.7861, Accuracy: 7296/10000 (73.0%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0.0%)]\tLoss: 0.465845\n",
      "Train Epoch: 7 [6400/50000 (12.8%)]\tLoss: 0.574731\n",
      "Train Epoch: 7 [12800/50000 (25.6%)]\tLoss: 0.613613\n",
      "Train Epoch: 7 [19200/50000 (38.4%)]\tLoss: 0.625393\n",
      "Train Epoch: 7 [25600/50000 (51.2%)]\tLoss: 0.619495\n",
      "Train Epoch: 7 [32000/50000 (63.9%)]\tLoss: 0.347898\n",
      "Train Epoch: 7 [38400/50000 (76.7%)]\tLoss: 0.671488\n",
      "Train Epoch: 7 [44800/50000 (89.5%)]\tLoss: 0.480444\n",
      "\n",
      "Test set: Average loss: 0.7159, Accuracy: 7685/10000 (76.8%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0.0%)]\tLoss: 0.759788\n",
      "Train Epoch: 8 [6400/50000 (12.8%)]\tLoss: 0.551691\n",
      "Train Epoch: 8 [12800/50000 (25.6%)]\tLoss: 0.675240\n",
      "Train Epoch: 8 [19200/50000 (38.4%)]\tLoss: 0.506415\n",
      "Train Epoch: 8 [25600/50000 (51.2%)]\tLoss: 0.789735\n",
      "Train Epoch: 8 [32000/50000 (63.9%)]\tLoss: 0.726081\n",
      "Train Epoch: 8 [38400/50000 (76.7%)]\tLoss: 0.561402\n",
      "Train Epoch: 8 [44800/50000 (89.5%)]\tLoss: 0.490630\n",
      "\n",
      "Test set: Average loss: 0.6649, Accuracy: 7769/10000 (77.7%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0.0%)]\tLoss: 0.604256\n",
      "Train Epoch: 9 [6400/50000 (12.8%)]\tLoss: 0.307775\n",
      "Train Epoch: 9 [12800/50000 (25.6%)]\tLoss: 0.560632\n",
      "Train Epoch: 9 [19200/50000 (38.4%)]\tLoss: 0.515054\n",
      "Train Epoch: 9 [25600/50000 (51.2%)]\tLoss: 0.474322\n",
      "Train Epoch: 9 [32000/50000 (63.9%)]\tLoss: 0.610065\n",
      "Train Epoch: 9 [38400/50000 (76.7%)]\tLoss: 0.421639\n",
      "Train Epoch: 9 [44800/50000 (89.5%)]\tLoss: 0.540135\n",
      "\n",
      "Test set: Average loss: 0.6794, Accuracy: 7681/10000 (76.8%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0.0%)]\tLoss: 0.357127\n",
      "Train Epoch: 10 [6400/50000 (12.8%)]\tLoss: 0.450064\n",
      "Train Epoch: 10 [12800/50000 (25.6%)]\tLoss: 0.330080\n",
      "Train Epoch: 10 [19200/50000 (38.4%)]\tLoss: 0.487835\n",
      "Train Epoch: 10 [25600/50000 (51.2%)]\tLoss: 0.244431\n",
      "Train Epoch: 10 [32000/50000 (63.9%)]\tLoss: 0.192115\n",
      "Train Epoch: 10 [38400/50000 (76.7%)]\tLoss: 0.166779\n",
      "Train Epoch: 10 [44800/50000 (89.5%)]\tLoss: 0.488869\n",
      "\n",
      "Test set: Average loss: 0.3632, Accuracy: 8765/10000 (87.7%)\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0.0%)]\tLoss: 0.458216\n",
      "Train Epoch: 11 [6400/50000 (12.8%)]\tLoss: 0.403655\n",
      "Train Epoch: 11 [12800/50000 (25.6%)]\tLoss: 0.257607\n",
      "Train Epoch: 11 [19200/50000 (38.4%)]\tLoss: 0.287172\n",
      "Train Epoch: 11 [25600/50000 (51.2%)]\tLoss: 0.267901\n",
      "Train Epoch: 11 [32000/50000 (63.9%)]\tLoss: 0.244379\n",
      "Train Epoch: 11 [38400/50000 (76.7%)]\tLoss: 0.372081\n",
      "Train Epoch: 11 [44800/50000 (89.5%)]\tLoss: 0.235081\n",
      "\n",
      "Test set: Average loss: 0.3482, Accuracy: 8824/10000 (88.2%)\n",
      "\n",
      "Train Epoch: 12 [0/50000 (0.0%)]\tLoss: 0.180920\n",
      "Train Epoch: 12 [6400/50000 (12.8%)]\tLoss: 0.246382\n",
      "Train Epoch: 12 [12800/50000 (25.6%)]\tLoss: 0.142397\n",
      "Train Epoch: 12 [19200/50000 (38.4%)]\tLoss: 0.305184\n",
      "Train Epoch: 12 [25600/50000 (51.2%)]\tLoss: 0.387934\n",
      "Train Epoch: 12 [32000/50000 (63.9%)]\tLoss: 0.270990\n",
      "Train Epoch: 12 [38400/50000 (76.7%)]\tLoss: 0.373098\n",
      "Train Epoch: 12 [44800/50000 (89.5%)]\tLoss: 0.364964\n",
      "\n",
      "Test set: Average loss: 0.3554, Accuracy: 8818/10000 (88.2%)\n",
      "\n",
      "Train Epoch: 13 [0/50000 (0.0%)]\tLoss: 0.138826\n",
      "Train Epoch: 13 [6400/50000 (12.8%)]\tLoss: 0.412120\n",
      "Train Epoch: 13 [12800/50000 (25.6%)]\tLoss: 0.380684\n",
      "Train Epoch: 13 [19200/50000 (38.4%)]\tLoss: 0.270372\n",
      "Train Epoch: 13 [25600/50000 (51.2%)]\tLoss: 0.395759\n",
      "Train Epoch: 13 [32000/50000 (63.9%)]\tLoss: 0.453453\n",
      "Train Epoch: 13 [38400/50000 (76.7%)]\tLoss: 0.212828\n",
      "Train Epoch: 13 [44800/50000 (89.5%)]\tLoss: 0.193172\n",
      "\n",
      "Test set: Average loss: 0.3332, Accuracy: 8875/10000 (88.8%)\n",
      "\n",
      "Train Epoch: 14 [0/50000 (0.0%)]\tLoss: 0.272042\n",
      "Train Epoch: 14 [6400/50000 (12.8%)]\tLoss: 0.259424\n",
      "Train Epoch: 14 [12800/50000 (25.6%)]\tLoss: 0.215975\n",
      "Train Epoch: 14 [19200/50000 (38.4%)]\tLoss: 0.168054\n",
      "Train Epoch: 14 [25600/50000 (51.2%)]\tLoss: 0.253131\n",
      "Train Epoch: 14 [32000/50000 (63.9%)]\tLoss: 0.340064\n",
      "Train Epoch: 14 [38400/50000 (76.7%)]\tLoss: 0.231513\n",
      "Train Epoch: 14 [44800/50000 (89.5%)]\tLoss: 0.293634\n",
      "\n",
      "Test set: Average loss: 0.3192, Accuracy: 8914/10000 (89.1%)\n",
      "\n",
      "Train Epoch: 15 [0/50000 (0.0%)]\tLoss: 0.241748\n",
      "Train Epoch: 15 [6400/50000 (12.8%)]\tLoss: 0.330003\n",
      "Train Epoch: 15 [12800/50000 (25.6%)]\tLoss: 0.187272\n",
      "Train Epoch: 15 [19200/50000 (38.4%)]\tLoss: 0.240623\n",
      "Train Epoch: 15 [25600/50000 (51.2%)]\tLoss: 0.180690\n",
      "Train Epoch: 15 [32000/50000 (63.9%)]\tLoss: 0.302372\n",
      "Train Epoch: 15 [38400/50000 (76.7%)]\tLoss: 0.160310\n",
      "Train Epoch: 15 [44800/50000 (89.5%)]\tLoss: 0.126757\n",
      "\n",
      "Test set: Average loss: 0.3063, Accuracy: 8974/10000 (89.7%)\n",
      "\n",
      "Train Epoch: 16 [0/50000 (0.0%)]\tLoss: 0.287457\n",
      "Train Epoch: 16 [6400/50000 (12.8%)]\tLoss: 0.172348\n",
      "Train Epoch: 16 [12800/50000 (25.6%)]\tLoss: 0.421598\n",
      "Train Epoch: 16 [19200/50000 (38.4%)]\tLoss: 0.288722\n",
      "Train Epoch: 16 [25600/50000 (51.2%)]\tLoss: 0.249532\n",
      "Train Epoch: 16 [32000/50000 (63.9%)]\tLoss: 0.374524\n",
      "Train Epoch: 16 [38400/50000 (76.7%)]\tLoss: 0.202379\n",
      "Train Epoch: 16 [44800/50000 (89.5%)]\tLoss: 0.189989\n",
      "\n",
      "Test set: Average loss: 0.3080, Accuracy: 8954/10000 (89.5%)\n",
      "\n",
      "Train Epoch: 17 [0/50000 (0.0%)]\tLoss: 0.161986\n",
      "Train Epoch: 17 [6400/50000 (12.8%)]\tLoss: 0.234588\n",
      "Train Epoch: 17 [12800/50000 (25.6%)]\tLoss: 0.161203\n",
      "Train Epoch: 17 [19200/50000 (38.4%)]\tLoss: 0.252400\n",
      "Train Epoch: 17 [25600/50000 (51.2%)]\tLoss: 0.326310\n",
      "Train Epoch: 17 [32000/50000 (63.9%)]\tLoss: 0.260791\n",
      "Train Epoch: 17 [38400/50000 (76.7%)]\tLoss: 0.200774\n",
      "Train Epoch: 17 [44800/50000 (89.5%)]\tLoss: 0.215072\n",
      "\n",
      "Test set: Average loss: 0.3042, Accuracy: 8983/10000 (89.8%)\n",
      "\n",
      "Train Epoch: 18 [0/50000 (0.0%)]\tLoss: 0.317367\n",
      "Train Epoch: 18 [6400/50000 (12.8%)]\tLoss: 0.193642\n",
      "Train Epoch: 18 [12800/50000 (25.6%)]\tLoss: 0.178072\n",
      "Train Epoch: 18 [19200/50000 (38.4%)]\tLoss: 0.161876\n",
      "Train Epoch: 18 [25600/50000 (51.2%)]\tLoss: 0.111253\n",
      "Train Epoch: 18 [32000/50000 (63.9%)]\tLoss: 0.147674\n",
      "Train Epoch: 18 [38400/50000 (76.7%)]\tLoss: 0.127135\n",
      "Train Epoch: 18 [44800/50000 (89.5%)]\tLoss: 0.110209\n",
      "\n",
      "Test set: Average loss: 0.3071, Accuracy: 8973/10000 (89.7%)\n",
      "\n",
      "Train Epoch: 19 [0/50000 (0.0%)]\tLoss: 0.200557\n",
      "Train Epoch: 19 [6400/50000 (12.8%)]\tLoss: 0.141353\n",
      "Train Epoch: 19 [12800/50000 (25.6%)]\tLoss: 0.246307\n",
      "Train Epoch: 19 [19200/50000 (38.4%)]\tLoss: 0.228621\n",
      "Train Epoch: 19 [25600/50000 (51.2%)]\tLoss: 0.238476\n",
      "Train Epoch: 19 [32000/50000 (63.9%)]\tLoss: 0.199473\n",
      "Train Epoch: 19 [38400/50000 (76.7%)]\tLoss: 0.200960\n",
      "Train Epoch: 19 [44800/50000 (89.5%)]\tLoss: 0.161794\n",
      "\n",
      "Test set: Average loss: 0.3059, Accuracy: 8972/10000 (89.7%)\n",
      "\n",
      "Best accuracy: tensor(0.8983)\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "save = ''\n",
    "\n",
    "best_prec1 = 0.\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    if epoch in [epochs*0.5, epochs*0.75]:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] *= 0.1\n",
    "    train(epoch)\n",
    "    prec1 = test()\n",
    "    is_best = prec1 > best_prec1\n",
    "    best_prec1 = max(prec1, best_prec1)\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_prec1': best_prec1,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, filepath=save)\n",
    "\n",
    "print(\"Best accuracy: \"+str(best_prec1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e3ec07",
   "metadata": {
    "papermill": {
     "duration": 0.024944,
     "end_time": "2024-03-31T15:28:40.551931",
     "exception": false,
     "start_time": "2024-03-31T15:28:40.526987",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Train with Sparsity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0741434b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T15:28:40.600100Z",
     "iopub.status.busy": "2024-03-31T15:28:40.599287Z",
     "iopub.status.idle": "2024-03-31T16:15:48.371180Z",
     "shell.execute_reply": "2024-03-31T16:15:48.369859Z"
    },
    "papermill": {
     "duration": 2827.838066,
     "end_time": "2024-03-31T16:15:48.412785",
     "exception": false,
     "start_time": "2024-03-31T15:28:40.574719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/50000 (0.0%)]\tLoss: 2.276196\n",
      "Train Epoch: 0 [6400/50000 (12.8%)]\tLoss: 1.801003\n",
      "Train Epoch: 0 [12800/50000 (25.6%)]\tLoss: 1.618730\n",
      "Train Epoch: 0 [19200/50000 (38.4%)]\tLoss: 1.718458\n",
      "Train Epoch: 0 [25600/50000 (51.2%)]\tLoss: 1.463857\n",
      "Train Epoch: 0 [32000/50000 (63.9%)]\tLoss: 1.289848\n",
      "Train Epoch: 0 [38400/50000 (76.7%)]\tLoss: 1.551985\n",
      "Train Epoch: 0 [44800/50000 (89.5%)]\tLoss: 1.416613\n",
      "\n",
      "Test set: Average loss: 1.6068, Accuracy: 4556/10000 (45.6%)\n",
      "\n",
      "Train Epoch: 1 [0/50000 (0.0%)]\tLoss: 1.228281\n",
      "Train Epoch: 1 [6400/50000 (12.8%)]\tLoss: 1.529305\n",
      "Train Epoch: 1 [12800/50000 (25.6%)]\tLoss: 1.139593\n",
      "Train Epoch: 1 [19200/50000 (38.4%)]\tLoss: 1.189836\n",
      "Train Epoch: 1 [25600/50000 (51.2%)]\tLoss: 1.343126\n",
      "Train Epoch: 1 [32000/50000 (63.9%)]\tLoss: 1.190499\n",
      "Train Epoch: 1 [38400/50000 (76.7%)]\tLoss: 1.191807\n",
      "Train Epoch: 1 [44800/50000 (89.5%)]\tLoss: 0.971528\n",
      "\n",
      "Test set: Average loss: 1.5823, Accuracy: 4974/10000 (49.7%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0.0%)]\tLoss: 0.867133\n",
      "Train Epoch: 2 [6400/50000 (12.8%)]\tLoss: 0.862610\n",
      "Train Epoch: 2 [12800/50000 (25.6%)]\tLoss: 1.138585\n",
      "Train Epoch: 2 [19200/50000 (38.4%)]\tLoss: 0.839336\n",
      "Train Epoch: 2 [25600/50000 (51.2%)]\tLoss: 1.083512\n",
      "Train Epoch: 2 [32000/50000 (63.9%)]\tLoss: 0.869510\n",
      "Train Epoch: 2 [38400/50000 (76.7%)]\tLoss: 0.917374\n",
      "Train Epoch: 2 [44800/50000 (89.5%)]\tLoss: 0.954741\n",
      "\n",
      "Test set: Average loss: 0.9898, Accuracy: 6447/10000 (64.5%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0.0%)]\tLoss: 1.068356\n",
      "Train Epoch: 3 [6400/50000 (12.8%)]\tLoss: 0.740142\n",
      "Train Epoch: 3 [12800/50000 (25.6%)]\tLoss: 0.949268\n",
      "Train Epoch: 3 [19200/50000 (38.4%)]\tLoss: 0.913966\n",
      "Train Epoch: 3 [25600/50000 (51.2%)]\tLoss: 0.994102\n",
      "Train Epoch: 3 [32000/50000 (63.9%)]\tLoss: 0.916554\n",
      "Train Epoch: 3 [38400/50000 (76.7%)]\tLoss: 0.658807\n",
      "Train Epoch: 3 [44800/50000 (89.5%)]\tLoss: 0.889923\n",
      "\n",
      "Test set: Average loss: 1.0414, Accuracy: 6531/10000 (65.3%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0.0%)]\tLoss: 0.715949\n",
      "Train Epoch: 4 [6400/50000 (12.8%)]\tLoss: 0.780040\n",
      "Train Epoch: 4 [12800/50000 (25.6%)]\tLoss: 0.738158\n",
      "Train Epoch: 4 [19200/50000 (38.4%)]\tLoss: 0.863637\n",
      "Train Epoch: 4 [25600/50000 (51.2%)]\tLoss: 0.651096\n",
      "Train Epoch: 4 [32000/50000 (63.9%)]\tLoss: 0.681700\n",
      "Train Epoch: 4 [38400/50000 (76.7%)]\tLoss: 0.750748\n",
      "Train Epoch: 4 [44800/50000 (89.5%)]\tLoss: 0.818315\n",
      "\n",
      "Test set: Average loss: 0.8902, Accuracy: 6956/10000 (69.6%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0.0%)]\tLoss: 0.696449\n",
      "Train Epoch: 5 [6400/50000 (12.8%)]\tLoss: 0.682440\n",
      "Train Epoch: 5 [12800/50000 (25.6%)]\tLoss: 0.916408\n",
      "Train Epoch: 5 [19200/50000 (38.4%)]\tLoss: 0.590531\n",
      "Train Epoch: 5 [25600/50000 (51.2%)]\tLoss: 0.768555\n",
      "Train Epoch: 5 [32000/50000 (63.9%)]\tLoss: 0.700579\n",
      "Train Epoch: 5 [38400/50000 (76.7%)]\tLoss: 0.595676\n",
      "Train Epoch: 5 [44800/50000 (89.5%)]\tLoss: 0.633668\n",
      "\n",
      "Test set: Average loss: 0.8333, Accuracy: 7208/10000 (72.1%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0.0%)]\tLoss: 0.682683\n",
      "Train Epoch: 6 [6400/50000 (12.8%)]\tLoss: 0.740687\n",
      "Train Epoch: 6 [12800/50000 (25.6%)]\tLoss: 0.572684\n",
      "Train Epoch: 6 [19200/50000 (38.4%)]\tLoss: 0.687581\n",
      "Train Epoch: 6 [25600/50000 (51.2%)]\tLoss: 0.581388\n",
      "Train Epoch: 6 [32000/50000 (63.9%)]\tLoss: 0.764716\n",
      "Train Epoch: 6 [38400/50000 (76.7%)]\tLoss: 0.725984\n",
      "Train Epoch: 6 [44800/50000 (89.5%)]\tLoss: 0.447983\n",
      "\n",
      "Test set: Average loss: 0.7243, Accuracy: 7603/10000 (76.0%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0.0%)]\tLoss: 0.590698\n",
      "Train Epoch: 7 [6400/50000 (12.8%)]\tLoss: 0.565733\n",
      "Train Epoch: 7 [12800/50000 (25.6%)]\tLoss: 0.612158\n",
      "Train Epoch: 7 [19200/50000 (38.4%)]\tLoss: 0.553103\n",
      "Train Epoch: 7 [25600/50000 (51.2%)]\tLoss: 0.558635\n",
      "Train Epoch: 7 [32000/50000 (63.9%)]\tLoss: 0.640572\n",
      "Train Epoch: 7 [38400/50000 (76.7%)]\tLoss: 0.731567\n",
      "Train Epoch: 7 [44800/50000 (89.5%)]\tLoss: 0.593186\n",
      "\n",
      "Test set: Average loss: 0.7884, Accuracy: 7422/10000 (74.2%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0.0%)]\tLoss: 0.414031\n",
      "Train Epoch: 8 [6400/50000 (12.8%)]\tLoss: 0.495642\n",
      "Train Epoch: 8 [12800/50000 (25.6%)]\tLoss: 0.791884\n",
      "Train Epoch: 8 [19200/50000 (38.4%)]\tLoss: 0.680897\n",
      "Train Epoch: 8 [25600/50000 (51.2%)]\tLoss: 0.503990\n",
      "Train Epoch: 8 [32000/50000 (63.9%)]\tLoss: 0.667048\n",
      "Train Epoch: 8 [38400/50000 (76.7%)]\tLoss: 0.551671\n",
      "Train Epoch: 8 [44800/50000 (89.5%)]\tLoss: 0.636573\n",
      "\n",
      "Test set: Average loss: 0.7643, Accuracy: 7487/10000 (74.9%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0.0%)]\tLoss: 0.340659\n",
      "Train Epoch: 9 [6400/50000 (12.8%)]\tLoss: 0.830834\n",
      "Train Epoch: 9 [12800/50000 (25.6%)]\tLoss: 0.666030\n",
      "Train Epoch: 9 [19200/50000 (38.4%)]\tLoss: 0.533348\n",
      "Train Epoch: 9 [25600/50000 (51.2%)]\tLoss: 0.382985\n",
      "Train Epoch: 9 [32000/50000 (63.9%)]\tLoss: 0.683837\n",
      "Train Epoch: 9 [38400/50000 (76.7%)]\tLoss: 0.606876\n",
      "Train Epoch: 9 [44800/50000 (89.5%)]\tLoss: 0.573323\n",
      "\n",
      "Test set: Average loss: 0.6504, Accuracy: 7816/10000 (78.2%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0.0%)]\tLoss: 0.446715\n",
      "Train Epoch: 10 [6400/50000 (12.8%)]\tLoss: 0.422388\n",
      "Train Epoch: 10 [12800/50000 (25.6%)]\tLoss: 0.515297\n",
      "Train Epoch: 10 [19200/50000 (38.4%)]\tLoss: 0.241382\n",
      "Train Epoch: 10 [25600/50000 (51.2%)]\tLoss: 0.418772\n",
      "Train Epoch: 10 [32000/50000 (63.9%)]\tLoss: 0.409545\n",
      "Train Epoch: 10 [38400/50000 (76.7%)]\tLoss: 0.425079\n",
      "Train Epoch: 10 [44800/50000 (89.5%)]\tLoss: 0.244268\n",
      "\n",
      "Test set: Average loss: 0.3698, Accuracy: 8720/10000 (87.2%)\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0.0%)]\tLoss: 0.399497\n",
      "Train Epoch: 11 [6400/50000 (12.8%)]\tLoss: 0.240203\n",
      "Train Epoch: 11 [12800/50000 (25.6%)]\tLoss: 0.377886\n",
      "Train Epoch: 11 [19200/50000 (38.4%)]\tLoss: 0.385656\n",
      "Train Epoch: 11 [25600/50000 (51.2%)]\tLoss: 0.350408\n",
      "Train Epoch: 11 [32000/50000 (63.9%)]\tLoss: 0.333423\n",
      "Train Epoch: 11 [38400/50000 (76.7%)]\tLoss: 0.483632\n",
      "Train Epoch: 11 [44800/50000 (89.5%)]\tLoss: 0.293639\n",
      "\n",
      "Test set: Average loss: 0.3578, Accuracy: 8784/10000 (87.8%)\n",
      "\n",
      "Train Epoch: 12 [0/50000 (0.0%)]\tLoss: 0.374660\n",
      "Train Epoch: 12 [6400/50000 (12.8%)]\tLoss: 0.342851\n",
      "Train Epoch: 12 [12800/50000 (25.6%)]\tLoss: 0.219466\n",
      "Train Epoch: 12 [19200/50000 (38.4%)]\tLoss: 0.258110\n",
      "Train Epoch: 12 [25600/50000 (51.2%)]\tLoss: 0.221135\n",
      "Train Epoch: 12 [32000/50000 (63.9%)]\tLoss: 0.317115\n",
      "Train Epoch: 12 [38400/50000 (76.7%)]\tLoss: 0.306839\n",
      "Train Epoch: 12 [44800/50000 (89.5%)]\tLoss: 0.445639\n",
      "\n",
      "Test set: Average loss: 0.3463, Accuracy: 8820/10000 (88.2%)\n",
      "\n",
      "Train Epoch: 13 [0/50000 (0.0%)]\tLoss: 0.465282\n",
      "Train Epoch: 13 [6400/50000 (12.8%)]\tLoss: 0.148492\n",
      "Train Epoch: 13 [12800/50000 (25.6%)]\tLoss: 0.221022\n",
      "Train Epoch: 13 [19200/50000 (38.4%)]\tLoss: 0.319354\n",
      "Train Epoch: 13 [25600/50000 (51.2%)]\tLoss: 0.314129\n",
      "Train Epoch: 13 [32000/50000 (63.9%)]\tLoss: 0.270375\n",
      "Train Epoch: 13 [38400/50000 (76.7%)]\tLoss: 0.462946\n",
      "Train Epoch: 13 [44800/50000 (89.5%)]\tLoss: 0.252590\n",
      "\n",
      "Test set: Average loss: 0.3391, Accuracy: 8860/10000 (88.6%)\n",
      "\n",
      "Train Epoch: 14 [0/50000 (0.0%)]\tLoss: 0.310661\n",
      "Train Epoch: 14 [6400/50000 (12.8%)]\tLoss: 0.313043\n",
      "Train Epoch: 14 [12800/50000 (25.6%)]\tLoss: 0.316558\n",
      "Train Epoch: 14 [19200/50000 (38.4%)]\tLoss: 0.398910\n",
      "Train Epoch: 14 [25600/50000 (51.2%)]\tLoss: 0.299897\n",
      "Train Epoch: 14 [32000/50000 (63.9%)]\tLoss: 0.373782\n",
      "Train Epoch: 14 [38400/50000 (76.7%)]\tLoss: 0.316624\n",
      "Train Epoch: 14 [44800/50000 (89.5%)]\tLoss: 0.281715\n",
      "\n",
      "Test set: Average loss: 0.3382, Accuracy: 8847/10000 (88.5%)\n",
      "\n",
      "Train Epoch: 15 [0/50000 (0.0%)]\tLoss: 0.181417\n",
      "Train Epoch: 15 [6400/50000 (12.8%)]\tLoss: 0.343793\n",
      "Train Epoch: 15 [12800/50000 (25.6%)]\tLoss: 0.250240\n",
      "Train Epoch: 15 [19200/50000 (38.4%)]\tLoss: 0.317820\n",
      "Train Epoch: 15 [25600/50000 (51.2%)]\tLoss: 0.272126\n",
      "Train Epoch: 15 [32000/50000 (63.9%)]\tLoss: 0.371417\n",
      "Train Epoch: 15 [38400/50000 (76.7%)]\tLoss: 0.204431\n",
      "Train Epoch: 15 [44800/50000 (89.5%)]\tLoss: 0.206538\n",
      "\n",
      "Test set: Average loss: 0.3176, Accuracy: 8926/10000 (89.3%)\n",
      "\n",
      "Train Epoch: 16 [0/50000 (0.0%)]\tLoss: 0.231570\n",
      "Train Epoch: 16 [6400/50000 (12.8%)]\tLoss: 0.227185\n",
      "Train Epoch: 16 [12800/50000 (25.6%)]\tLoss: 0.314161\n",
      "Train Epoch: 16 [19200/50000 (38.4%)]\tLoss: 0.226312\n",
      "Train Epoch: 16 [25600/50000 (51.2%)]\tLoss: 0.192614\n",
      "Train Epoch: 16 [32000/50000 (63.9%)]\tLoss: 0.392489\n",
      "Train Epoch: 16 [38400/50000 (76.7%)]\tLoss: 0.276123\n",
      "Train Epoch: 16 [44800/50000 (89.5%)]\tLoss: 0.218937\n",
      "\n",
      "Test set: Average loss: 0.3161, Accuracy: 8910/10000 (89.1%)\n",
      "\n",
      "Train Epoch: 17 [0/50000 (0.0%)]\tLoss: 0.323780\n",
      "Train Epoch: 17 [6400/50000 (12.8%)]\tLoss: 0.438465\n",
      "Train Epoch: 17 [12800/50000 (25.6%)]\tLoss: 0.166205\n",
      "Train Epoch: 17 [19200/50000 (38.4%)]\tLoss: 0.244850\n",
      "Train Epoch: 17 [25600/50000 (51.2%)]\tLoss: 0.104417\n",
      "Train Epoch: 17 [32000/50000 (63.9%)]\tLoss: 0.269921\n",
      "Train Epoch: 17 [38400/50000 (76.7%)]\tLoss: 0.204800\n",
      "Train Epoch: 17 [44800/50000 (89.5%)]\tLoss: 0.190432\n",
      "\n",
      "Test set: Average loss: 0.3139, Accuracy: 8925/10000 (89.2%)\n",
      "\n",
      "Train Epoch: 18 [0/50000 (0.0%)]\tLoss: 0.338311\n",
      "Train Epoch: 18 [6400/50000 (12.8%)]\tLoss: 0.239965\n",
      "Train Epoch: 18 [12800/50000 (25.6%)]\tLoss: 0.300156\n",
      "Train Epoch: 18 [19200/50000 (38.4%)]\tLoss: 0.227251\n",
      "Train Epoch: 18 [25600/50000 (51.2%)]\tLoss: 0.173512\n",
      "Train Epoch: 18 [32000/50000 (63.9%)]\tLoss: 0.192625\n",
      "Train Epoch: 18 [38400/50000 (76.7%)]\tLoss: 0.243582\n",
      "Train Epoch: 18 [44800/50000 (89.5%)]\tLoss: 0.152180\n",
      "\n",
      "Test set: Average loss: 0.3088, Accuracy: 8954/10000 (89.5%)\n",
      "\n",
      "Train Epoch: 19 [0/50000 (0.0%)]\tLoss: 0.388367\n",
      "Train Epoch: 19 [6400/50000 (12.8%)]\tLoss: 0.257025\n",
      "Train Epoch: 19 [12800/50000 (25.6%)]\tLoss: 0.250177\n",
      "Train Epoch: 19 [19200/50000 (38.4%)]\tLoss: 0.223391\n",
      "Train Epoch: 19 [25600/50000 (51.2%)]\tLoss: 0.184357\n",
      "Train Epoch: 19 [32000/50000 (63.9%)]\tLoss: 0.253227\n",
      "Train Epoch: 19 [38400/50000 (76.7%)]\tLoss: 0.345515\n",
      "Train Epoch: 19 [44800/50000 (89.5%)]\tLoss: 0.169834\n",
      "\n",
      "Test set: Average loss: 0.3092, Accuracy: 8940/10000 (89.4%)\n",
      "\n",
      "Best accuracy: tensor(0.8954)\n"
     ]
    }
   ],
   "source": [
    "sr = 'sr'\n",
    "s = 0.00001\n",
    "depth = 164\n",
    "\n",
    "if refine:\n",
    "    checkpoint = torch.load(refine)\n",
    "    model = resnet(dataset=dataset, depth=depth, cfg=checkpoint['cfg'])\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "else:\n",
    "    model = resnet(dataset=dataset, depth=depth)\n",
    "    \n",
    "if cuda:\n",
    "    model.cuda()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "resume = ''\n",
    "start_epoch = 0\n",
    "\n",
    "if resume:\n",
    "    if os.path.isfile(resume):\n",
    "        print(\"=> loading checkpoint '{}'\".format(resume))\n",
    "        checkpoint = torch.load(resume)\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        best_prec1 = checkpoint['best_prec1']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {}) Prec1: {:f}\"\n",
    "              .format(resume, checkpoint['epoch'], best_prec1))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(resume))\n",
    "        \n",
    "epochs = 20\n",
    "save = ''\n",
    "\n",
    "best_prec1 = 0.\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    if epoch in [epochs*0.5, epochs*0.75]:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] *= 0.1\n",
    "    train(epoch)\n",
    "    prec1 = test()\n",
    "    is_best = prec1 > best_prec1\n",
    "    best_prec1 = max(prec1, best_prec1)\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_prec1': best_prec1,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, filepath=save)\n",
    "\n",
    "print(\"Best accuracy: \"+str(best_prec1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3bf024",
   "metadata": {
    "papermill": {
     "duration": 0.039216,
     "end_time": "2024-03-31T16:15:48.491818",
     "exception": false,
     "start_time": "2024-03-31T16:15:48.452602",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Prune**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4782c4b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T16:15:48.573515Z",
     "iopub.status.busy": "2024-03-31T16:15:48.573101Z",
     "iopub.status.idle": "2024-03-31T16:15:48.578539Z",
     "shell.execute_reply": "2024-03-31T16:15:48.577592Z"
    },
    "papermill": {
     "duration": 0.049238,
     "end_time": "2024-03-31T16:15:48.580650",
     "exception": false,
     "start_time": "2024-03-31T16:15:48.531412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# depth = 164\n",
    "# percent = 0.4\n",
    "# model_path = '/kaggle/working/model_best.pth.tar'\n",
    "\n",
    "# model = resnet(depth=depth)\n",
    "\n",
    "# if cuda:\n",
    "#     model.cuda()\n",
    "\n",
    "# if model_path:\n",
    "#     if os.path.isfile(model_path):\n",
    "#         print(\"=> loading checkpoint '{}'\".format(model_path))\n",
    "#         checkpoint = torch.load(model_path)\n",
    "#         start_epoch = checkpoint['epoch']\n",
    "#         best_prec1 = checkpoint['best_prec1']\n",
    "#         model.load_state_dict(checkpoint['state_dict'])\n",
    "#         print(\"=> loaded checkpoint '{}' (epoch {}) Prec1: {:f}\"\n",
    "#               .format(model_path, checkpoint['epoch'], best_prec1))\n",
    "#     else:\n",
    "#         print(\"=> no checkpoint found at '{}'\".format(resume))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "899a6f57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T16:15:48.658869Z",
     "iopub.status.busy": "2024-03-31T16:15:48.658236Z",
     "iopub.status.idle": "2024-03-31T16:15:48.663645Z",
     "shell.execute_reply": "2024-03-31T16:15:48.662692Z"
    },
    "papermill": {
     "duration": 0.046217,
     "end_time": "2024-03-31T16:15:48.665669",
     "exception": false,
     "start_time": "2024-03-31T16:15:48.619452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# total = 0\n",
    "\n",
    "# for m in model.modules():\n",
    "#     if isinstance(m, nn.BatchNorm2d):\n",
    "#         total += m.weight.data.shape[0]\n",
    "\n",
    "# bn = torch.zeros(total)\n",
    "# index = 0\n",
    "# for m in model.modules():\n",
    "#     if isinstance(m, nn.BatchNorm2d):\n",
    "#         size = m.weight.data.shape[0]\n",
    "#         bn[index:(index+size)] = m.weight.data.abs().clone()\n",
    "#         index += size\n",
    "\n",
    "# y, i = torch.sort(bn)\n",
    "# thre_index = int(total * percent)\n",
    "# thre = y[thre_index]\n",
    "\n",
    "\n",
    "# pruned = 0\n",
    "# cfg = []\n",
    "# cfg_mask = []\n",
    "# for k, m in enumerate(model.modules()):\n",
    "#     if isinstance(m, nn.BatchNorm2d):\n",
    "#         weight_copy = m.weight.data.abs().clone()\n",
    "#         mask = weight_copy.gt(thre).float().cuda()\n",
    "#         pruned = pruned + mask.shape[0] - torch.sum(mask)\n",
    "#         m.weight.data.mul_(mask)\n",
    "#         m.bias.data.mul_(mask)\n",
    "#         cfg.append(int(torch.sum(mask)))\n",
    "#         cfg_mask.append(mask.clone())\n",
    "#         print('layer index: {:d} \\t total channel: {:d} \\t remaining channel: {:d}'.\n",
    "#             format(k, mask.shape[0], int(torch.sum(mask))))\n",
    "#     elif isinstance(m, nn.MaxPool2d):\n",
    "#         cfg.append('M')\n",
    "\n",
    "# pruned_ratio = pruned/total\n",
    "\n",
    "# print('Pre-processing Successful!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4887fd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T16:15:48.748509Z",
     "iopub.status.busy": "2024-03-31T16:15:48.747541Z",
     "iopub.status.idle": "2024-03-31T16:15:48.753855Z",
     "shell.execute_reply": "2024-03-31T16:15:48.752826Z"
    },
    "papermill": {
     "duration": 0.052033,
     "end_time": "2024-03-31T16:15:48.756082",
     "exception": false,
     "start_time": "2024-03-31T16:15:48.704049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # simple test model after Pre-processing prune (simple set BN scales to zeros)\n",
    "# def test(model):\n",
    "#     kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "#     if dataset == 'cifar10':\n",
    "#         test_loader = torch.utils.data.DataLoader(\n",
    "#             datasets.CIFAR10('./data.cifar10', train=False, transform=transforms.Compose([\n",
    "#                 transforms.ToTensor(),\n",
    "#                 transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])),\n",
    "#             batch_size=test_batch_size, shuffle=False, **kwargs)\n",
    "#     elif dataset == 'cifar100':\n",
    "#         test_loader = torch.utils.data.DataLoader(\n",
    "#             datasets.CIFAR100('./data.cifar100', train=False, transform=transforms.Compose([\n",
    "#                 transforms.ToTensor(),\n",
    "#                 transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])),\n",
    "#             batch_size=test_batch_size, shuffle=False, **kwargs)\n",
    "#     else:\n",
    "#         raise ValueError(\"No valid dataset is given.\")\n",
    "#     model.eval()\n",
    "#     correct = 0\n",
    "#     for data, target in test_loader:\n",
    "#         if cuda:\n",
    "#             data, target = data.cuda(), target.cuda()\n",
    "#         with torch.no_grad():\n",
    "#             data, target = Variable(data), Variable(target)\n",
    "#         output = model(data)\n",
    "#         pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "#         correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "#     print('\\nTest set: Accuracy: {}/{} ({:.1f}%)\\n'.format(\n",
    "#         correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n",
    "#     return correct / float(len(test_loader.dataset))\n",
    "\n",
    "# acc = test(model)\n",
    "\n",
    "# print(\"Cfg:\")\n",
    "# print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41e15924",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T16:15:48.837705Z",
     "iopub.status.busy": "2024-03-31T16:15:48.836753Z",
     "iopub.status.idle": "2024-03-31T16:15:48.841905Z",
     "shell.execute_reply": "2024-03-31T16:15:48.840854Z"
    },
    "papermill": {
     "duration": 0.047758,
     "end_time": "2024-03-31T16:15:48.843910",
     "exception": false,
     "start_time": "2024-03-31T16:15:48.796152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save = ''\n",
    "# newmodel = resnet(depth=depth, cfg=cfg)\n",
    "# if cuda:\n",
    "#     newmodel.cuda()\n",
    "\n",
    "# num_parameters = sum([param.nelement() for param in newmodel.parameters()])\n",
    "# savepath = os.path.join(save, \"prune.txt\")\n",
    "# with open(savepath, \"w\") as fp:\n",
    "#     fp.write(\"Configuration: \\n\"+str(cfg)+\"\\n\")\n",
    "#     fp.write(\"Number of parameters: \\n\"+str(num_parameters)+\"\\n\")\n",
    "#     fp.write(\"Test accuracy: \\n\"+str(acc))\n",
    "\n",
    "# old_modules = list(model.modules())\n",
    "# new_modules = list(newmodel.modules())\n",
    "# layer_id_in_cfg = 0\n",
    "# start_mask = torch.ones(3)\n",
    "# end_mask = cfg_mask[layer_id_in_cfg]\n",
    "# conv_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f98e2f86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T16:15:48.927533Z",
     "iopub.status.busy": "2024-03-31T16:15:48.927148Z",
     "iopub.status.idle": "2024-03-31T16:15:48.935207Z",
     "shell.execute_reply": "2024-03-31T16:15:48.934149Z"
    },
    "papermill": {
     "duration": 0.053475,
     "end_time": "2024-03-31T16:15:48.937520",
     "exception": false,
     "start_time": "2024-03-31T16:15:48.884045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for layer_id in range(len(old_modules)):\n",
    "#     m0 = old_modules[layer_id]\n",
    "#     m1 = new_modules[layer_id]\n",
    "#     if isinstance(m0, nn.BatchNorm2d):\n",
    "#         idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
    "#         if idx1.size == 1:\n",
    "#             idx1 = np.resize(idx1,(1,))\n",
    "\n",
    "#         if isinstance(old_modules[layer_id + 1], channel_selection):\n",
    "#             # If the next layer is the channel selection layer, then the current batchnorm 2d layer won't be pruned.\n",
    "#             m1.weight.data = m0.weight.data.clone()\n",
    "#             m1.bias.data = m0.bias.data.clone()\n",
    "#             m1.running_mean = m0.running_mean.clone()\n",
    "#             m1.running_var = m0.running_var.clone()\n",
    "\n",
    "#             # We need to set the channel selection layer.\n",
    "#             m2 = new_modules[layer_id + 1]\n",
    "#             m2.indexes.data.zero_()\n",
    "#             m2.indexes.data[idx1.tolist()] = 1.0\n",
    "\n",
    "#             layer_id_in_cfg += 1\n",
    "#             start_mask = end_mask.clone()\n",
    "#             if layer_id_in_cfg < len(cfg_mask):\n",
    "#                 end_mask = cfg_mask[layer_id_in_cfg]\n",
    "#         else:\n",
    "#             m1.weight.data = m0.weight.data[idx1.tolist()].clone()\n",
    "#             m1.bias.data = m0.bias.data[idx1.tolist()].clone()\n",
    "#             m1.running_mean = m0.running_mean[idx1.tolist()].clone()\n",
    "#             m1.running_var = m0.running_var[idx1.tolist()].clone()\n",
    "#             layer_id_in_cfg += 1\n",
    "#             start_mask = end_mask.clone()\n",
    "#             if layer_id_in_cfg < len(cfg_mask):  # do not change in Final FC\n",
    "#                 end_mask = cfg_mask[layer_id_in_cfg]\n",
    "#     elif isinstance(m0, nn.Conv2d):\n",
    "#         if conv_count == 0:\n",
    "#             m1.weight.data = m0.weight.data.clone()\n",
    "#             conv_count += 1\n",
    "#             continue\n",
    "#         if isinstance(old_modules[layer_id-1], channel_selection) or isinstance(old_modules[layer_id-1], nn.BatchNorm2d):\n",
    "#             # This convers the convolutions in the residual block.\n",
    "#             # The convolutions are either after the channel selection layer or after the batch normalization layer.\n",
    "#             conv_count += 1\n",
    "#             idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
    "#             idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
    "#             print('In shape: {:d}, Out shape {:d}.'.format(idx0.size, idx1.size))\n",
    "#             if idx0.size == 1:\n",
    "#                 idx0 = np.resize(idx0, (1,))\n",
    "#             if idx1.size == 1:\n",
    "#                 idx1 = np.resize(idx1, (1,))\n",
    "#             w1 = m0.weight.data[:, idx0.tolist(), :, :].clone()\n",
    "\n",
    "#             # If the current convolution is not the last convolution in the residual block, then we can change the \n",
    "#             # number of output channels. Currently we use `conv_count` to detect whether it is such convolution.\n",
    "#             if conv_count % 3 != 1:\n",
    "#                 w1 = w1[idx1.tolist(), :, :, :].clone()\n",
    "#             m1.weight.data = w1.clone()\n",
    "#             continue\n",
    "\n",
    "#         # We need to consider the case where there are downsampling convolutions. \n",
    "#         # For these convolutions, we just copy the weights.\n",
    "#         m1.weight.data = m0.weight.data.clone()\n",
    "#     elif isinstance(m0, nn.Linear):\n",
    "#         idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
    "#         if idx0.size == 1:\n",
    "#             idx0 = np.resize(idx0, (1,))\n",
    "\n",
    "#         m1.weight.data = m0.weight.data[:, idx0].clone()\n",
    "#         m1.bias.data = m0.bias.data.clone()\n",
    "\n",
    "# torch.save({'cfg': cfg, 'state_dict': newmodel.state_dict()}, os.path.join(save, 'pruned.pth.tar'))\n",
    "\n",
    "# print(newmodel)\n",
    "# model = newmodel\n",
    "# test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba57e43e",
   "metadata": {
    "papermill": {
     "duration": 0.04012,
     "end_time": "2024-03-31T16:15:49.018515",
     "exception": false,
     "start_time": "2024-03-31T16:15:48.978395",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Fine-tune**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "423eaf4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T16:15:49.099683Z",
     "iopub.status.busy": "2024-03-31T16:15:49.098988Z",
     "iopub.status.idle": "2024-03-31T16:15:49.107656Z",
     "shell.execute_reply": "2024-03-31T16:15:49.106730Z"
    },
    "papermill": {
     "duration": 0.051542,
     "end_time": "2024-03-31T16:15:49.109626",
     "exception": false,
     "start_time": "2024-03-31T16:15:49.058084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# refine = '/kaggle/working/pruned.pth.tar'\n",
    "# epochs = 20\n",
    "# depth = 164\n",
    "\n",
    "# s = 0.0001\n",
    "# sr = ''\n",
    "# log_interval = 100\n",
    "\n",
    "# # additional subgradient descent on the sparsity-induced penalty term\n",
    "# def updateBN():\n",
    "#     for m in model.modules():\n",
    "#         if isinstance(m, nn.BatchNorm2d):\n",
    "#             m.weight.grad.data.add_(s*torch.sign(m.weight.data))  # L1\n",
    "            \n",
    "# def train(epoch):\n",
    "#     model.train()\n",
    "#     for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#         if cuda:\n",
    "#             data, target = data.cuda(), target.cuda()\n",
    "#         with torch.no_grad():\n",
    "#             data, target = Variable(data), Variable(target)\n",
    "#         optimizer.zero_grad()\n",
    "#         output = model(data)\n",
    "#         loss = F.cross_entropy(output, target)\n",
    "#         pred = output.data.max(1, keepdim=True)[1]\n",
    "#         loss.backward()\n",
    "#         if sr:\n",
    "#             updateBN()\n",
    "#         optimizer.step()\n",
    "#         if batch_idx % log_interval == 0:\n",
    "#             print('Train Epoch: {} [{}/{} ({:.1f}%)]\\tLoss: {:.6f}'.format(\n",
    "#                 epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "#                 100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "# def test():\n",
    "#     model.eval()\n",
    "#     test_loss = 0\n",
    "#     correct = 0\n",
    "#     for data, target in test_loader:\n",
    "#         if cuda:\n",
    "#             data, target = data.cuda(), target.cuda()\n",
    "#         with torch.no_grad():\n",
    "#             data, target = Variable(data), Variable(target)\n",
    "#         output = model(data)\n",
    "#         test_loss += F.cross_entropy(output, target, reduction='sum').item() # sum up batch loss\n",
    "#         pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "#         correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "#     test_loss /= len(test_loader.dataset)\n",
    "#     print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n'.format(\n",
    "#         test_loss, correct, len(test_loader.dataset),\n",
    "#         100. * correct / len(test_loader.dataset)))\n",
    "#     return correct / float(len(test_loader.dataset))\n",
    "\n",
    "# def save_checkpoint(state, is_best, filepath):\n",
    "#     torch.save(state, os.path.join(filepath, 'checkpoint.pth.tar'))\n",
    "#     if is_best:\n",
    "#         shutil.copyfile(os.path.join(filepath, 'checkpoint.pth.tar'), os.path.join(filepath, 'model_best.pth.tar'))\n",
    "\n",
    "\n",
    "# if refine:\n",
    "#     checkpoint = torch.load(refine)\n",
    "#     model = resnet(dataset=dataset, depth=depth, cfg=checkpoint['cfg'])\n",
    "#     model.load_state_dict(checkpoint['state_dict'])\n",
    "# else:\n",
    "#     model = resnet(dataset=dataset, depth=depth)\n",
    "    \n",
    "# if cuda:\n",
    "#     model.cuda()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "# resume = ''\n",
    "# start_epoch = 0\n",
    "\n",
    "# if resume:\n",
    "#     if os.path.isfile(resume):\n",
    "#         print(\"=> loading checkpoint '{}'\".format(resume))\n",
    "#         checkpoint = torch.load(resume)\n",
    "#         start_epoch = checkpoint['epoch']\n",
    "#         best_prec1 = checkpoint['best_prec1']\n",
    "#         model.load_state_dict(checkpoint['state_dict'])\n",
    "#         optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "#         print(\"=> loaded checkpoint '{}' (epoch {}) Prec1: {:f}\"\n",
    "#               .format(resume, checkpoint['epoch'], best_prec1))\n",
    "#     else:\n",
    "#         print(\"=> no checkpoint found at '{}'\".format(resume))\n",
    "        \n",
    "# epochs = 20\n",
    "# save = ''\n",
    "\n",
    "# best_prec1 = 0.\n",
    "# for epoch in range(start_epoch, epochs):\n",
    "#     if epoch in [epochs*0.5, epochs*0.75]:\n",
    "#         for param_group in optimizer.param_groups:\n",
    "#             param_group['lr'] *= 0.1\n",
    "#     train(epoch)\n",
    "#     prec1 = test()\n",
    "#     is_best = prec1 > best_prec1\n",
    "#     best_prec1 = max(prec1, best_prec1)\n",
    "#     save_checkpoint({\n",
    "#         'epoch': epoch + 1,\n",
    "#         'state_dict': model.state_dict(),\n",
    "#         'best_prec1': best_prec1,\n",
    "#         'optimizer': optimizer.state_dict(),\n",
    "#     }, is_best, filepath=save)\n",
    "\n",
    "# print(\"Best accuracy: \"+str(best_prec1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7af7ab",
   "metadata": {
    "papermill": {
     "duration": 0.039919,
     "end_time": "2024-03-31T16:15:49.248060",
     "exception": false,
     "start_time": "2024-03-31T16:15:49.208141",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Pruning with different percent values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "beab97bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T16:15:49.330429Z",
     "iopub.status.busy": "2024-03-31T16:15:49.330074Z",
     "iopub.status.idle": "2024-03-31T22:49:30.071927Z",
     "shell.execute_reply": "2024-03-31T22:49:30.070722Z"
    },
    "papermill": {
     "duration": 23620.786029,
     "end_time": "2024-03-31T22:49:30.074147",
     "exception": false,
     "start_time": "2024-03-31T16:15:49.288118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0 Percent:  0\n",
      "=> loading checkpoint '/kaggle/working/model_best.pth.tar'\n",
      "=> loaded checkpoint '/kaggle/working/model_best.pth.tar' (epoch 19) Prec1: 0.895400\n",
      "layer index: 4 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 7 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 9 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 15 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 18 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 20 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 24 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 27 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 29 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 33 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 36 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 38 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 42 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 45 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 47 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 51 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 54 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 56 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 60 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 63 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 65 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 69 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 72 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 74 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 78 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 81 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 83 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 87 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 90 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 92 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 96 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 99 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 101 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 105 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 108 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 110 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 114 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 117 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 119 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 123 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 126 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 128 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 132 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 135 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 137 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 141 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 144 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 146 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 150 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 153 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 155 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 159 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 162 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 164 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 169 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 172 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 174 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 180 \t total channel: 128 \t remaining channel: 128\n",
      "layer index: 183 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 185 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 189 \t total channel: 128 \t remaining channel: 128\n",
      "layer index: 192 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 194 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 198 \t total channel: 128 \t remaining channel: 128\n",
      "layer index: 201 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 203 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 207 \t total channel: 128 \t remaining channel: 128\n",
      "layer index: 210 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 212 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 216 \t total channel: 128 \t remaining channel: 128\n",
      "layer index: 219 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 221 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 225 \t total channel: 128 \t remaining channel: 128\n",
      "layer index: 228 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 230 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 234 \t total channel: 128 \t remaining channel: 128\n",
      "layer index: 237 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 239 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 243 \t total channel: 128 \t remaining channel: 128\n",
      "layer index: 246 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 248 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 252 \t total channel: 128 \t remaining channel: 128\n",
      "layer index: 255 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 257 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 261 \t total channel: 128 \t remaining channel: 128\n",
      "layer index: 264 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 266 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 270 \t total channel: 128 \t remaining channel: 128\n",
      "layer index: 273 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 275 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 279 \t total channel: 128 \t remaining channel: 128\n",
      "layer index: 282 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 284 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 288 \t total channel: 128 \t remaining channel: 128\n",
      "layer index: 291 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 293 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 297 \t total channel: 128 \t remaining channel: 128\n",
      "layer index: 300 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 302 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 306 \t total channel: 128 \t remaining channel: 128\n",
      "layer index: 309 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 311 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 315 \t total channel: 128 \t remaining channel: 128\n",
      "layer index: 318 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 320 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 324 \t total channel: 128 \t remaining channel: 128\n",
      "layer index: 327 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 329 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 334 \t total channel: 128 \t remaining channel: 128\n",
      "layer index: 337 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 339 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 345 \t total channel: 256 \t remaining channel: 256\n",
      "layer index: 348 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 350 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 354 \t total channel: 256 \t remaining channel: 256\n",
      "layer index: 357 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 359 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 363 \t total channel: 256 \t remaining channel: 256\n",
      "layer index: 366 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 368 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 372 \t total channel: 256 \t remaining channel: 256\n",
      "layer index: 375 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 377 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 381 \t total channel: 256 \t remaining channel: 256\n",
      "layer index: 384 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 386 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 390 \t total channel: 256 \t remaining channel: 256\n",
      "layer index: 393 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 395 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 399 \t total channel: 256 \t remaining channel: 256\n",
      "layer index: 402 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 404 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 408 \t total channel: 256 \t remaining channel: 256\n",
      "layer index: 411 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 413 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 417 \t total channel: 256 \t remaining channel: 256\n",
      "layer index: 420 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 422 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 426 \t total channel: 256 \t remaining channel: 256\n",
      "layer index: 429 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 431 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 435 \t total channel: 256 \t remaining channel: 256\n",
      "layer index: 438 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 440 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 444 \t total channel: 256 \t remaining channel: 256\n",
      "layer index: 447 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 449 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 453 \t total channel: 256 \t remaining channel: 256\n",
      "layer index: 456 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 458 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 462 \t total channel: 256 \t remaining channel: 256\n",
      "layer index: 465 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 467 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 471 \t total channel: 256 \t remaining channel: 256\n",
      "layer index: 474 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 476 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 480 \t total channel: 256 \t remaining channel: 256\n",
      "layer index: 483 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 485 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 489 \t total channel: 256 \t remaining channel: 256\n",
      "layer index: 492 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 494 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 497 \t total channel: 256 \t remaining channel: 256\n",
      "Pre-processing Successful!\n",
      "\n",
      "Test set: Accuracy: 8954/10000 (89.5%)\n",
      "\n",
      "Cfg:\n",
      "[16, 16, 16, 64, 16, 16, 64, 16, 16, 64, 16, 16, 64, 16, 16, 64, 16, 16, 64, 16, 16, 64, 16, 16, 64, 16, 16, 64, 16, 16, 64, 16, 16, 64, 15, 16, 64, 16, 16, 64, 16, 16, 64, 16, 16, 64, 16, 16, 64, 16, 16, 64, 16, 16, 64, 32, 32, 128, 32, 32, 128, 32, 32, 128, 32, 32, 128, 32, 32, 128, 32, 32, 128, 32, 32, 128, 32, 32, 128, 32, 32, 128, 32, 32, 128, 32, 32, 128, 32, 32, 128, 32, 32, 128, 32, 32, 128, 32, 32, 128, 32, 32, 128, 32, 32, 128, 32, 32, 128, 64, 64, 256, 64, 64, 256, 64, 64, 256, 64, 64, 256, 64, 64, 256, 64, 64, 256, 64, 64, 256, 64, 64, 256, 64, 64, 256, 64, 64, 256, 64, 64, 256, 64, 64, 256, 64, 64, 256, 64, 64, 256, 64, 64, 256, 64, 64, 256, 64, 64, 256, 64, 64, 256]\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 64.\n",
      "In shape: 64, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 64.\n",
      "In shape: 64, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 64.\n",
      "In shape: 64, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 64.\n",
      "In shape: 64, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 64.\n",
      "In shape: 64, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 64.\n",
      "In shape: 64, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 64.\n",
      "In shape: 64, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 64.\n",
      "In shape: 64, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 64.\n",
      "In shape: 64, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 64.\n",
      "In shape: 64, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 64.\n",
      "In shape: 64, Out shape 15.\n",
      "In shape: 15, Out shape 16.\n",
      "In shape: 16, Out shape 64.\n",
      "In shape: 64, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 64.\n",
      "In shape: 64, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 64.\n",
      "In shape: 64, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 64.\n",
      "In shape: 64, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 64.\n",
      "In shape: 64, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 64.\n",
      "In shape: 64, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 64.\n",
      "In shape: 64, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 128.\n",
      "In shape: 128, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 128.\n",
      "In shape: 128, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 128.\n",
      "In shape: 128, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 128.\n",
      "In shape: 128, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 128.\n",
      "In shape: 128, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 128.\n",
      "In shape: 128, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 128.\n",
      "In shape: 128, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 128.\n",
      "In shape: 128, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 128.\n",
      "In shape: 128, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 128.\n",
      "In shape: 128, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 128.\n",
      "In shape: 128, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 128.\n",
      "In shape: 128, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 128.\n",
      "In shape: 128, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 128.\n",
      "In shape: 128, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 128.\n",
      "In shape: 128, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 128.\n",
      "In shape: 128, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 128.\n",
      "In shape: 128, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 128.\n",
      "In shape: 128, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 256.\n",
      "In shape: 256, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 256.\n",
      "In shape: 256, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 256.\n",
      "In shape: 256, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 256.\n",
      "In shape: 256, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 256.\n",
      "In shape: 256, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 256.\n",
      "In shape: 256, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 256.\n",
      "In shape: 256, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 256.\n",
      "In shape: 256, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 256.\n",
      "In shape: 256, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 256.\n",
      "In shape: 256, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 256.\n",
      "In shape: 256, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 256.\n",
      "In shape: 256, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 256.\n",
      "In shape: 256, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 256.\n",
      "In shape: 256, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 256.\n",
      "In shape: 256, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 256.\n",
      "In shape: 256, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 256.\n",
      "In shape: 256, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 256.\n",
      "resnet(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(64, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (select): channel_selection()\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
      "  (fc): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "Test set: Accuracy: 8954/10000 (89.5%)\n",
      "\n",
      "Train Epoch: 0 [0/50000 (0.0%)]\tLoss: 0.255334\n",
      "Train Epoch: 0 [6400/50000 (12.8%)]\tLoss: 0.720231\n",
      "Train Epoch: 0 [12800/50000 (25.6%)]\tLoss: 0.374474\n",
      "Train Epoch: 0 [19200/50000 (38.4%)]\tLoss: 0.342123\n",
      "Train Epoch: 0 [25600/50000 (51.2%)]\tLoss: 0.250826\n",
      "Train Epoch: 0 [32000/50000 (63.9%)]\tLoss: 0.587879\n",
      "Train Epoch: 0 [38400/50000 (76.7%)]\tLoss: 0.706877\n",
      "Train Epoch: 0 [44800/50000 (89.5%)]\tLoss: 0.403810\n",
      "\n",
      "Test set: Average loss: 0.6190, Accuracy: 7877/10000 (78.8%)\n",
      "\n",
      "Train Epoch: 1 [0/50000 (0.0%)]\tLoss: 0.618984\n",
      "Train Epoch: 1 [6400/50000 (12.8%)]\tLoss: 0.420540\n",
      "Train Epoch: 1 [12800/50000 (25.6%)]\tLoss: 0.540258\n",
      "Train Epoch: 1 [19200/50000 (38.4%)]\tLoss: 0.397711\n",
      "Train Epoch: 1 [25600/50000 (51.2%)]\tLoss: 0.527794\n",
      "Train Epoch: 1 [32000/50000 (63.9%)]\tLoss: 0.855428\n",
      "Train Epoch: 1 [38400/50000 (76.7%)]\tLoss: 0.492079\n",
      "Train Epoch: 1 [44800/50000 (89.5%)]\tLoss: 0.647411\n",
      "\n",
      "Test set: Average loss: 0.6480, Accuracy: 7832/10000 (78.3%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0.0%)]\tLoss: 0.379094\n",
      "Train Epoch: 2 [6400/50000 (12.8%)]\tLoss: 0.480062\n",
      "Train Epoch: 2 [12800/50000 (25.6%)]\tLoss: 0.663830\n",
      "Train Epoch: 2 [19200/50000 (38.4%)]\tLoss: 0.508362\n",
      "Train Epoch: 2 [25600/50000 (51.2%)]\tLoss: 0.529071\n",
      "Train Epoch: 2 [32000/50000 (63.9%)]\tLoss: 0.508363\n",
      "Train Epoch: 2 [38400/50000 (76.7%)]\tLoss: 0.576308\n",
      "Train Epoch: 2 [44800/50000 (89.5%)]\tLoss: 0.493527\n",
      "\n",
      "Test set: Average loss: 0.7201, Accuracy: 7645/10000 (76.4%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0.0%)]\tLoss: 0.628927\n",
      "Train Epoch: 3 [6400/50000 (12.8%)]\tLoss: 0.452407\n",
      "Train Epoch: 3 [12800/50000 (25.6%)]\tLoss: 0.520720\n",
      "Train Epoch: 3 [19200/50000 (38.4%)]\tLoss: 0.471162\n",
      "Train Epoch: 3 [25600/50000 (51.2%)]\tLoss: 0.257402\n",
      "Train Epoch: 3 [32000/50000 (63.9%)]\tLoss: 0.489016\n",
      "Train Epoch: 3 [38400/50000 (76.7%)]\tLoss: 0.541058\n",
      "Train Epoch: 3 [44800/50000 (89.5%)]\tLoss: 0.466225\n",
      "\n",
      "Test set: Average loss: 0.5416, Accuracy: 8194/10000 (81.9%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0.0%)]\tLoss: 0.302486\n",
      "Train Epoch: 4 [6400/50000 (12.8%)]\tLoss: 0.444787\n",
      "Train Epoch: 4 [12800/50000 (25.6%)]\tLoss: 0.501005\n",
      "Train Epoch: 4 [19200/50000 (38.4%)]\tLoss: 0.688942\n",
      "Train Epoch: 4 [25600/50000 (51.2%)]\tLoss: 0.382749\n",
      "Train Epoch: 4 [32000/50000 (63.9%)]\tLoss: 0.397481\n",
      "Train Epoch: 4 [38400/50000 (76.7%)]\tLoss: 0.363640\n",
      "Train Epoch: 4 [44800/50000 (89.5%)]\tLoss: 0.374056\n",
      "\n",
      "Test set: Average loss: 0.4957, Accuracy: 8339/10000 (83.4%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0.0%)]\tLoss: 0.543884\n",
      "Train Epoch: 5 [6400/50000 (12.8%)]\tLoss: 0.410687\n",
      "Train Epoch: 5 [12800/50000 (25.6%)]\tLoss: 0.579869\n",
      "Train Epoch: 5 [19200/50000 (38.4%)]\tLoss: 0.356870\n",
      "Train Epoch: 5 [25600/50000 (51.2%)]\tLoss: 0.301367\n",
      "Train Epoch: 5 [32000/50000 (63.9%)]\tLoss: 0.378585\n",
      "Train Epoch: 5 [38400/50000 (76.7%)]\tLoss: 0.441768\n",
      "Train Epoch: 5 [44800/50000 (89.5%)]\tLoss: 0.408141\n",
      "\n",
      "Test set: Average loss: 0.5028, Accuracy: 8327/10000 (83.3%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0.0%)]\tLoss: 0.369480\n",
      "Train Epoch: 6 [6400/50000 (12.8%)]\tLoss: 0.287295\n",
      "Train Epoch: 6 [12800/50000 (25.6%)]\tLoss: 0.466971\n",
      "Train Epoch: 6 [19200/50000 (38.4%)]\tLoss: 0.602305\n",
      "Train Epoch: 6 [25600/50000 (51.2%)]\tLoss: 0.371439\n",
      "Train Epoch: 6 [32000/50000 (63.9%)]\tLoss: 0.295814\n",
      "Train Epoch: 6 [38400/50000 (76.7%)]\tLoss: 0.391874\n",
      "Train Epoch: 6 [44800/50000 (89.5%)]\tLoss: 0.431776\n",
      "\n",
      "Test set: Average loss: 0.6197, Accuracy: 7996/10000 (80.0%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0.0%)]\tLoss: 0.386397\n",
      "Train Epoch: 7 [6400/50000 (12.8%)]\tLoss: 0.337454\n",
      "Train Epoch: 7 [12800/50000 (25.6%)]\tLoss: 0.358797\n",
      "Train Epoch: 7 [19200/50000 (38.4%)]\tLoss: 0.423364\n",
      "Train Epoch: 7 [25600/50000 (51.2%)]\tLoss: 0.445605\n",
      "Train Epoch: 7 [32000/50000 (63.9%)]\tLoss: 0.365411\n",
      "Train Epoch: 7 [38400/50000 (76.7%)]\tLoss: 0.455824\n",
      "Train Epoch: 7 [44800/50000 (89.5%)]\tLoss: 0.431843\n",
      "\n",
      "Test set: Average loss: 0.5461, Accuracy: 8224/10000 (82.2%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0.0%)]\tLoss: 0.261018\n",
      "Train Epoch: 8 [6400/50000 (12.8%)]\tLoss: 0.527419\n",
      "Train Epoch: 8 [12800/50000 (25.6%)]\tLoss: 0.470943\n",
      "Train Epoch: 8 [19200/50000 (38.4%)]\tLoss: 0.339622\n",
      "Train Epoch: 8 [25600/50000 (51.2%)]\tLoss: 0.494643\n",
      "Train Epoch: 8 [32000/50000 (63.9%)]\tLoss: 0.604019\n",
      "Train Epoch: 8 [38400/50000 (76.7%)]\tLoss: 0.420745\n",
      "Train Epoch: 8 [44800/50000 (89.5%)]\tLoss: 0.593270\n",
      "\n",
      "Test set: Average loss: 0.5949, Accuracy: 8014/10000 (80.1%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0.0%)]\tLoss: 0.429135\n",
      "Train Epoch: 9 [6400/50000 (12.8%)]\tLoss: 0.490224\n",
      "Train Epoch: 9 [12800/50000 (25.6%)]\tLoss: 0.489533\n",
      "Train Epoch: 9 [19200/50000 (38.4%)]\tLoss: 0.599026\n",
      "Train Epoch: 9 [25600/50000 (51.2%)]\tLoss: 0.390323\n",
      "Train Epoch: 9 [32000/50000 (63.9%)]\tLoss: 0.267355\n",
      "Train Epoch: 9 [38400/50000 (76.7%)]\tLoss: 0.611145\n",
      "Train Epoch: 9 [44800/50000 (89.5%)]\tLoss: 0.593428\n",
      "\n",
      "Test set: Average loss: 0.6253, Accuracy: 8000/10000 (80.0%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0.0%)]\tLoss: 0.481673\n",
      "Train Epoch: 10 [6400/50000 (12.8%)]\tLoss: 0.210523\n",
      "Train Epoch: 10 [12800/50000 (25.6%)]\tLoss: 0.369214\n",
      "Train Epoch: 10 [19200/50000 (38.4%)]\tLoss: 0.274570\n",
      "Train Epoch: 10 [25600/50000 (51.2%)]\tLoss: 0.304452\n",
      "Train Epoch: 10 [32000/50000 (63.9%)]\tLoss: 0.199795\n",
      "Train Epoch: 10 [38400/50000 (76.7%)]\tLoss: 0.131654\n",
      "Train Epoch: 10 [44800/50000 (89.5%)]\tLoss: 0.151766\n",
      "\n",
      "Test set: Average loss: 0.2726, Accuracy: 9067/10000 (90.7%)\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0.0%)]\tLoss: 0.163873\n",
      "Train Epoch: 11 [6400/50000 (12.8%)]\tLoss: 0.340741\n",
      "Train Epoch: 11 [12800/50000 (25.6%)]\tLoss: 0.122503\n",
      "Train Epoch: 11 [19200/50000 (38.4%)]\tLoss: 0.178811\n",
      "Train Epoch: 11 [25600/50000 (51.2%)]\tLoss: 0.207307\n",
      "Train Epoch: 11 [32000/50000 (63.9%)]\tLoss: 0.202913\n",
      "Train Epoch: 11 [38400/50000 (76.7%)]\tLoss: 0.151617\n",
      "Train Epoch: 11 [44800/50000 (89.5%)]\tLoss: 0.117408\n",
      "\n",
      "Test set: Average loss: 0.2633, Accuracy: 9116/10000 (91.2%)\n",
      "\n",
      "Train Epoch: 12 [0/50000 (0.0%)]\tLoss: 0.093327\n",
      "Train Epoch: 12 [6400/50000 (12.8%)]\tLoss: 0.106999\n",
      "Train Epoch: 12 [12800/50000 (25.6%)]\tLoss: 0.104071\n",
      "Train Epoch: 12 [19200/50000 (38.4%)]\tLoss: 0.298496\n",
      "Train Epoch: 12 [25600/50000 (51.2%)]\tLoss: 0.167844\n",
      "Train Epoch: 12 [32000/50000 (63.9%)]\tLoss: 0.218387\n",
      "Train Epoch: 12 [38400/50000 (76.7%)]\tLoss: 0.140677\n",
      "Train Epoch: 12 [44800/50000 (89.5%)]\tLoss: 0.140969\n",
      "\n",
      "Test set: Average loss: 0.2656, Accuracy: 9119/10000 (91.2%)\n",
      "\n",
      "Train Epoch: 13 [0/50000 (0.0%)]\tLoss: 0.282659\n",
      "Train Epoch: 13 [6400/50000 (12.8%)]\tLoss: 0.144939\n",
      "Train Epoch: 13 [12800/50000 (25.6%)]\tLoss: 0.186698\n",
      "Train Epoch: 13 [19200/50000 (38.4%)]\tLoss: 0.109701\n",
      "Train Epoch: 13 [25600/50000 (51.2%)]\tLoss: 0.219445\n",
      "Train Epoch: 13 [32000/50000 (63.9%)]\tLoss: 0.353465\n",
      "Train Epoch: 13 [38400/50000 (76.7%)]\tLoss: 0.235689\n",
      "Train Epoch: 13 [44800/50000 (89.5%)]\tLoss: 0.216059\n",
      "\n",
      "Test set: Average loss: 0.2541, Accuracy: 9166/10000 (91.7%)\n",
      "\n",
      "Train Epoch: 14 [0/50000 (0.0%)]\tLoss: 0.141715\n",
      "Train Epoch: 14 [6400/50000 (12.8%)]\tLoss: 0.139808\n",
      "Train Epoch: 14 [12800/50000 (25.6%)]\tLoss: 0.221479\n",
      "Train Epoch: 14 [19200/50000 (38.4%)]\tLoss: 0.036389\n",
      "Train Epoch: 14 [25600/50000 (51.2%)]\tLoss: 0.204995\n",
      "Train Epoch: 14 [32000/50000 (63.9%)]\tLoss: 0.189185\n",
      "Train Epoch: 14 [38400/50000 (76.7%)]\tLoss: 0.231133\n",
      "Train Epoch: 14 [44800/50000 (89.5%)]\tLoss: 0.204931\n",
      "\n",
      "Test set: Average loss: 0.2580, Accuracy: 9169/10000 (91.7%)\n",
      "\n",
      "Train Epoch: 15 [0/50000 (0.0%)]\tLoss: 0.083810\n",
      "Train Epoch: 15 [6400/50000 (12.8%)]\tLoss: 0.112603\n",
      "Train Epoch: 15 [12800/50000 (25.6%)]\tLoss: 0.151876\n",
      "Train Epoch: 15 [19200/50000 (38.4%)]\tLoss: 0.076696\n",
      "Train Epoch: 15 [25600/50000 (51.2%)]\tLoss: 0.152500\n",
      "Train Epoch: 15 [32000/50000 (63.9%)]\tLoss: 0.135618\n",
      "Train Epoch: 15 [38400/50000 (76.7%)]\tLoss: 0.102527\n",
      "Train Epoch: 15 [44800/50000 (89.5%)]\tLoss: 0.198905\n",
      "\n",
      "Test set: Average loss: 0.2421, Accuracy: 9208/10000 (92.1%)\n",
      "\n",
      "Train Epoch: 16 [0/50000 (0.0%)]\tLoss: 0.098861\n",
      "Train Epoch: 16 [6400/50000 (12.8%)]\tLoss: 0.088416\n",
      "Train Epoch: 16 [12800/50000 (25.6%)]\tLoss: 0.053376\n",
      "Train Epoch: 16 [19200/50000 (38.4%)]\tLoss: 0.124304\n",
      "Train Epoch: 16 [25600/50000 (51.2%)]\tLoss: 0.137262\n",
      "Train Epoch: 16 [32000/50000 (63.9%)]\tLoss: 0.138795\n",
      "Train Epoch: 16 [38400/50000 (76.7%)]\tLoss: 0.256049\n",
      "Train Epoch: 16 [44800/50000 (89.5%)]\tLoss: 0.216168\n",
      "\n",
      "Test set: Average loss: 0.2427, Accuracy: 9210/10000 (92.1%)\n",
      "\n",
      "Train Epoch: 17 [0/50000 (0.0%)]\tLoss: 0.097174\n",
      "Train Epoch: 17 [6400/50000 (12.8%)]\tLoss: 0.174693\n",
      "Train Epoch: 17 [12800/50000 (25.6%)]\tLoss: 0.189607\n",
      "Train Epoch: 17 [19200/50000 (38.4%)]\tLoss: 0.143555\n",
      "Train Epoch: 17 [25600/50000 (51.2%)]\tLoss: 0.084449\n",
      "Train Epoch: 17 [32000/50000 (63.9%)]\tLoss: 0.150412\n",
      "Train Epoch: 17 [38400/50000 (76.7%)]\tLoss: 0.203911\n",
      "Train Epoch: 17 [44800/50000 (89.5%)]\tLoss: 0.087719\n",
      "\n",
      "Test set: Average loss: 0.2372, Accuracy: 9215/10000 (92.2%)\n",
      "\n",
      "Train Epoch: 18 [0/50000 (0.0%)]\tLoss: 0.085095\n",
      "Train Epoch: 18 [6400/50000 (12.8%)]\tLoss: 0.197212\n",
      "Train Epoch: 18 [12800/50000 (25.6%)]\tLoss: 0.043224\n",
      "Train Epoch: 18 [19200/50000 (38.4%)]\tLoss: 0.125717\n",
      "Train Epoch: 18 [25600/50000 (51.2%)]\tLoss: 0.185471\n",
      "Train Epoch: 18 [32000/50000 (63.9%)]\tLoss: 0.272576\n",
      "Train Epoch: 18 [38400/50000 (76.7%)]\tLoss: 0.136827\n",
      "Train Epoch: 18 [44800/50000 (89.5%)]\tLoss: 0.136933\n",
      "\n",
      "Test set: Average loss: 0.2426, Accuracy: 9208/10000 (92.1%)\n",
      "\n",
      "Train Epoch: 19 [0/50000 (0.0%)]\tLoss: 0.078204\n",
      "Train Epoch: 19 [6400/50000 (12.8%)]\tLoss: 0.114816\n",
      "Train Epoch: 19 [12800/50000 (25.6%)]\tLoss: 0.065499\n",
      "Train Epoch: 19 [19200/50000 (38.4%)]\tLoss: 0.139415\n",
      "Train Epoch: 19 [25600/50000 (51.2%)]\tLoss: 0.137515\n",
      "Train Epoch: 19 [32000/50000 (63.9%)]\tLoss: 0.108325\n",
      "Train Epoch: 19 [38400/50000 (76.7%)]\tLoss: 0.168115\n",
      "Train Epoch: 19 [44800/50000 (89.5%)]\tLoss: 0.097903\n",
      "\n",
      "Test set: Average loss: 0.2440, Accuracy: 9226/10000 (92.3%)\n",
      "\n",
      "Best accuracy: tensor(0.9226)\n",
      "Number of parameters: 1711128\n",
      "Average Time taken: 140.54788216352463\n",
      "Iteration:  1 Percent:  0\n",
      "=> loading checkpoint '/kaggle/working/model_best.pth.tar'\n",
      "=> loaded checkpoint '/kaggle/working/model_best.pth.tar' (epoch 19) Prec1: 0.895400\n",
      "layer index: 4 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 7 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 9 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 15 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 18 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 20 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 24 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 27 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 29 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 33 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 36 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 38 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 42 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 45 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 47 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 51 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 54 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 56 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 60 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 63 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 65 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 69 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 72 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 74 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 78 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 81 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 83 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 87 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 90 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 92 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 96 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 99 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 101 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 105 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 108 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 110 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 114 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 117 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 119 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 123 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 126 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 128 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 132 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 135 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 137 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 141 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 144 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 146 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 150 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 153 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 155 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 159 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 162 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 164 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 169 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 172 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 174 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 180 \t total channel: 128 \t remaining channel: 128\n",
      "layer index: 183 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 185 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 189 \t total channel: 128 \t remaining channel: 128\n",
      "layer index: 192 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 194 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 198 \t total channel: 128 \t remaining channel: 128\n",
      "layer index: 201 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 203 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 207 \t total channel: 128 \t remaining channel: 128\n",
      "layer index: 210 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 212 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 216 \t total channel: 128 \t remaining channel: 128\n",
      "layer index: 219 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 221 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 225 \t total channel: 128 \t remaining channel: 128\n",
      "layer index: 228 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 230 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 234 \t total channel: 128 \t remaining channel: 128\n",
      "layer index: 237 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 239 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 243 \t total channel: 128 \t remaining channel: 128\n",
      "layer index: 246 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 248 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 252 \t total channel: 128 \t remaining channel: 128\n",
      "layer index: 255 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 257 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 261 \t total channel: 128 \t remaining channel: 128\n",
      "layer index: 264 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 266 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 270 \t total channel: 128 \t remaining channel: 128\n",
      "layer index: 273 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 275 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 279 \t total channel: 128 \t remaining channel: 128\n",
      "layer index: 282 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 284 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 288 \t total channel: 128 \t remaining channel: 128\n",
      "layer index: 291 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 293 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 297 \t total channel: 128 \t remaining channel: 128\n",
      "layer index: 300 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 302 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 306 \t total channel: 128 \t remaining channel: 128\n",
      "layer index: 309 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 311 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 315 \t total channel: 128 \t remaining channel: 128\n",
      "layer index: 318 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 320 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 324 \t total channel: 128 \t remaining channel: 128\n",
      "layer index: 327 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 329 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 334 \t total channel: 128 \t remaining channel: 128\n",
      "layer index: 337 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 339 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 345 \t total channel: 256 \t remaining channel: 256\n",
      "layer index: 348 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 350 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 354 \t total channel: 256 \t remaining channel: 256\n",
      "layer index: 357 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 359 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 363 \t total channel: 256 \t remaining channel: 256\n",
      "layer index: 366 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 368 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 372 \t total channel: 256 \t remaining channel: 256\n",
      "layer index: 375 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 377 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 381 \t total channel: 256 \t remaining channel: 256\n",
      "layer index: 384 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 386 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 390 \t total channel: 256 \t remaining channel: 256\n",
      "layer index: 393 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 395 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 399 \t total channel: 256 \t remaining channel: 256\n",
      "layer index: 402 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 404 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 408 \t total channel: 256 \t remaining channel: 256\n",
      "layer index: 411 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 413 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 417 \t total channel: 256 \t remaining channel: 256\n",
      "layer index: 420 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 422 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 426 \t total channel: 256 \t remaining channel: 256\n",
      "layer index: 429 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 431 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 435 \t total channel: 256 \t remaining channel: 256\n",
      "layer index: 438 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 440 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 444 \t total channel: 256 \t remaining channel: 256\n",
      "layer index: 447 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 449 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 453 \t total channel: 256 \t remaining channel: 256\n",
      "layer index: 456 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 458 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 462 \t total channel: 256 \t remaining channel: 256\n",
      "layer index: 465 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 467 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 471 \t total channel: 256 \t remaining channel: 256\n",
      "layer index: 474 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 476 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 480 \t total channel: 256 \t remaining channel: 256\n",
      "layer index: 483 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 485 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 489 \t total channel: 256 \t remaining channel: 256\n",
      "layer index: 492 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 494 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 497 \t total channel: 256 \t remaining channel: 256\n",
      "Pre-processing Successful!\n",
      "\n",
      "Test set: Accuracy: 8954/10000 (89.5%)\n",
      "\n",
      "Cfg:\n",
      "[16, 16, 16, 64, 16, 16, 64, 16, 16, 64, 16, 16, 64, 16, 16, 64, 16, 16, 64, 16, 16, 64, 16, 16, 64, 16, 16, 64, 16, 16, 64, 16, 16, 64, 15, 16, 64, 16, 16, 64, 16, 16, 64, 16, 16, 64, 16, 16, 64, 16, 16, 64, 16, 16, 64, 32, 32, 128, 32, 32, 128, 32, 32, 128, 32, 32, 128, 32, 32, 128, 32, 32, 128, 32, 32, 128, 32, 32, 128, 32, 32, 128, 32, 32, 128, 32, 32, 128, 32, 32, 128, 32, 32, 128, 32, 32, 128, 32, 32, 128, 32, 32, 128, 32, 32, 128, 32, 32, 128, 64, 64, 256, 64, 64, 256, 64, 64, 256, 64, 64, 256, 64, 64, 256, 64, 64, 256, 64, 64, 256, 64, 64, 256, 64, 64, 256, 64, 64, 256, 64, 64, 256, 64, 64, 256, 64, 64, 256, 64, 64, 256, 64, 64, 256, 64, 64, 256, 64, 64, 256, 64, 64, 256]\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 64.\n",
      "In shape: 64, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 64.\n",
      "In shape: 64, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 64.\n",
      "In shape: 64, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 64.\n",
      "In shape: 64, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 64.\n",
      "In shape: 64, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 64.\n",
      "In shape: 64, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 64.\n",
      "In shape: 64, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 64.\n",
      "In shape: 64, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 64.\n",
      "In shape: 64, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 64.\n",
      "In shape: 64, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 64.\n",
      "In shape: 64, Out shape 15.\n",
      "In shape: 15, Out shape 16.\n",
      "In shape: 16, Out shape 64.\n",
      "In shape: 64, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 64.\n",
      "In shape: 64, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 64.\n",
      "In shape: 64, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 64.\n",
      "In shape: 64, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 64.\n",
      "In shape: 64, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 64.\n",
      "In shape: 64, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 64.\n",
      "In shape: 64, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 128.\n",
      "In shape: 128, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 128.\n",
      "In shape: 128, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 128.\n",
      "In shape: 128, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 128.\n",
      "In shape: 128, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 128.\n",
      "In shape: 128, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 128.\n",
      "In shape: 128, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 128.\n",
      "In shape: 128, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 128.\n",
      "In shape: 128, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 128.\n",
      "In shape: 128, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 128.\n",
      "In shape: 128, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 128.\n",
      "In shape: 128, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 128.\n",
      "In shape: 128, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 128.\n",
      "In shape: 128, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 128.\n",
      "In shape: 128, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 128.\n",
      "In shape: 128, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 128.\n",
      "In shape: 128, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 128.\n",
      "In shape: 128, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 128.\n",
      "In shape: 128, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 256.\n",
      "In shape: 256, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 256.\n",
      "In shape: 256, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 256.\n",
      "In shape: 256, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 256.\n",
      "In shape: 256, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 256.\n",
      "In shape: 256, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 256.\n",
      "In shape: 256, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 256.\n",
      "In shape: 256, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 256.\n",
      "In shape: 256, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 256.\n",
      "In shape: 256, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 256.\n",
      "In shape: 256, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 256.\n",
      "In shape: 256, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 256.\n",
      "In shape: 256, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 256.\n",
      "In shape: 256, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 256.\n",
      "In shape: 256, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 256.\n",
      "In shape: 256, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 256.\n",
      "In shape: 256, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 256.\n",
      "In shape: 256, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 256.\n",
      "resnet(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(64, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (select): channel_selection()\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
      "  (fc): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "Test set: Accuracy: 8954/10000 (89.5%)\n",
      "\n",
      "Train Epoch: 0 [0/50000 (0.0%)]\tLoss: 0.077649\n",
      "Train Epoch: 0 [6400/50000 (12.8%)]\tLoss: 0.559945\n",
      "Train Epoch: 0 [12800/50000 (25.6%)]\tLoss: 0.460926\n",
      "Train Epoch: 0 [19200/50000 (38.4%)]\tLoss: 0.371354\n",
      "Train Epoch: 0 [25600/50000 (51.2%)]\tLoss: 0.551672\n",
      "Train Epoch: 0 [32000/50000 (63.9%)]\tLoss: 0.430025\n",
      "Train Epoch: 0 [38400/50000 (76.7%)]\tLoss: 0.413606\n",
      "Train Epoch: 0 [44800/50000 (89.5%)]\tLoss: 0.527807\n",
      "\n",
      "Test set: Average loss: 0.6530, Accuracy: 7885/10000 (78.8%)\n",
      "\n",
      "Train Epoch: 1 [0/50000 (0.0%)]\tLoss: 0.534857\n",
      "Train Epoch: 1 [6400/50000 (12.8%)]\tLoss: 0.574345\n",
      "Train Epoch: 1 [12800/50000 (25.6%)]\tLoss: 0.567133\n",
      "Train Epoch: 1 [19200/50000 (38.4%)]\tLoss: 0.412747\n",
      "Train Epoch: 1 [25600/50000 (51.2%)]\tLoss: 0.511763\n",
      "Train Epoch: 1 [32000/50000 (63.9%)]\tLoss: 0.338032\n",
      "Train Epoch: 1 [38400/50000 (76.7%)]\tLoss: 0.323156\n",
      "Train Epoch: 1 [44800/50000 (89.5%)]\tLoss: 0.275962\n",
      "\n",
      "Test set: Average loss: 0.5882, Accuracy: 8033/10000 (80.3%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0.0%)]\tLoss: 0.435044\n",
      "Train Epoch: 2 [6400/50000 (12.8%)]\tLoss: 0.421266\n",
      "Train Epoch: 2 [12800/50000 (25.6%)]\tLoss: 0.480113\n",
      "Train Epoch: 2 [19200/50000 (38.4%)]\tLoss: 0.348041\n",
      "Train Epoch: 2 [25600/50000 (51.2%)]\tLoss: 0.618163\n",
      "Train Epoch: 2 [32000/50000 (63.9%)]\tLoss: 0.702415\n",
      "Train Epoch: 2 [38400/50000 (76.7%)]\tLoss: 0.626415\n",
      "Train Epoch: 2 [44800/50000 (89.5%)]\tLoss: 0.445983\n",
      "\n",
      "Test set: Average loss: 0.7280, Accuracy: 7632/10000 (76.3%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0.0%)]\tLoss: 0.517569\n",
      "Train Epoch: 3 [6400/50000 (12.8%)]\tLoss: 0.421185\n",
      "Train Epoch: 3 [12800/50000 (25.6%)]\tLoss: 0.465402\n",
      "Train Epoch: 3 [19200/50000 (38.4%)]\tLoss: 0.645563\n",
      "Train Epoch: 3 [25600/50000 (51.2%)]\tLoss: 0.450299\n",
      "Train Epoch: 3 [32000/50000 (63.9%)]\tLoss: 0.492708\n",
      "Train Epoch: 3 [38400/50000 (76.7%)]\tLoss: 0.556276\n",
      "Train Epoch: 3 [44800/50000 (89.5%)]\tLoss: 0.447140\n",
      "\n",
      "Test set: Average loss: 0.5627, Accuracy: 8127/10000 (81.3%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0.0%)]\tLoss: 0.468130\n",
      "Train Epoch: 4 [6400/50000 (12.8%)]\tLoss: 0.452065\n",
      "Train Epoch: 4 [12800/50000 (25.6%)]\tLoss: 0.619324\n",
      "Train Epoch: 4 [19200/50000 (38.4%)]\tLoss: 0.833520\n",
      "Train Epoch: 4 [25600/50000 (51.2%)]\tLoss: 0.383330\n",
      "Train Epoch: 4 [32000/50000 (63.9%)]\tLoss: 0.393896\n",
      "Train Epoch: 4 [38400/50000 (76.7%)]\tLoss: 0.531016\n",
      "Train Epoch: 4 [44800/50000 (89.5%)]\tLoss: 0.530914\n",
      "\n",
      "Test set: Average loss: 0.5867, Accuracy: 8090/10000 (80.9%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0.0%)]\tLoss: 0.302758\n",
      "Train Epoch: 5 [6400/50000 (12.8%)]\tLoss: 0.488150\n",
      "Train Epoch: 5 [12800/50000 (25.6%)]\tLoss: 0.444730\n",
      "Train Epoch: 5 [19200/50000 (38.4%)]\tLoss: 0.474647\n",
      "Train Epoch: 5 [25600/50000 (51.2%)]\tLoss: 0.530173\n",
      "Train Epoch: 5 [32000/50000 (63.9%)]\tLoss: 0.349943\n",
      "Train Epoch: 5 [38400/50000 (76.7%)]\tLoss: 0.284096\n",
      "Train Epoch: 5 [44800/50000 (89.5%)]\tLoss: 0.628285\n",
      "\n",
      "Test set: Average loss: 0.5816, Accuracy: 8033/10000 (80.3%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0.0%)]\tLoss: 0.450490\n",
      "Train Epoch: 6 [6400/50000 (12.8%)]\tLoss: 0.481130\n",
      "Train Epoch: 6 [12800/50000 (25.6%)]\tLoss: 0.260234\n",
      "Train Epoch: 6 [19200/50000 (38.4%)]\tLoss: 0.306318\n",
      "Train Epoch: 6 [25600/50000 (51.2%)]\tLoss: 0.453245\n",
      "Train Epoch: 6 [32000/50000 (63.9%)]\tLoss: 0.344387\n",
      "Train Epoch: 6 [38400/50000 (76.7%)]\tLoss: 0.400293\n",
      "Train Epoch: 6 [44800/50000 (89.5%)]\tLoss: 0.463039\n",
      "\n",
      "Test set: Average loss: 0.5015, Accuracy: 8343/10000 (83.4%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0.0%)]\tLoss: 0.456654\n",
      "Train Epoch: 7 [6400/50000 (12.8%)]\tLoss: 0.396609\n",
      "Train Epoch: 7 [12800/50000 (25.6%)]\tLoss: 0.236506\n",
      "Train Epoch: 7 [19200/50000 (38.4%)]\tLoss: 0.526992\n",
      "Train Epoch: 7 [25600/50000 (51.2%)]\tLoss: 0.415151\n",
      "Train Epoch: 7 [32000/50000 (63.9%)]\tLoss: 0.574859\n",
      "Train Epoch: 7 [38400/50000 (76.7%)]\tLoss: 0.409969\n",
      "Train Epoch: 7 [44800/50000 (89.5%)]\tLoss: 0.478768\n",
      "\n",
      "Test set: Average loss: 0.4819, Accuracy: 8395/10000 (83.9%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0.0%)]\tLoss: 0.464146\n",
      "Train Epoch: 8 [6400/50000 (12.8%)]\tLoss: 0.332691\n",
      "Train Epoch: 8 [12800/50000 (25.6%)]\tLoss: 0.322705\n",
      "Train Epoch: 8 [19200/50000 (38.4%)]\tLoss: 0.376052\n",
      "Train Epoch: 8 [25600/50000 (51.2%)]\tLoss: 0.463623\n",
      "Train Epoch: 8 [32000/50000 (63.9%)]\tLoss: 0.244098\n",
      "Train Epoch: 8 [38400/50000 (76.7%)]\tLoss: 0.522153\n",
      "Train Epoch: 8 [44800/50000 (89.5%)]\tLoss: 0.298290\n",
      "\n",
      "Test set: Average loss: 0.5939, Accuracy: 8116/10000 (81.2%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0.0%)]\tLoss: 0.384278\n",
      "Train Epoch: 9 [6400/50000 (12.8%)]\tLoss: 0.221764\n",
      "Train Epoch: 9 [12800/50000 (25.6%)]\tLoss: 0.331125\n",
      "Train Epoch: 9 [19200/50000 (38.4%)]\tLoss: 0.395194\n",
      "Train Epoch: 9 [25600/50000 (51.2%)]\tLoss: 0.481848\n",
      "Train Epoch: 9 [32000/50000 (63.9%)]\tLoss: 0.281377\n",
      "Train Epoch: 9 [38400/50000 (76.7%)]\tLoss: 0.283291\n",
      "Train Epoch: 9 [44800/50000 (89.5%)]\tLoss: 0.274841\n",
      "\n",
      "Test set: Average loss: 0.5126, Accuracy: 8369/10000 (83.7%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0.0%)]\tLoss: 0.231419\n",
      "Train Epoch: 10 [6400/50000 (12.8%)]\tLoss: 0.378268\n",
      "Train Epoch: 10 [12800/50000 (25.6%)]\tLoss: 0.306844\n",
      "Train Epoch: 10 [19200/50000 (38.4%)]\tLoss: 0.259073\n",
      "Train Epoch: 10 [25600/50000 (51.2%)]\tLoss: 0.216172\n",
      "Train Epoch: 10 [32000/50000 (63.9%)]\tLoss: 0.126956\n",
      "Train Epoch: 10 [38400/50000 (76.7%)]\tLoss: 0.109515\n",
      "Train Epoch: 10 [44800/50000 (89.5%)]\tLoss: 0.326911\n",
      "\n",
      "Test set: Average loss: 0.2704, Accuracy: 9074/10000 (90.7%)\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0.0%)]\tLoss: 0.236858\n",
      "Train Epoch: 11 [6400/50000 (12.8%)]\tLoss: 0.258378\n",
      "Train Epoch: 11 [12800/50000 (25.6%)]\tLoss: 0.289388\n",
      "Train Epoch: 11 [19200/50000 (38.4%)]\tLoss: 0.139201\n",
      "Train Epoch: 11 [25600/50000 (51.2%)]\tLoss: 0.148029\n",
      "Train Epoch: 11 [32000/50000 (63.9%)]\tLoss: 0.184327\n",
      "Train Epoch: 11 [38400/50000 (76.7%)]\tLoss: 0.376749\n",
      "Train Epoch: 11 [44800/50000 (89.5%)]\tLoss: 0.249688\n",
      "\n",
      "Test set: Average loss: 0.2580, Accuracy: 9136/10000 (91.4%)\n",
      "\n",
      "Train Epoch: 12 [0/50000 (0.0%)]\tLoss: 0.251920\n",
      "Train Epoch: 12 [6400/50000 (12.8%)]\tLoss: 0.216211\n",
      "Train Epoch: 12 [12800/50000 (25.6%)]\tLoss: 0.246441\n",
      "Train Epoch: 12 [19200/50000 (38.4%)]\tLoss: 0.187502\n",
      "Train Epoch: 12 [25600/50000 (51.2%)]\tLoss: 0.150259\n",
      "Train Epoch: 12 [32000/50000 (63.9%)]\tLoss: 0.143752\n",
      "Train Epoch: 12 [38400/50000 (76.7%)]\tLoss: 0.149562\n",
      "Train Epoch: 12 [44800/50000 (89.5%)]\tLoss: 0.171771\n",
      "\n",
      "Test set: Average loss: 0.2611, Accuracy: 9138/10000 (91.4%)\n",
      "\n",
      "Train Epoch: 13 [0/50000 (0.0%)]\tLoss: 0.124448\n",
      "Train Epoch: 13 [6400/50000 (12.8%)]\tLoss: 0.314643\n",
      "Train Epoch: 13 [12800/50000 (25.6%)]\tLoss: 0.224339\n",
      "Train Epoch: 13 [19200/50000 (38.4%)]\tLoss: 0.270879\n",
      "Train Epoch: 13 [25600/50000 (51.2%)]\tLoss: 0.288758\n",
      "Train Epoch: 13 [32000/50000 (63.9%)]\tLoss: 0.160875\n",
      "Train Epoch: 13 [38400/50000 (76.7%)]\tLoss: 0.111892\n",
      "Train Epoch: 13 [44800/50000 (89.5%)]\tLoss: 0.185660\n",
      "\n",
      "Test set: Average loss: 0.2494, Accuracy: 9177/10000 (91.8%)\n",
      "\n",
      "Train Epoch: 14 [0/50000 (0.0%)]\tLoss: 0.121646\n",
      "Train Epoch: 14 [6400/50000 (12.8%)]\tLoss: 0.115760\n",
      "Train Epoch: 14 [12800/50000 (25.6%)]\tLoss: 0.206141\n",
      "Train Epoch: 14 [19200/50000 (38.4%)]\tLoss: 0.143503\n",
      "Train Epoch: 14 [25600/50000 (51.2%)]\tLoss: 0.132842\n",
      "Train Epoch: 14 [32000/50000 (63.9%)]\tLoss: 0.209755\n",
      "Train Epoch: 14 [38400/50000 (76.7%)]\tLoss: 0.075711\n",
      "Train Epoch: 14 [44800/50000 (89.5%)]\tLoss: 0.274365\n",
      "\n",
      "Test set: Average loss: 0.2504, Accuracy: 9169/10000 (91.7%)\n",
      "\n",
      "Train Epoch: 15 [0/50000 (0.0%)]\tLoss: 0.203565\n",
      "Train Epoch: 15 [6400/50000 (12.8%)]\tLoss: 0.167354\n",
      "Train Epoch: 15 [12800/50000 (25.6%)]\tLoss: 0.149962\n",
      "Train Epoch: 15 [19200/50000 (38.4%)]\tLoss: 0.310344\n",
      "Train Epoch: 15 [25600/50000 (51.2%)]\tLoss: 0.162912\n",
      "Train Epoch: 15 [32000/50000 (63.9%)]\tLoss: 0.166970\n",
      "Train Epoch: 15 [38400/50000 (76.7%)]\tLoss: 0.037914\n",
      "Train Epoch: 15 [44800/50000 (89.5%)]\tLoss: 0.127847\n",
      "\n",
      "Test set: Average loss: 0.2428, Accuracy: 9214/10000 (92.1%)\n",
      "\n",
      "Train Epoch: 16 [0/50000 (0.0%)]\tLoss: 0.193920\n",
      "Train Epoch: 16 [6400/50000 (12.8%)]\tLoss: 0.115809\n",
      "Train Epoch: 16 [12800/50000 (25.6%)]\tLoss: 0.098208\n",
      "Train Epoch: 16 [19200/50000 (38.4%)]\tLoss: 0.197693\n",
      "Train Epoch: 16 [25600/50000 (51.2%)]\tLoss: 0.082766\n",
      "Train Epoch: 16 [32000/50000 (63.9%)]\tLoss: 0.082284\n",
      "Train Epoch: 16 [38400/50000 (76.7%)]\tLoss: 0.109343\n",
      "Train Epoch: 16 [44800/50000 (89.5%)]\tLoss: 0.115204\n",
      "\n",
      "Test set: Average loss: 0.2409, Accuracy: 9191/10000 (91.9%)\n",
      "\n",
      "Train Epoch: 17 [0/50000 (0.0%)]\tLoss: 0.084364\n",
      "Train Epoch: 17 [6400/50000 (12.8%)]\tLoss: 0.097658\n",
      "Train Epoch: 17 [12800/50000 (25.6%)]\tLoss: 0.068406\n",
      "Train Epoch: 17 [19200/50000 (38.4%)]\tLoss: 0.190739\n",
      "Train Epoch: 17 [25600/50000 (51.2%)]\tLoss: 0.152494\n",
      "Train Epoch: 17 [32000/50000 (63.9%)]\tLoss: 0.074839\n",
      "Train Epoch: 17 [38400/50000 (76.7%)]\tLoss: 0.125468\n",
      "Train Epoch: 17 [44800/50000 (89.5%)]\tLoss: 0.181437\n",
      "\n",
      "Test set: Average loss: 0.2390, Accuracy: 9212/10000 (92.1%)\n",
      "\n",
      "Train Epoch: 18 [0/50000 (0.0%)]\tLoss: 0.081580\n",
      "Train Epoch: 18 [6400/50000 (12.8%)]\tLoss: 0.166551\n",
      "Train Epoch: 18 [12800/50000 (25.6%)]\tLoss: 0.211344\n",
      "Train Epoch: 18 [19200/50000 (38.4%)]\tLoss: 0.229602\n",
      "Train Epoch: 18 [25600/50000 (51.2%)]\tLoss: 0.185364\n",
      "Train Epoch: 18 [32000/50000 (63.9%)]\tLoss: 0.191571\n",
      "Train Epoch: 18 [38400/50000 (76.7%)]\tLoss: 0.118929\n",
      "Train Epoch: 18 [44800/50000 (89.5%)]\tLoss: 0.110733\n",
      "\n",
      "Test set: Average loss: 0.2384, Accuracy: 9224/10000 (92.2%)\n",
      "\n",
      "Train Epoch: 19 [0/50000 (0.0%)]\tLoss: 0.098550\n",
      "Train Epoch: 19 [6400/50000 (12.8%)]\tLoss: 0.058360\n",
      "Train Epoch: 19 [12800/50000 (25.6%)]\tLoss: 0.177055\n",
      "Train Epoch: 19 [19200/50000 (38.4%)]\tLoss: 0.192242\n",
      "Train Epoch: 19 [25600/50000 (51.2%)]\tLoss: 0.102835\n",
      "Train Epoch: 19 [32000/50000 (63.9%)]\tLoss: 0.193823\n",
      "Train Epoch: 19 [38400/50000 (76.7%)]\tLoss: 0.079980\n",
      "Train Epoch: 19 [44800/50000 (89.5%)]\tLoss: 0.091392\n",
      "\n",
      "Test set: Average loss: 0.2379, Accuracy: 9228/10000 (92.3%)\n",
      "\n",
      "Best accuracy: tensor(0.9228)\n",
      "Number of parameters: 1711128\n",
      "Average Time taken: 140.61624838113784\n",
      "Iteration:  2 Percent:  0.1\n",
      "=> loading checkpoint '/kaggle/working/model_best.pth.tar'\n",
      "=> loaded checkpoint '/kaggle/working/model_best.pth.tar' (epoch 19) Prec1: 0.895400\n",
      "layer index: 4 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 7 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 9 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 15 \t total channel: 64 \t remaining channel: 48\n",
      "layer index: 18 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 20 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 24 \t total channel: 64 \t remaining channel: 47\n",
      "layer index: 27 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 29 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 33 \t total channel: 64 \t remaining channel: 49\n",
      "layer index: 36 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 38 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 42 \t total channel: 64 \t remaining channel: 51\n",
      "layer index: 45 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 47 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 51 \t total channel: 64 \t remaining channel: 42\n",
      "layer index: 54 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 56 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 60 \t total channel: 64 \t remaining channel: 46\n",
      "layer index: 63 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 65 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 69 \t total channel: 64 \t remaining channel: 44\n",
      "layer index: 72 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 74 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 78 \t total channel: 64 \t remaining channel: 45\n",
      "layer index: 81 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 83 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 87 \t total channel: 64 \t remaining channel: 55\n",
      "layer index: 90 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 92 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 96 \t total channel: 64 \t remaining channel: 52\n",
      "layer index: 99 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 101 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 105 \t total channel: 64 \t remaining channel: 48\n",
      "layer index: 108 \t total channel: 16 \t remaining channel: 12\n",
      "layer index: 110 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 114 \t total channel: 64 \t remaining channel: 56\n",
      "layer index: 117 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 119 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 123 \t total channel: 64 \t remaining channel: 46\n",
      "layer index: 126 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 128 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 132 \t total channel: 64 \t remaining channel: 51\n",
      "layer index: 135 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 137 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 141 \t total channel: 64 \t remaining channel: 50\n",
      "layer index: 144 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 146 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 150 \t total channel: 64 \t remaining channel: 55\n",
      "layer index: 153 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 155 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 159 \t total channel: 64 \t remaining channel: 52\n",
      "layer index: 162 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 164 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 169 \t total channel: 64 \t remaining channel: 60\n",
      "layer index: 172 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 174 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 180 \t total channel: 128 \t remaining channel: 109\n",
      "layer index: 183 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 185 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 189 \t total channel: 128 \t remaining channel: 113\n",
      "layer index: 192 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 194 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 198 \t total channel: 128 \t remaining channel: 110\n",
      "layer index: 201 \t total channel: 32 \t remaining channel: 31\n",
      "layer index: 203 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 207 \t total channel: 128 \t remaining channel: 104\n",
      "layer index: 210 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 212 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 216 \t total channel: 128 \t remaining channel: 112\n",
      "layer index: 219 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 221 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 225 \t total channel: 128 \t remaining channel: 112\n",
      "layer index: 228 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 230 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 234 \t total channel: 128 \t remaining channel: 108\n",
      "layer index: 237 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 239 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 243 \t total channel: 128 \t remaining channel: 109\n",
      "layer index: 246 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 248 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 252 \t total channel: 128 \t remaining channel: 115\n",
      "layer index: 255 \t total channel: 32 \t remaining channel: 31\n",
      "layer index: 257 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 261 \t total channel: 128 \t remaining channel: 109\n",
      "layer index: 264 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 266 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 270 \t total channel: 128 \t remaining channel: 112\n",
      "layer index: 273 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 275 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 279 \t total channel: 128 \t remaining channel: 111\n",
      "layer index: 282 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 284 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 288 \t total channel: 128 \t remaining channel: 108\n",
      "layer index: 291 \t total channel: 32 \t remaining channel: 31\n",
      "layer index: 293 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 297 \t total channel: 128 \t remaining channel: 107\n",
      "layer index: 300 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 302 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 306 \t total channel: 128 \t remaining channel: 108\n",
      "layer index: 309 \t total channel: 32 \t remaining channel: 31\n",
      "layer index: 311 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 315 \t total channel: 128 \t remaining channel: 110\n",
      "layer index: 318 \t total channel: 32 \t remaining channel: 31\n",
      "layer index: 320 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 324 \t total channel: 128 \t remaining channel: 106\n",
      "layer index: 327 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 329 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 334 \t total channel: 128 \t remaining channel: 116\n",
      "layer index: 337 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 339 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 345 \t total channel: 256 \t remaining channel: 213\n",
      "layer index: 348 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 350 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 354 \t total channel: 256 \t remaining channel: 223\n",
      "layer index: 357 \t total channel: 64 \t remaining channel: 62\n",
      "layer index: 359 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 363 \t total channel: 256 \t remaining channel: 226\n",
      "layer index: 366 \t total channel: 64 \t remaining channel: 63\n",
      "layer index: 368 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 372 \t total channel: 256 \t remaining channel: 222\n",
      "layer index: 375 \t total channel: 64 \t remaining channel: 63\n",
      "layer index: 377 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 381 \t total channel: 256 \t remaining channel: 219\n",
      "layer index: 384 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 386 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 390 \t total channel: 256 \t remaining channel: 218\n",
      "layer index: 393 \t total channel: 64 \t remaining channel: 63\n",
      "layer index: 395 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 399 \t total channel: 256 \t remaining channel: 228\n",
      "layer index: 402 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 404 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 408 \t total channel: 256 \t remaining channel: 226\n",
      "layer index: 411 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 413 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 417 \t total channel: 256 \t remaining channel: 212\n",
      "layer index: 420 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 422 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 426 \t total channel: 256 \t remaining channel: 213\n",
      "layer index: 429 \t total channel: 64 \t remaining channel: 61\n",
      "layer index: 431 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 435 \t total channel: 256 \t remaining channel: 229\n",
      "layer index: 438 \t total channel: 64 \t remaining channel: 63\n",
      "layer index: 440 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 444 \t total channel: 256 \t remaining channel: 230\n",
      "layer index: 447 \t total channel: 64 \t remaining channel: 61\n",
      "layer index: 449 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 453 \t total channel: 256 \t remaining channel: 226\n",
      "layer index: 456 \t total channel: 64 \t remaining channel: 63\n",
      "layer index: 458 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 462 \t total channel: 256 \t remaining channel: 217\n",
      "layer index: 465 \t total channel: 64 \t remaining channel: 61\n",
      "layer index: 467 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 471 \t total channel: 256 \t remaining channel: 230\n",
      "layer index: 474 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 476 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 480 \t total channel: 256 \t remaining channel: 222\n",
      "layer index: 483 \t total channel: 64 \t remaining channel: 63\n",
      "layer index: 485 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 489 \t total channel: 256 \t remaining channel: 220\n",
      "layer index: 492 \t total channel: 64 \t remaining channel: 60\n",
      "layer index: 494 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 497 \t total channel: 256 \t remaining channel: 248\n",
      "Pre-processing Successful!\n",
      "\n",
      "Test set: Accuracy: 8871/10000 (88.7%)\n",
      "\n",
      "Cfg:\n",
      "[16, 15, 16, 48, 15, 16, 47, 16, 16, 49, 15, 16, 51, 15, 16, 42, 16, 16, 46, 16, 14, 44, 15, 16, 45, 15, 15, 55, 15, 16, 52, 16, 16, 48, 12, 16, 56, 15, 14, 46, 15, 16, 51, 15, 16, 50, 16, 16, 55, 15, 16, 52, 16, 16, 60, 32, 32, 109, 32, 32, 113, 32, 32, 110, 31, 32, 104, 32, 32, 112, 32, 32, 112, 32, 32, 108, 32, 32, 109, 32, 32, 115, 31, 32, 109, 32, 32, 112, 32, 32, 111, 32, 32, 108, 31, 32, 107, 32, 32, 108, 31, 32, 110, 31, 32, 106, 32, 32, 116, 64, 64, 213, 64, 64, 223, 62, 64, 226, 63, 64, 222, 63, 64, 219, 64, 64, 218, 63, 64, 228, 64, 64, 226, 64, 64, 212, 64, 64, 213, 61, 64, 229, 63, 64, 230, 61, 64, 226, 63, 64, 217, 61, 64, 230, 64, 64, 222, 63, 64, 220, 60, 64, 248]\n",
      "In shape: 16, Out shape 15.\n",
      "In shape: 15, Out shape 16.\n",
      "In shape: 16, Out shape 48.\n",
      "In shape: 48, Out shape 15.\n",
      "In shape: 15, Out shape 16.\n",
      "In shape: 16, Out shape 47.\n",
      "In shape: 47, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 49.\n",
      "In shape: 49, Out shape 15.\n",
      "In shape: 15, Out shape 16.\n",
      "In shape: 16, Out shape 51.\n",
      "In shape: 51, Out shape 15.\n",
      "In shape: 15, Out shape 16.\n",
      "In shape: 16, Out shape 42.\n",
      "In shape: 42, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 46.\n",
      "In shape: 46, Out shape 16.\n",
      "In shape: 16, Out shape 14.\n",
      "In shape: 14, Out shape 44.\n",
      "In shape: 44, Out shape 15.\n",
      "In shape: 15, Out shape 16.\n",
      "In shape: 16, Out shape 45.\n",
      "In shape: 45, Out shape 15.\n",
      "In shape: 15, Out shape 15.\n",
      "In shape: 15, Out shape 55.\n",
      "In shape: 55, Out shape 15.\n",
      "In shape: 15, Out shape 16.\n",
      "In shape: 16, Out shape 52.\n",
      "In shape: 52, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 48.\n",
      "In shape: 48, Out shape 12.\n",
      "In shape: 12, Out shape 16.\n",
      "In shape: 16, Out shape 56.\n",
      "In shape: 56, Out shape 15.\n",
      "In shape: 15, Out shape 14.\n",
      "In shape: 14, Out shape 46.\n",
      "In shape: 46, Out shape 15.\n",
      "In shape: 15, Out shape 16.\n",
      "In shape: 16, Out shape 51.\n",
      "In shape: 51, Out shape 15.\n",
      "In shape: 15, Out shape 16.\n",
      "In shape: 16, Out shape 50.\n",
      "In shape: 50, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 55.\n",
      "In shape: 55, Out shape 15.\n",
      "In shape: 15, Out shape 16.\n",
      "In shape: 16, Out shape 52.\n",
      "In shape: 52, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 60.\n",
      "In shape: 60, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 109.\n",
      "In shape: 109, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 113.\n",
      "In shape: 113, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 110.\n",
      "In shape: 110, Out shape 31.\n",
      "In shape: 31, Out shape 32.\n",
      "In shape: 32, Out shape 104.\n",
      "In shape: 104, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 112.\n",
      "In shape: 112, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 112.\n",
      "In shape: 112, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 108.\n",
      "In shape: 108, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 109.\n",
      "In shape: 109, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 115.\n",
      "In shape: 115, Out shape 31.\n",
      "In shape: 31, Out shape 32.\n",
      "In shape: 32, Out shape 109.\n",
      "In shape: 109, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 112.\n",
      "In shape: 112, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 111.\n",
      "In shape: 111, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 108.\n",
      "In shape: 108, Out shape 31.\n",
      "In shape: 31, Out shape 32.\n",
      "In shape: 32, Out shape 107.\n",
      "In shape: 107, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 108.\n",
      "In shape: 108, Out shape 31.\n",
      "In shape: 31, Out shape 32.\n",
      "In shape: 32, Out shape 110.\n",
      "In shape: 110, Out shape 31.\n",
      "In shape: 31, Out shape 32.\n",
      "In shape: 32, Out shape 106.\n",
      "In shape: 106, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 116.\n",
      "In shape: 116, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 213.\n",
      "In shape: 213, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 223.\n",
      "In shape: 223, Out shape 62.\n",
      "In shape: 62, Out shape 64.\n",
      "In shape: 64, Out shape 226.\n",
      "In shape: 226, Out shape 63.\n",
      "In shape: 63, Out shape 64.\n",
      "In shape: 64, Out shape 222.\n",
      "In shape: 222, Out shape 63.\n",
      "In shape: 63, Out shape 64.\n",
      "In shape: 64, Out shape 219.\n",
      "In shape: 219, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 218.\n",
      "In shape: 218, Out shape 63.\n",
      "In shape: 63, Out shape 64.\n",
      "In shape: 64, Out shape 228.\n",
      "In shape: 228, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 226.\n",
      "In shape: 226, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 212.\n",
      "In shape: 212, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 213.\n",
      "In shape: 213, Out shape 61.\n",
      "In shape: 61, Out shape 64.\n",
      "In shape: 64, Out shape 229.\n",
      "In shape: 229, Out shape 63.\n",
      "In shape: 63, Out shape 64.\n",
      "In shape: 64, Out shape 230.\n",
      "In shape: 230, Out shape 61.\n",
      "In shape: 61, Out shape 64.\n",
      "In shape: 64, Out shape 226.\n",
      "In shape: 226, Out shape 63.\n",
      "In shape: 63, Out shape 64.\n",
      "In shape: 64, Out shape 217.\n",
      "In shape: 217, Out shape 61.\n",
      "In shape: 61, Out shape 64.\n",
      "In shape: 64, Out shape 230.\n",
      "In shape: 230, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 222.\n",
      "In shape: 222, Out shape 63.\n",
      "In shape: 63, Out shape 64.\n",
      "In shape: 64, Out shape 220.\n",
      "In shape: 220, Out shape 60.\n",
      "In shape: 60, Out shape 64.\n",
      "In shape: 64, Out shape 248.\n",
      "resnet(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(16, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(48, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(47, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(49, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(51, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(42, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(46, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(14, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(44, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(45, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(15, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(55, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(52, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(12, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(56, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(14, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(46, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(51, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(50, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(55, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(52, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(60, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(109, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(113, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(110, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(31, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(104, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(112, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(112, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(108, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(109, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(115, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(31, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(109, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(112, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(111, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(108, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(31, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(107, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(108, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(31, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(110, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(31, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(106, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(116, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(213, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(223, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(62, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(226, 63, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(63, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(222, 63, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(63, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(219, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(218, 63, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(63, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(228, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(226, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(212, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(213, 61, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(61, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(229, 63, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(63, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(230, 61, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(61, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(226, 63, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(63, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(217, 61, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(61, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(230, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(222, 63, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(63, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(220, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(60, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (select): channel_selection()\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
      "  (fc): Linear(in_features=248, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "Test set: Accuracy: 8871/10000 (88.7%)\n",
      "\n",
      "Train Epoch: 0 [0/50000 (0.0%)]\tLoss: 0.382508\n",
      "Train Epoch: 0 [6400/50000 (12.8%)]\tLoss: 0.459016\n",
      "Train Epoch: 0 [12800/50000 (25.6%)]\tLoss: 0.485131\n",
      "Train Epoch: 0 [19200/50000 (38.4%)]\tLoss: 0.700975\n",
      "Train Epoch: 0 [25600/50000 (51.2%)]\tLoss: 0.335091\n",
      "Train Epoch: 0 [32000/50000 (63.9%)]\tLoss: 0.558058\n",
      "Train Epoch: 0 [38400/50000 (76.7%)]\tLoss: 0.391881\n",
      "Train Epoch: 0 [44800/50000 (89.5%)]\tLoss: 0.424167\n",
      "\n",
      "Test set: Average loss: 0.6605, Accuracy: 7794/10000 (77.9%)\n",
      "\n",
      "Train Epoch: 1 [0/50000 (0.0%)]\tLoss: 0.594193\n",
      "Train Epoch: 1 [6400/50000 (12.8%)]\tLoss: 0.538956\n",
      "Train Epoch: 1 [12800/50000 (25.6%)]\tLoss: 0.455792\n",
      "Train Epoch: 1 [19200/50000 (38.4%)]\tLoss: 0.649383\n",
      "Train Epoch: 1 [25600/50000 (51.2%)]\tLoss: 0.419262\n",
      "Train Epoch: 1 [32000/50000 (63.9%)]\tLoss: 0.507428\n",
      "Train Epoch: 1 [38400/50000 (76.7%)]\tLoss: 0.354354\n",
      "Train Epoch: 1 [44800/50000 (89.5%)]\tLoss: 0.428712\n",
      "\n",
      "Test set: Average loss: 0.5680, Accuracy: 8102/10000 (81.0%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0.0%)]\tLoss: 0.366187\n",
      "Train Epoch: 2 [6400/50000 (12.8%)]\tLoss: 0.449583\n",
      "Train Epoch: 2 [12800/50000 (25.6%)]\tLoss: 0.453175\n",
      "Train Epoch: 2 [19200/50000 (38.4%)]\tLoss: 0.483829\n",
      "Train Epoch: 2 [25600/50000 (51.2%)]\tLoss: 0.583131\n",
      "Train Epoch: 2 [32000/50000 (63.9%)]\tLoss: 0.504356\n",
      "Train Epoch: 2 [38400/50000 (76.7%)]\tLoss: 0.358991\n",
      "Train Epoch: 2 [44800/50000 (89.5%)]\tLoss: 0.542172\n",
      "\n",
      "Test set: Average loss: 0.5185, Accuracy: 8273/10000 (82.7%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0.0%)]\tLoss: 0.460695\n",
      "Train Epoch: 3 [6400/50000 (12.8%)]\tLoss: 0.487435\n",
      "Train Epoch: 3 [12800/50000 (25.6%)]\tLoss: 0.515102\n",
      "Train Epoch: 3 [19200/50000 (38.4%)]\tLoss: 0.414446\n",
      "Train Epoch: 3 [25600/50000 (51.2%)]\tLoss: 0.552111\n",
      "Train Epoch: 3 [32000/50000 (63.9%)]\tLoss: 0.456141\n",
      "Train Epoch: 3 [38400/50000 (76.7%)]\tLoss: 0.304615\n",
      "Train Epoch: 3 [44800/50000 (89.5%)]\tLoss: 0.596050\n",
      "\n",
      "Test set: Average loss: 0.5852, Accuracy: 8178/10000 (81.8%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0.0%)]\tLoss: 0.774790\n",
      "Train Epoch: 4 [6400/50000 (12.8%)]\tLoss: 0.608038\n",
      "Train Epoch: 4 [12800/50000 (25.6%)]\tLoss: 0.311291\n",
      "Train Epoch: 4 [19200/50000 (38.4%)]\tLoss: 0.519332\n",
      "Train Epoch: 4 [25600/50000 (51.2%)]\tLoss: 0.382523\n",
      "Train Epoch: 4 [32000/50000 (63.9%)]\tLoss: 0.516405\n",
      "Train Epoch: 4 [38400/50000 (76.7%)]\tLoss: 0.309808\n",
      "Train Epoch: 4 [44800/50000 (89.5%)]\tLoss: 0.406504\n",
      "\n",
      "Test set: Average loss: 0.5116, Accuracy: 8326/10000 (83.3%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0.0%)]\tLoss: 0.730515\n",
      "Train Epoch: 5 [6400/50000 (12.8%)]\tLoss: 0.567765\n",
      "Train Epoch: 5 [12800/50000 (25.6%)]\tLoss: 0.370956\n",
      "Train Epoch: 5 [19200/50000 (38.4%)]\tLoss: 0.253715\n",
      "Train Epoch: 5 [25600/50000 (51.2%)]\tLoss: 0.485820\n",
      "Train Epoch: 5 [32000/50000 (63.9%)]\tLoss: 0.285739\n",
      "Train Epoch: 5 [38400/50000 (76.7%)]\tLoss: 0.436828\n",
      "Train Epoch: 5 [44800/50000 (89.5%)]\tLoss: 0.594578\n",
      "\n",
      "Test set: Average loss: 0.6217, Accuracy: 7977/10000 (79.8%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0.0%)]\tLoss: 0.400689\n",
      "Train Epoch: 6 [6400/50000 (12.8%)]\tLoss: 0.416646\n",
      "Train Epoch: 6 [12800/50000 (25.6%)]\tLoss: 0.429378\n",
      "Train Epoch: 6 [19200/50000 (38.4%)]\tLoss: 0.238157\n",
      "Train Epoch: 6 [25600/50000 (51.2%)]\tLoss: 0.401616\n",
      "Train Epoch: 6 [32000/50000 (63.9%)]\tLoss: 0.332815\n",
      "Train Epoch: 6 [38400/50000 (76.7%)]\tLoss: 0.405749\n",
      "Train Epoch: 6 [44800/50000 (89.5%)]\tLoss: 0.464830\n",
      "\n",
      "Test set: Average loss: 0.4938, Accuracy: 8321/10000 (83.2%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0.0%)]\tLoss: 0.686223\n",
      "Train Epoch: 7 [6400/50000 (12.8%)]\tLoss: 0.350221\n",
      "Train Epoch: 7 [12800/50000 (25.6%)]\tLoss: 0.364439\n",
      "Train Epoch: 7 [19200/50000 (38.4%)]\tLoss: 0.485712\n",
      "Train Epoch: 7 [25600/50000 (51.2%)]\tLoss: 0.322752\n",
      "Train Epoch: 7 [32000/50000 (63.9%)]\tLoss: 0.434964\n",
      "Train Epoch: 7 [38400/50000 (76.7%)]\tLoss: 0.545131\n",
      "Train Epoch: 7 [44800/50000 (89.5%)]\tLoss: 0.561723\n",
      "\n",
      "Test set: Average loss: 0.6374, Accuracy: 7972/10000 (79.7%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0.0%)]\tLoss: 0.515121\n",
      "Train Epoch: 8 [6400/50000 (12.8%)]\tLoss: 0.637251\n",
      "Train Epoch: 8 [12800/50000 (25.6%)]\tLoss: 0.447564\n",
      "Train Epoch: 8 [19200/50000 (38.4%)]\tLoss: 0.296917\n",
      "Train Epoch: 8 [25600/50000 (51.2%)]\tLoss: 0.590280\n",
      "Train Epoch: 8 [32000/50000 (63.9%)]\tLoss: 0.367797\n",
      "Train Epoch: 8 [38400/50000 (76.7%)]\tLoss: 0.332010\n",
      "Train Epoch: 8 [44800/50000 (89.5%)]\tLoss: 0.343703\n",
      "\n",
      "Test set: Average loss: 0.5195, Accuracy: 8312/10000 (83.1%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0.0%)]\tLoss: 0.457009\n",
      "Train Epoch: 9 [6400/50000 (12.8%)]\tLoss: 0.379585\n",
      "Train Epoch: 9 [12800/50000 (25.6%)]\tLoss: 0.376179\n",
      "Train Epoch: 9 [19200/50000 (38.4%)]\tLoss: 0.580227\n",
      "Train Epoch: 9 [25600/50000 (51.2%)]\tLoss: 0.490942\n",
      "Train Epoch: 9 [32000/50000 (63.9%)]\tLoss: 0.332028\n",
      "Train Epoch: 9 [38400/50000 (76.7%)]\tLoss: 0.344967\n",
      "Train Epoch: 9 [44800/50000 (89.5%)]\tLoss: 0.482861\n",
      "\n",
      "Test set: Average loss: 0.4911, Accuracy: 8384/10000 (83.8%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0.0%)]\tLoss: 0.540048\n",
      "Train Epoch: 10 [6400/50000 (12.8%)]\tLoss: 0.235967\n",
      "Train Epoch: 10 [12800/50000 (25.6%)]\tLoss: 0.200042\n",
      "Train Epoch: 10 [19200/50000 (38.4%)]\tLoss: 0.468654\n",
      "Train Epoch: 10 [25600/50000 (51.2%)]\tLoss: 0.223736\n",
      "Train Epoch: 10 [32000/50000 (63.9%)]\tLoss: 0.203089\n",
      "Train Epoch: 10 [38400/50000 (76.7%)]\tLoss: 0.379744\n",
      "Train Epoch: 10 [44800/50000 (89.5%)]\tLoss: 0.256483\n",
      "\n",
      "Test set: Average loss: 0.2720, Accuracy: 9080/10000 (90.8%)\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0.0%)]\tLoss: 0.273305\n",
      "Train Epoch: 11 [6400/50000 (12.8%)]\tLoss: 0.216599\n",
      "Train Epoch: 11 [12800/50000 (25.6%)]\tLoss: 0.207298\n",
      "Train Epoch: 11 [19200/50000 (38.4%)]\tLoss: 0.304561\n",
      "Train Epoch: 11 [25600/50000 (51.2%)]\tLoss: 0.256681\n",
      "Train Epoch: 11 [32000/50000 (63.9%)]\tLoss: 0.223231\n",
      "Train Epoch: 11 [38400/50000 (76.7%)]\tLoss: 0.185902\n",
      "Train Epoch: 11 [44800/50000 (89.5%)]\tLoss: 0.178144\n",
      "\n",
      "Test set: Average loss: 0.2611, Accuracy: 9127/10000 (91.3%)\n",
      "\n",
      "Train Epoch: 12 [0/50000 (0.0%)]\tLoss: 0.216201\n",
      "Train Epoch: 12 [6400/50000 (12.8%)]\tLoss: 0.232794\n",
      "Train Epoch: 12 [12800/50000 (25.6%)]\tLoss: 0.222979\n",
      "Train Epoch: 12 [19200/50000 (38.4%)]\tLoss: 0.181164\n",
      "Train Epoch: 12 [25600/50000 (51.2%)]\tLoss: 0.210140\n",
      "Train Epoch: 12 [32000/50000 (63.9%)]\tLoss: 0.293460\n",
      "Train Epoch: 12 [38400/50000 (76.7%)]\tLoss: 0.240456\n",
      "Train Epoch: 12 [44800/50000 (89.5%)]\tLoss: 0.231686\n",
      "\n",
      "Test set: Average loss: 0.2524, Accuracy: 9181/10000 (91.8%)\n",
      "\n",
      "Train Epoch: 13 [0/50000 (0.0%)]\tLoss: 0.139835\n",
      "Train Epoch: 13 [6400/50000 (12.8%)]\tLoss: 0.161170\n",
      "Train Epoch: 13 [12800/50000 (25.6%)]\tLoss: 0.117026\n",
      "Train Epoch: 13 [19200/50000 (38.4%)]\tLoss: 0.118964\n",
      "Train Epoch: 13 [25600/50000 (51.2%)]\tLoss: 0.199190\n",
      "Train Epoch: 13 [32000/50000 (63.9%)]\tLoss: 0.231728\n",
      "Train Epoch: 13 [38400/50000 (76.7%)]\tLoss: 0.186358\n",
      "Train Epoch: 13 [44800/50000 (89.5%)]\tLoss: 0.059025\n",
      "\n",
      "Test set: Average loss: 0.2484, Accuracy: 9189/10000 (91.9%)\n",
      "\n",
      "Train Epoch: 14 [0/50000 (0.0%)]\tLoss: 0.187755\n",
      "Train Epoch: 14 [6400/50000 (12.8%)]\tLoss: 0.083537\n",
      "Train Epoch: 14 [12800/50000 (25.6%)]\tLoss: 0.116041\n",
      "Train Epoch: 14 [19200/50000 (38.4%)]\tLoss: 0.179268\n",
      "Train Epoch: 14 [25600/50000 (51.2%)]\tLoss: 0.182678\n",
      "Train Epoch: 14 [32000/50000 (63.9%)]\tLoss: 0.210501\n",
      "Train Epoch: 14 [38400/50000 (76.7%)]\tLoss: 0.097984\n",
      "Train Epoch: 14 [44800/50000 (89.5%)]\tLoss: 0.174345\n",
      "\n",
      "Test set: Average loss: 0.2442, Accuracy: 9215/10000 (92.2%)\n",
      "\n",
      "Train Epoch: 15 [0/50000 (0.0%)]\tLoss: 0.116493\n",
      "Train Epoch: 15 [6400/50000 (12.8%)]\tLoss: 0.158767\n",
      "Train Epoch: 15 [12800/50000 (25.6%)]\tLoss: 0.242775\n",
      "Train Epoch: 15 [19200/50000 (38.4%)]\tLoss: 0.097087\n",
      "Train Epoch: 15 [25600/50000 (51.2%)]\tLoss: 0.143013\n",
      "Train Epoch: 15 [32000/50000 (63.9%)]\tLoss: 0.096550\n",
      "Train Epoch: 15 [38400/50000 (76.7%)]\tLoss: 0.116137\n",
      "Train Epoch: 15 [44800/50000 (89.5%)]\tLoss: 0.190070\n",
      "\n",
      "Test set: Average loss: 0.2389, Accuracy: 9236/10000 (92.4%)\n",
      "\n",
      "Train Epoch: 16 [0/50000 (0.0%)]\tLoss: 0.120520\n",
      "Train Epoch: 16 [6400/50000 (12.8%)]\tLoss: 0.088584\n",
      "Train Epoch: 16 [12800/50000 (25.6%)]\tLoss: 0.054241\n",
      "Train Epoch: 16 [19200/50000 (38.4%)]\tLoss: 0.110977\n",
      "Train Epoch: 16 [25600/50000 (51.2%)]\tLoss: 0.110396\n",
      "Train Epoch: 16 [32000/50000 (63.9%)]\tLoss: 0.076511\n",
      "Train Epoch: 16 [38400/50000 (76.7%)]\tLoss: 0.167585\n",
      "Train Epoch: 16 [44800/50000 (89.5%)]\tLoss: 0.096974\n",
      "\n",
      "Test set: Average loss: 0.2384, Accuracy: 9243/10000 (92.4%)\n",
      "\n",
      "Train Epoch: 17 [0/50000 (0.0%)]\tLoss: 0.049458\n",
      "Train Epoch: 17 [6400/50000 (12.8%)]\tLoss: 0.119059\n",
      "Train Epoch: 17 [12800/50000 (25.6%)]\tLoss: 0.072134\n",
      "Train Epoch: 17 [19200/50000 (38.4%)]\tLoss: 0.144532\n",
      "Train Epoch: 17 [25600/50000 (51.2%)]\tLoss: 0.126396\n",
      "Train Epoch: 17 [32000/50000 (63.9%)]\tLoss: 0.312164\n",
      "Train Epoch: 17 [38400/50000 (76.7%)]\tLoss: 0.097735\n",
      "Train Epoch: 17 [44800/50000 (89.5%)]\tLoss: 0.189531\n",
      "\n",
      "Test set: Average loss: 0.2382, Accuracy: 9236/10000 (92.4%)\n",
      "\n",
      "Train Epoch: 18 [0/50000 (0.0%)]\tLoss: 0.134574\n",
      "Train Epoch: 18 [6400/50000 (12.8%)]\tLoss: 0.121600\n",
      "Train Epoch: 18 [12800/50000 (25.6%)]\tLoss: 0.180583\n",
      "Train Epoch: 18 [19200/50000 (38.4%)]\tLoss: 0.129629\n",
      "Train Epoch: 18 [25600/50000 (51.2%)]\tLoss: 0.188353\n",
      "Train Epoch: 18 [32000/50000 (63.9%)]\tLoss: 0.095303\n",
      "Train Epoch: 18 [38400/50000 (76.7%)]\tLoss: 0.121511\n",
      "Train Epoch: 18 [44800/50000 (89.5%)]\tLoss: 0.125778\n",
      "\n",
      "Test set: Average loss: 0.2353, Accuracy: 9254/10000 (92.5%)\n",
      "\n",
      "Train Epoch: 19 [0/50000 (0.0%)]\tLoss: 0.096318\n",
      "Train Epoch: 19 [6400/50000 (12.8%)]\tLoss: 0.282029\n",
      "Train Epoch: 19 [12800/50000 (25.6%)]\tLoss: 0.135290\n",
      "Train Epoch: 19 [19200/50000 (38.4%)]\tLoss: 0.166373\n",
      "Train Epoch: 19 [25600/50000 (51.2%)]\tLoss: 0.079644\n",
      "Train Epoch: 19 [32000/50000 (63.9%)]\tLoss: 0.246361\n",
      "Train Epoch: 19 [38400/50000 (76.7%)]\tLoss: 0.098023\n",
      "Train Epoch: 19 [44800/50000 (89.5%)]\tLoss: 0.211273\n",
      "\n",
      "Test set: Average loss: 0.2374, Accuracy: 9243/10000 (92.4%)\n",
      "\n",
      "Best accuracy: tensor(0.9254)\n",
      "Number of parameters: 1636629\n",
      "Average Time taken: 135.72569392919542\n",
      "Iteration:  3 Percent:  0.2\n",
      "=> loading checkpoint '/kaggle/working/model_best.pth.tar'\n",
      "=> loaded checkpoint '/kaggle/working/model_best.pth.tar' (epoch 19) Prec1: 0.895400\n",
      "layer index: 4 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 7 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 9 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 15 \t total channel: 64 \t remaining channel: 46\n",
      "layer index: 18 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 20 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 24 \t total channel: 64 \t remaining channel: 43\n",
      "layer index: 27 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 29 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 33 \t total channel: 64 \t remaining channel: 46\n",
      "layer index: 36 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 38 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 42 \t total channel: 64 \t remaining channel: 47\n",
      "layer index: 45 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 47 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 51 \t total channel: 64 \t remaining channel: 40\n",
      "layer index: 54 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 56 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 60 \t total channel: 64 \t remaining channel: 41\n",
      "layer index: 63 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 65 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 69 \t total channel: 64 \t remaining channel: 43\n",
      "layer index: 72 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 74 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 78 \t total channel: 64 \t remaining channel: 40\n",
      "layer index: 81 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 83 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 87 \t total channel: 64 \t remaining channel: 45\n",
      "layer index: 90 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 92 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 96 \t total channel: 64 \t remaining channel: 46\n",
      "layer index: 99 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 101 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 105 \t total channel: 64 \t remaining channel: 40\n",
      "layer index: 108 \t total channel: 16 \t remaining channel: 11\n",
      "layer index: 110 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 114 \t total channel: 64 \t remaining channel: 47\n",
      "layer index: 117 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 119 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 123 \t total channel: 64 \t remaining channel: 46\n",
      "layer index: 126 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 128 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 132 \t total channel: 64 \t remaining channel: 41\n",
      "layer index: 135 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 137 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 141 \t total channel: 64 \t remaining channel: 43\n",
      "layer index: 144 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 146 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 150 \t total channel: 64 \t remaining channel: 53\n",
      "layer index: 153 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 155 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 159 \t total channel: 64 \t remaining channel: 42\n",
      "layer index: 162 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 164 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 169 \t total channel: 64 \t remaining channel: 58\n",
      "layer index: 172 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 174 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 180 \t total channel: 128 \t remaining channel: 96\n",
      "layer index: 183 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 185 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 189 \t total channel: 128 \t remaining channel: 99\n",
      "layer index: 192 \t total channel: 32 \t remaining channel: 31\n",
      "layer index: 194 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 198 \t total channel: 128 \t remaining channel: 98\n",
      "layer index: 201 \t total channel: 32 \t remaining channel: 31\n",
      "layer index: 203 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 207 \t total channel: 128 \t remaining channel: 93\n",
      "layer index: 210 \t total channel: 32 \t remaining channel: 31\n",
      "layer index: 212 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 216 \t total channel: 128 \t remaining channel: 97\n",
      "layer index: 219 \t total channel: 32 \t remaining channel: 31\n",
      "layer index: 221 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 225 \t total channel: 128 \t remaining channel: 97\n",
      "layer index: 228 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 230 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 234 \t total channel: 128 \t remaining channel: 95\n",
      "layer index: 237 \t total channel: 32 \t remaining channel: 31\n",
      "layer index: 239 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 243 \t total channel: 128 \t remaining channel: 92\n",
      "layer index: 246 \t total channel: 32 \t remaining channel: 30\n",
      "layer index: 248 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 252 \t total channel: 128 \t remaining channel: 100\n",
      "layer index: 255 \t total channel: 32 \t remaining channel: 30\n",
      "layer index: 257 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 261 \t total channel: 128 \t remaining channel: 100\n",
      "layer index: 264 \t total channel: 32 \t remaining channel: 31\n",
      "layer index: 266 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 270 \t total channel: 128 \t remaining channel: 104\n",
      "layer index: 273 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 275 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 279 \t total channel: 128 \t remaining channel: 93\n",
      "layer index: 282 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 284 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 288 \t total channel: 128 \t remaining channel: 97\n",
      "layer index: 291 \t total channel: 32 \t remaining channel: 31\n",
      "layer index: 293 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 297 \t total channel: 128 \t remaining channel: 95\n",
      "layer index: 300 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 302 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 306 \t total channel: 128 \t remaining channel: 97\n",
      "layer index: 309 \t total channel: 32 \t remaining channel: 31\n",
      "layer index: 311 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 315 \t total channel: 128 \t remaining channel: 103\n",
      "layer index: 318 \t total channel: 32 \t remaining channel: 29\n",
      "layer index: 320 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 324 \t total channel: 128 \t remaining channel: 91\n",
      "layer index: 327 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 329 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 334 \t total channel: 128 \t remaining channel: 107\n",
      "layer index: 337 \t total channel: 64 \t remaining channel: 59\n",
      "layer index: 339 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 345 \t total channel: 256 \t remaining channel: 168\n",
      "layer index: 348 \t total channel: 64 \t remaining channel: 58\n",
      "layer index: 350 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 354 \t total channel: 256 \t remaining channel: 168\n",
      "layer index: 357 \t total channel: 64 \t remaining channel: 60\n",
      "layer index: 359 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 363 \t total channel: 256 \t remaining channel: 171\n",
      "layer index: 366 \t total channel: 64 \t remaining channel: 62\n",
      "layer index: 368 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 372 \t total channel: 256 \t remaining channel: 177\n",
      "layer index: 375 \t total channel: 64 \t remaining channel: 60\n",
      "layer index: 377 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 381 \t total channel: 256 \t remaining channel: 176\n",
      "layer index: 384 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 386 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 390 \t total channel: 256 \t remaining channel: 170\n",
      "layer index: 393 \t total channel: 64 \t remaining channel: 61\n",
      "layer index: 395 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 399 \t total channel: 256 \t remaining channel: 179\n",
      "layer index: 402 \t total channel: 64 \t remaining channel: 63\n",
      "layer index: 404 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 408 \t total channel: 256 \t remaining channel: 167\n",
      "layer index: 411 \t total channel: 64 \t remaining channel: 58\n",
      "layer index: 413 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 417 \t total channel: 256 \t remaining channel: 172\n",
      "layer index: 420 \t total channel: 64 \t remaining channel: 59\n",
      "layer index: 422 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 426 \t total channel: 256 \t remaining channel: 171\n",
      "layer index: 429 \t total channel: 64 \t remaining channel: 55\n",
      "layer index: 431 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 435 \t total channel: 256 \t remaining channel: 184\n",
      "layer index: 438 \t total channel: 64 \t remaining channel: 62\n",
      "layer index: 440 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 444 \t total channel: 256 \t remaining channel: 181\n",
      "layer index: 447 \t total channel: 64 \t remaining channel: 58\n",
      "layer index: 449 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 453 \t total channel: 256 \t remaining channel: 175\n",
      "layer index: 456 \t total channel: 64 \t remaining channel: 61\n",
      "layer index: 458 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 462 \t total channel: 256 \t remaining channel: 175\n",
      "layer index: 465 \t total channel: 64 \t remaining channel: 57\n",
      "layer index: 467 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 471 \t total channel: 256 \t remaining channel: 181\n",
      "layer index: 474 \t total channel: 64 \t remaining channel: 60\n",
      "layer index: 476 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 480 \t total channel: 256 \t remaining channel: 173\n",
      "layer index: 483 \t total channel: 64 \t remaining channel: 59\n",
      "layer index: 485 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 489 \t total channel: 256 \t remaining channel: 172\n",
      "layer index: 492 \t total channel: 64 \t remaining channel: 56\n",
      "layer index: 494 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 497 \t total channel: 256 \t remaining channel: 241\n",
      "Pre-processing Successful!\n",
      "\n",
      "Test set: Accuracy: 8745/10000 (87.4%)\n",
      "\n",
      "Cfg:\n",
      "[16, 15, 16, 46, 15, 16, 43, 16, 16, 46, 15, 16, 47, 14, 16, 40, 16, 16, 41, 14, 14, 43, 15, 16, 40, 15, 15, 45, 15, 16, 46, 16, 16, 40, 11, 16, 47, 15, 14, 46, 15, 16, 41, 15, 16, 43, 15, 16, 53, 14, 16, 42, 16, 16, 58, 32, 32, 96, 32, 32, 99, 31, 32, 98, 31, 32, 93, 31, 32, 97, 31, 32, 97, 32, 32, 95, 31, 32, 92, 30, 32, 100, 30, 32, 100, 31, 32, 104, 32, 32, 93, 32, 32, 97, 31, 32, 95, 32, 32, 97, 31, 32, 103, 29, 32, 91, 32, 32, 107, 59, 64, 168, 58, 64, 168, 60, 64, 171, 62, 64, 177, 60, 64, 176, 64, 64, 170, 61, 64, 179, 63, 64, 167, 58, 64, 172, 59, 64, 171, 55, 64, 184, 62, 64, 181, 58, 64, 175, 61, 64, 175, 57, 64, 181, 60, 64, 173, 59, 64, 172, 56, 64, 241]\n",
      "In shape: 16, Out shape 15.\n",
      "In shape: 15, Out shape 16.\n",
      "In shape: 16, Out shape 46.\n",
      "In shape: 46, Out shape 15.\n",
      "In shape: 15, Out shape 16.\n",
      "In shape: 16, Out shape 43.\n",
      "In shape: 43, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 46.\n",
      "In shape: 46, Out shape 15.\n",
      "In shape: 15, Out shape 16.\n",
      "In shape: 16, Out shape 47.\n",
      "In shape: 47, Out shape 14.\n",
      "In shape: 14, Out shape 16.\n",
      "In shape: 16, Out shape 40.\n",
      "In shape: 40, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 41.\n",
      "In shape: 41, Out shape 14.\n",
      "In shape: 14, Out shape 14.\n",
      "In shape: 14, Out shape 43.\n",
      "In shape: 43, Out shape 15.\n",
      "In shape: 15, Out shape 16.\n",
      "In shape: 16, Out shape 40.\n",
      "In shape: 40, Out shape 15.\n",
      "In shape: 15, Out shape 15.\n",
      "In shape: 15, Out shape 45.\n",
      "In shape: 45, Out shape 15.\n",
      "In shape: 15, Out shape 16.\n",
      "In shape: 16, Out shape 46.\n",
      "In shape: 46, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 40.\n",
      "In shape: 40, Out shape 11.\n",
      "In shape: 11, Out shape 16.\n",
      "In shape: 16, Out shape 47.\n",
      "In shape: 47, Out shape 15.\n",
      "In shape: 15, Out shape 14.\n",
      "In shape: 14, Out shape 46.\n",
      "In shape: 46, Out shape 15.\n",
      "In shape: 15, Out shape 16.\n",
      "In shape: 16, Out shape 41.\n",
      "In shape: 41, Out shape 15.\n",
      "In shape: 15, Out shape 16.\n",
      "In shape: 16, Out shape 43.\n",
      "In shape: 43, Out shape 15.\n",
      "In shape: 15, Out shape 16.\n",
      "In shape: 16, Out shape 53.\n",
      "In shape: 53, Out shape 14.\n",
      "In shape: 14, Out shape 16.\n",
      "In shape: 16, Out shape 42.\n",
      "In shape: 42, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 58.\n",
      "In shape: 58, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 96.\n",
      "In shape: 96, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 99.\n",
      "In shape: 99, Out shape 31.\n",
      "In shape: 31, Out shape 32.\n",
      "In shape: 32, Out shape 98.\n",
      "In shape: 98, Out shape 31.\n",
      "In shape: 31, Out shape 32.\n",
      "In shape: 32, Out shape 93.\n",
      "In shape: 93, Out shape 31.\n",
      "In shape: 31, Out shape 32.\n",
      "In shape: 32, Out shape 97.\n",
      "In shape: 97, Out shape 31.\n",
      "In shape: 31, Out shape 32.\n",
      "In shape: 32, Out shape 97.\n",
      "In shape: 97, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 95.\n",
      "In shape: 95, Out shape 31.\n",
      "In shape: 31, Out shape 32.\n",
      "In shape: 32, Out shape 92.\n",
      "In shape: 92, Out shape 30.\n",
      "In shape: 30, Out shape 32.\n",
      "In shape: 32, Out shape 100.\n",
      "In shape: 100, Out shape 30.\n",
      "In shape: 30, Out shape 32.\n",
      "In shape: 32, Out shape 100.\n",
      "In shape: 100, Out shape 31.\n",
      "In shape: 31, Out shape 32.\n",
      "In shape: 32, Out shape 104.\n",
      "In shape: 104, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 93.\n",
      "In shape: 93, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 97.\n",
      "In shape: 97, Out shape 31.\n",
      "In shape: 31, Out shape 32.\n",
      "In shape: 32, Out shape 95.\n",
      "In shape: 95, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 97.\n",
      "In shape: 97, Out shape 31.\n",
      "In shape: 31, Out shape 32.\n",
      "In shape: 32, Out shape 103.\n",
      "In shape: 103, Out shape 29.\n",
      "In shape: 29, Out shape 32.\n",
      "In shape: 32, Out shape 91.\n",
      "In shape: 91, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 107.\n",
      "In shape: 107, Out shape 59.\n",
      "In shape: 59, Out shape 64.\n",
      "In shape: 64, Out shape 168.\n",
      "In shape: 168, Out shape 58.\n",
      "In shape: 58, Out shape 64.\n",
      "In shape: 64, Out shape 168.\n",
      "In shape: 168, Out shape 60.\n",
      "In shape: 60, Out shape 64.\n",
      "In shape: 64, Out shape 171.\n",
      "In shape: 171, Out shape 62.\n",
      "In shape: 62, Out shape 64.\n",
      "In shape: 64, Out shape 177.\n",
      "In shape: 177, Out shape 60.\n",
      "In shape: 60, Out shape 64.\n",
      "In shape: 64, Out shape 176.\n",
      "In shape: 176, Out shape 64.\n",
      "In shape: 64, Out shape 64.\n",
      "In shape: 64, Out shape 170.\n",
      "In shape: 170, Out shape 61.\n",
      "In shape: 61, Out shape 64.\n",
      "In shape: 64, Out shape 179.\n",
      "In shape: 179, Out shape 63.\n",
      "In shape: 63, Out shape 64.\n",
      "In shape: 64, Out shape 167.\n",
      "In shape: 167, Out shape 58.\n",
      "In shape: 58, Out shape 64.\n",
      "In shape: 64, Out shape 172.\n",
      "In shape: 172, Out shape 59.\n",
      "In shape: 59, Out shape 64.\n",
      "In shape: 64, Out shape 171.\n",
      "In shape: 171, Out shape 55.\n",
      "In shape: 55, Out shape 64.\n",
      "In shape: 64, Out shape 184.\n",
      "In shape: 184, Out shape 62.\n",
      "In shape: 62, Out shape 64.\n",
      "In shape: 64, Out shape 181.\n",
      "In shape: 181, Out shape 58.\n",
      "In shape: 58, Out shape 64.\n",
      "In shape: 64, Out shape 175.\n",
      "In shape: 175, Out shape 61.\n",
      "In shape: 61, Out shape 64.\n",
      "In shape: 64, Out shape 175.\n",
      "In shape: 175, Out shape 57.\n",
      "In shape: 57, Out shape 64.\n",
      "In shape: 64, Out shape 181.\n",
      "In shape: 181, Out shape 60.\n",
      "In shape: 60, Out shape 64.\n",
      "In shape: 64, Out shape 173.\n",
      "In shape: 173, Out shape 59.\n",
      "In shape: 59, Out shape 64.\n",
      "In shape: 64, Out shape 172.\n",
      "In shape: 172, Out shape 56.\n",
      "In shape: 56, Out shape 64.\n",
      "In shape: 64, Out shape 241.\n",
      "resnet(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(16, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(46, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(43, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(46, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(47, 14, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(14, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(40, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(41, 14, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(14, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(14, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(43, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(40, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(15, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(45, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(46, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(40, 11, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(11, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(47, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(14, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(46, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(41, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(43, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(53, 14, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(14, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(42, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(58, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(99, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(31, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(98, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(31, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(93, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(31, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(97, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(31, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(97, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(95, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(31, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(92, 30, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(30, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(100, 30, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(30, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(100, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(31, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(104, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(93, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(97, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(31, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(95, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(97, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(31, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(103, 29, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(29, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(91, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(107, 59, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(59, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(168, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(58, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(168, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(60, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(171, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(62, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(177, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(60, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(176, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(170, 61, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(61, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(179, 63, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(63, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(167, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(58, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(172, 59, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(59, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(171, 55, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(55, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(184, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(62, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(181, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(58, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(175, 61, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(61, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(175, 57, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(57, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(57, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(181, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(60, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(173, 59, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(59, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(172, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(56, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (select): channel_selection()\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
      "  (fc): Linear(in_features=241, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "Test set: Accuracy: 8745/10000 (87.4%)\n",
      "\n",
      "Train Epoch: 0 [0/50000 (0.0%)]\tLoss: 0.191004\n",
      "Train Epoch: 0 [6400/50000 (12.8%)]\tLoss: 0.687982\n",
      "Train Epoch: 0 [12800/50000 (25.6%)]\tLoss: 0.574510\n",
      "Train Epoch: 0 [19200/50000 (38.4%)]\tLoss: 0.651667\n",
      "Train Epoch: 0 [25600/50000 (51.2%)]\tLoss: 0.436200\n",
      "Train Epoch: 0 [32000/50000 (63.9%)]\tLoss: 0.703210\n",
      "Train Epoch: 0 [38400/50000 (76.7%)]\tLoss: 0.373886\n",
      "Train Epoch: 0 [44800/50000 (89.5%)]\tLoss: 0.419927\n",
      "\n",
      "Test set: Average loss: 0.6035, Accuracy: 7929/10000 (79.3%)\n",
      "\n",
      "Train Epoch: 1 [0/50000 (0.0%)]\tLoss: 0.488534\n",
      "Train Epoch: 1 [6400/50000 (12.8%)]\tLoss: 0.470777\n",
      "Train Epoch: 1 [12800/50000 (25.6%)]\tLoss: 0.403043\n",
      "Train Epoch: 1 [19200/50000 (38.4%)]\tLoss: 0.504953\n",
      "Train Epoch: 1 [25600/50000 (51.2%)]\tLoss: 0.690691\n",
      "Train Epoch: 1 [32000/50000 (63.9%)]\tLoss: 0.386098\n",
      "Train Epoch: 1 [38400/50000 (76.7%)]\tLoss: 0.603046\n",
      "Train Epoch: 1 [44800/50000 (89.5%)]\tLoss: 0.435288\n",
      "\n",
      "Test set: Average loss: 0.6508, Accuracy: 7882/10000 (78.8%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0.0%)]\tLoss: 0.539865\n",
      "Train Epoch: 2 [6400/50000 (12.8%)]\tLoss: 0.410058\n",
      "Train Epoch: 2 [12800/50000 (25.6%)]\tLoss: 0.513298\n",
      "Train Epoch: 2 [19200/50000 (38.4%)]\tLoss: 0.416214\n",
      "Train Epoch: 2 [25600/50000 (51.2%)]\tLoss: 0.386519\n",
      "Train Epoch: 2 [32000/50000 (63.9%)]\tLoss: 0.437386\n",
      "Train Epoch: 2 [38400/50000 (76.7%)]\tLoss: 0.427052\n",
      "Train Epoch: 2 [44800/50000 (89.5%)]\tLoss: 0.377742\n",
      "\n",
      "Test set: Average loss: 0.6801, Accuracy: 7810/10000 (78.1%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0.0%)]\tLoss: 0.461988\n",
      "Train Epoch: 3 [6400/50000 (12.8%)]\tLoss: 0.358761\n",
      "Train Epoch: 3 [12800/50000 (25.6%)]\tLoss: 0.251113\n",
      "Train Epoch: 3 [19200/50000 (38.4%)]\tLoss: 0.524765\n",
      "Train Epoch: 3 [25600/50000 (51.2%)]\tLoss: 0.550420\n",
      "Train Epoch: 3 [32000/50000 (63.9%)]\tLoss: 0.609024\n",
      "Train Epoch: 3 [38400/50000 (76.7%)]\tLoss: 0.386984\n",
      "Train Epoch: 3 [44800/50000 (89.5%)]\tLoss: 0.299784\n",
      "\n",
      "Test set: Average loss: 0.6379, Accuracy: 7867/10000 (78.7%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0.0%)]\tLoss: 0.502568\n",
      "Train Epoch: 4 [6400/50000 (12.8%)]\tLoss: 0.638760\n",
      "Train Epoch: 4 [12800/50000 (25.6%)]\tLoss: 0.482990\n",
      "Train Epoch: 4 [19200/50000 (38.4%)]\tLoss: 0.538622\n",
      "Train Epoch: 4 [25600/50000 (51.2%)]\tLoss: 0.547130\n",
      "Train Epoch: 4 [32000/50000 (63.9%)]\tLoss: 0.442503\n",
      "Train Epoch: 4 [38400/50000 (76.7%)]\tLoss: 0.413989\n",
      "Train Epoch: 4 [44800/50000 (89.5%)]\tLoss: 0.765497\n",
      "\n",
      "Test set: Average loss: 0.5770, Accuracy: 7989/10000 (79.9%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0.0%)]\tLoss: 0.406312\n",
      "Train Epoch: 5 [6400/50000 (12.8%)]\tLoss: 0.552922\n",
      "Train Epoch: 5 [12800/50000 (25.6%)]\tLoss: 0.514432\n",
      "Train Epoch: 5 [19200/50000 (38.4%)]\tLoss: 0.424020\n",
      "Train Epoch: 5 [25600/50000 (51.2%)]\tLoss: 0.496502\n",
      "Train Epoch: 5 [32000/50000 (63.9%)]\tLoss: 0.450256\n",
      "Train Epoch: 5 [38400/50000 (76.7%)]\tLoss: 0.325368\n",
      "Train Epoch: 5 [44800/50000 (89.5%)]\tLoss: 0.381885\n",
      "\n",
      "Test set: Average loss: 0.6019, Accuracy: 8028/10000 (80.3%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0.0%)]\tLoss: 0.366771\n",
      "Train Epoch: 6 [6400/50000 (12.8%)]\tLoss: 0.258396\n",
      "Train Epoch: 6 [12800/50000 (25.6%)]\tLoss: 0.429016\n",
      "Train Epoch: 6 [19200/50000 (38.4%)]\tLoss: 0.522575\n",
      "Train Epoch: 6 [25600/50000 (51.2%)]\tLoss: 0.376517\n",
      "Train Epoch: 6 [32000/50000 (63.9%)]\tLoss: 0.334094\n",
      "Train Epoch: 6 [38400/50000 (76.7%)]\tLoss: 0.446203\n",
      "Train Epoch: 6 [44800/50000 (89.5%)]\tLoss: 0.383565\n",
      "\n",
      "Test set: Average loss: 0.5094, Accuracy: 8301/10000 (83.0%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0.0%)]\tLoss: 0.488031\n",
      "Train Epoch: 7 [6400/50000 (12.8%)]\tLoss: 0.587517\n",
      "Train Epoch: 7 [12800/50000 (25.6%)]\tLoss: 0.491803\n",
      "Train Epoch: 7 [19200/50000 (38.4%)]\tLoss: 0.461187\n",
      "Train Epoch: 7 [25600/50000 (51.2%)]\tLoss: 0.453414\n",
      "Train Epoch: 7 [32000/50000 (63.9%)]\tLoss: 0.287167\n",
      "Train Epoch: 7 [38400/50000 (76.7%)]\tLoss: 0.274011\n",
      "Train Epoch: 7 [44800/50000 (89.5%)]\tLoss: 0.405238\n",
      "\n",
      "Test set: Average loss: 0.4733, Accuracy: 8401/10000 (84.0%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0.0%)]\tLoss: 0.303234\n",
      "Train Epoch: 8 [6400/50000 (12.8%)]\tLoss: 0.358876\n",
      "Train Epoch: 8 [12800/50000 (25.6%)]\tLoss: 0.515896\n",
      "Train Epoch: 8 [19200/50000 (38.4%)]\tLoss: 0.608424\n",
      "Train Epoch: 8 [25600/50000 (51.2%)]\tLoss: 0.590633\n",
      "Train Epoch: 8 [32000/50000 (63.9%)]\tLoss: 0.326965\n",
      "Train Epoch: 8 [38400/50000 (76.7%)]\tLoss: 0.292016\n",
      "Train Epoch: 8 [44800/50000 (89.5%)]\tLoss: 0.370198\n",
      "\n",
      "Test set: Average loss: 0.5780, Accuracy: 8154/10000 (81.5%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0.0%)]\tLoss: 0.547339\n",
      "Train Epoch: 9 [6400/50000 (12.8%)]\tLoss: 0.361305\n",
      "Train Epoch: 9 [12800/50000 (25.6%)]\tLoss: 0.449893\n",
      "Train Epoch: 9 [19200/50000 (38.4%)]\tLoss: 0.281571\n",
      "Train Epoch: 9 [25600/50000 (51.2%)]\tLoss: 0.391260\n",
      "Train Epoch: 9 [32000/50000 (63.9%)]\tLoss: 0.454989\n",
      "Train Epoch: 9 [38400/50000 (76.7%)]\tLoss: 0.432630\n",
      "Train Epoch: 9 [44800/50000 (89.5%)]\tLoss: 0.331612\n",
      "\n",
      "Test set: Average loss: 0.6182, Accuracy: 7997/10000 (80.0%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0.0%)]\tLoss: 0.492326\n",
      "Train Epoch: 10 [6400/50000 (12.8%)]\tLoss: 0.430106\n",
      "Train Epoch: 10 [12800/50000 (25.6%)]\tLoss: 0.129742\n",
      "Train Epoch: 10 [19200/50000 (38.4%)]\tLoss: 0.258057\n",
      "Train Epoch: 10 [25600/50000 (51.2%)]\tLoss: 0.258353\n",
      "Train Epoch: 10 [32000/50000 (63.9%)]\tLoss: 0.306897\n",
      "Train Epoch: 10 [38400/50000 (76.7%)]\tLoss: 0.292176\n",
      "Train Epoch: 10 [44800/50000 (89.5%)]\tLoss: 0.198370\n",
      "\n",
      "Test set: Average loss: 0.2736, Accuracy: 9064/10000 (90.6%)\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0.0%)]\tLoss: 0.150051\n",
      "Train Epoch: 11 [6400/50000 (12.8%)]\tLoss: 0.209924\n",
      "Train Epoch: 11 [12800/50000 (25.6%)]\tLoss: 0.215564\n",
      "Train Epoch: 11 [19200/50000 (38.4%)]\tLoss: 0.216813\n",
      "Train Epoch: 11 [25600/50000 (51.2%)]\tLoss: 0.104940\n",
      "Train Epoch: 11 [32000/50000 (63.9%)]\tLoss: 0.201291\n",
      "Train Epoch: 11 [38400/50000 (76.7%)]\tLoss: 0.207122\n",
      "Train Epoch: 11 [44800/50000 (89.5%)]\tLoss: 0.147676\n",
      "\n",
      "Test set: Average loss: 0.2587, Accuracy: 9124/10000 (91.2%)\n",
      "\n",
      "Train Epoch: 12 [0/50000 (0.0%)]\tLoss: 0.383730\n",
      "Train Epoch: 12 [6400/50000 (12.8%)]\tLoss: 0.174963\n",
      "Train Epoch: 12 [12800/50000 (25.6%)]\tLoss: 0.193742\n",
      "Train Epoch: 12 [19200/50000 (38.4%)]\tLoss: 0.205223\n",
      "Train Epoch: 12 [25600/50000 (51.2%)]\tLoss: 0.202501\n",
      "Train Epoch: 12 [32000/50000 (63.9%)]\tLoss: 0.229228\n",
      "Train Epoch: 12 [38400/50000 (76.7%)]\tLoss: 0.220746\n",
      "Train Epoch: 12 [44800/50000 (89.5%)]\tLoss: 0.165123\n",
      "\n",
      "Test set: Average loss: 0.2590, Accuracy: 9141/10000 (91.4%)\n",
      "\n",
      "Train Epoch: 13 [0/50000 (0.0%)]\tLoss: 0.113302\n",
      "Train Epoch: 13 [6400/50000 (12.8%)]\tLoss: 0.121539\n",
      "Train Epoch: 13 [12800/50000 (25.6%)]\tLoss: 0.133956\n",
      "Train Epoch: 13 [19200/50000 (38.4%)]\tLoss: 0.149874\n",
      "Train Epoch: 13 [25600/50000 (51.2%)]\tLoss: 0.141461\n",
      "Train Epoch: 13 [32000/50000 (63.9%)]\tLoss: 0.219051\n",
      "Train Epoch: 13 [38400/50000 (76.7%)]\tLoss: 0.117125\n",
      "Train Epoch: 13 [44800/50000 (89.5%)]\tLoss: 0.070994\n",
      "\n",
      "Test set: Average loss: 0.2558, Accuracy: 9155/10000 (91.6%)\n",
      "\n",
      "Train Epoch: 14 [0/50000 (0.0%)]\tLoss: 0.129944\n",
      "Train Epoch: 14 [6400/50000 (12.8%)]\tLoss: 0.278867\n",
      "Train Epoch: 14 [12800/50000 (25.6%)]\tLoss: 0.134884\n",
      "Train Epoch: 14 [19200/50000 (38.4%)]\tLoss: 0.358266\n",
      "Train Epoch: 14 [25600/50000 (51.2%)]\tLoss: 0.215715\n",
      "Train Epoch: 14 [32000/50000 (63.9%)]\tLoss: 0.078468\n",
      "Train Epoch: 14 [38400/50000 (76.7%)]\tLoss: 0.127675\n",
      "Train Epoch: 14 [44800/50000 (89.5%)]\tLoss: 0.299446\n",
      "\n",
      "Test set: Average loss: 0.2586, Accuracy: 9148/10000 (91.5%)\n",
      "\n",
      "Train Epoch: 15 [0/50000 (0.0%)]\tLoss: 0.104972\n",
      "Train Epoch: 15 [6400/50000 (12.8%)]\tLoss: 0.100003\n",
      "Train Epoch: 15 [12800/50000 (25.6%)]\tLoss: 0.198285\n",
      "Train Epoch: 15 [19200/50000 (38.4%)]\tLoss: 0.142657\n",
      "Train Epoch: 15 [25600/50000 (51.2%)]\tLoss: 0.220524\n",
      "Train Epoch: 15 [32000/50000 (63.9%)]\tLoss: 0.046537\n",
      "Train Epoch: 15 [38400/50000 (76.7%)]\tLoss: 0.067813\n",
      "Train Epoch: 15 [44800/50000 (89.5%)]\tLoss: 0.323599\n",
      "\n",
      "Test set: Average loss: 0.2431, Accuracy: 9185/10000 (91.8%)\n",
      "\n",
      "Train Epoch: 16 [0/50000 (0.0%)]\tLoss: 0.189240\n",
      "Train Epoch: 16 [6400/50000 (12.8%)]\tLoss: 0.108187\n",
      "Train Epoch: 16 [12800/50000 (25.6%)]\tLoss: 0.089257\n",
      "Train Epoch: 16 [19200/50000 (38.4%)]\tLoss: 0.056115\n",
      "Train Epoch: 16 [25600/50000 (51.2%)]\tLoss: 0.127907\n",
      "Train Epoch: 16 [32000/50000 (63.9%)]\tLoss: 0.198378\n",
      "Train Epoch: 16 [38400/50000 (76.7%)]\tLoss: 0.122140\n",
      "Train Epoch: 16 [44800/50000 (89.5%)]\tLoss: 0.195106\n",
      "\n",
      "Test set: Average loss: 0.2420, Accuracy: 9201/10000 (92.0%)\n",
      "\n",
      "Train Epoch: 17 [0/50000 (0.0%)]\tLoss: 0.096289\n",
      "Train Epoch: 17 [6400/50000 (12.8%)]\tLoss: 0.098145\n",
      "Train Epoch: 17 [12800/50000 (25.6%)]\tLoss: 0.106213\n",
      "Train Epoch: 17 [19200/50000 (38.4%)]\tLoss: 0.059129\n",
      "Train Epoch: 17 [25600/50000 (51.2%)]\tLoss: 0.093017\n",
      "Train Epoch: 17 [32000/50000 (63.9%)]\tLoss: 0.311895\n",
      "Train Epoch: 17 [38400/50000 (76.7%)]\tLoss: 0.219292\n",
      "Train Epoch: 17 [44800/50000 (89.5%)]\tLoss: 0.188046\n",
      "\n",
      "Test set: Average loss: 0.2401, Accuracy: 9215/10000 (92.2%)\n",
      "\n",
      "Train Epoch: 18 [0/50000 (0.0%)]\tLoss: 0.129586\n",
      "Train Epoch: 18 [6400/50000 (12.8%)]\tLoss: 0.155756\n",
      "Train Epoch: 18 [12800/50000 (25.6%)]\tLoss: 0.052390\n",
      "Train Epoch: 18 [19200/50000 (38.4%)]\tLoss: 0.148047\n",
      "Train Epoch: 18 [25600/50000 (51.2%)]\tLoss: 0.125682\n",
      "Train Epoch: 18 [32000/50000 (63.9%)]\tLoss: 0.096558\n",
      "Train Epoch: 18 [38400/50000 (76.7%)]\tLoss: 0.116749\n",
      "Train Epoch: 18 [44800/50000 (89.5%)]\tLoss: 0.151485\n",
      "\n",
      "Test set: Average loss: 0.2418, Accuracy: 9202/10000 (92.0%)\n",
      "\n",
      "Train Epoch: 19 [0/50000 (0.0%)]\tLoss: 0.164237\n",
      "Train Epoch: 19 [6400/50000 (12.8%)]\tLoss: 0.162955\n",
      "Train Epoch: 19 [12800/50000 (25.6%)]\tLoss: 0.142980\n",
      "Train Epoch: 19 [19200/50000 (38.4%)]\tLoss: 0.110826\n",
      "Train Epoch: 19 [25600/50000 (51.2%)]\tLoss: 0.183472\n",
      "Train Epoch: 19 [32000/50000 (63.9%)]\tLoss: 0.084030\n",
      "Train Epoch: 19 [38400/50000 (76.7%)]\tLoss: 0.061854\n",
      "Train Epoch: 19 [44800/50000 (89.5%)]\tLoss: 0.200375\n",
      "\n",
      "Test set: Average loss: 0.2387, Accuracy: 9222/10000 (92.2%)\n",
      "\n",
      "Best accuracy: tensor(0.9222)\n",
      "Number of parameters: 1527681\n",
      "Average Time taken: 133.31104830503463\n",
      "Iteration:  4 Percent:  0.3\n",
      "=> loading checkpoint '/kaggle/working/model_best.pth.tar'\n",
      "=> loaded checkpoint '/kaggle/working/model_best.pth.tar' (epoch 19) Prec1: 0.895400\n",
      "layer index: 4 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 7 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 9 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 15 \t total channel: 64 \t remaining channel: 44\n",
      "layer index: 18 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 20 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 24 \t total channel: 64 \t remaining channel: 42\n",
      "layer index: 27 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 29 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 33 \t total channel: 64 \t remaining channel: 40\n",
      "layer index: 36 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 38 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 42 \t total channel: 64 \t remaining channel: 40\n",
      "layer index: 45 \t total channel: 16 \t remaining channel: 13\n",
      "layer index: 47 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 51 \t total channel: 64 \t remaining channel: 37\n",
      "layer index: 54 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 56 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 60 \t total channel: 64 \t remaining channel: 33\n",
      "layer index: 63 \t total channel: 16 \t remaining channel: 13\n",
      "layer index: 65 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 69 \t total channel: 64 \t remaining channel: 41\n",
      "layer index: 72 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 74 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 78 \t total channel: 64 \t remaining channel: 35\n",
      "layer index: 81 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 83 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 87 \t total channel: 64 \t remaining channel: 38\n",
      "layer index: 90 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 92 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 96 \t total channel: 64 \t remaining channel: 40\n",
      "layer index: 99 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 101 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 105 \t total channel: 64 \t remaining channel: 32\n",
      "layer index: 108 \t total channel: 16 \t remaining channel: 9\n",
      "layer index: 110 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 114 \t total channel: 64 \t remaining channel: 41\n",
      "layer index: 117 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 119 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 123 \t total channel: 64 \t remaining channel: 43\n",
      "layer index: 126 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 128 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 132 \t total channel: 64 \t remaining channel: 39\n",
      "layer index: 135 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 137 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 141 \t total channel: 64 \t remaining channel: 40\n",
      "layer index: 144 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 146 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 150 \t total channel: 64 \t remaining channel: 47\n",
      "layer index: 153 \t total channel: 16 \t remaining channel: 13\n",
      "layer index: 155 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 159 \t total channel: 64 \t remaining channel: 36\n",
      "layer index: 162 \t total channel: 16 \t remaining channel: 13\n",
      "layer index: 164 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 169 \t total channel: 64 \t remaining channel: 55\n",
      "layer index: 172 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 174 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 180 \t total channel: 128 \t remaining channel: 82\n",
      "layer index: 183 \t total channel: 32 \t remaining channel: 31\n",
      "layer index: 185 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 189 \t total channel: 128 \t remaining channel: 81\n",
      "layer index: 192 \t total channel: 32 \t remaining channel: 31\n",
      "layer index: 194 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 198 \t total channel: 128 \t remaining channel: 86\n",
      "layer index: 201 \t total channel: 32 \t remaining channel: 31\n",
      "layer index: 203 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 207 \t total channel: 128 \t remaining channel: 85\n",
      "layer index: 210 \t total channel: 32 \t remaining channel: 31\n",
      "layer index: 212 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 216 \t total channel: 128 \t remaining channel: 81\n",
      "layer index: 219 \t total channel: 32 \t remaining channel: 31\n",
      "layer index: 221 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 225 \t total channel: 128 \t remaining channel: 83\n",
      "layer index: 228 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 230 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 234 \t total channel: 128 \t remaining channel: 82\n",
      "layer index: 237 \t total channel: 32 \t remaining channel: 29\n",
      "layer index: 239 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 243 \t total channel: 128 \t remaining channel: 78\n",
      "layer index: 246 \t total channel: 32 \t remaining channel: 29\n",
      "layer index: 248 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 252 \t total channel: 128 \t remaining channel: 85\n",
      "layer index: 255 \t total channel: 32 \t remaining channel: 29\n",
      "layer index: 257 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 261 \t total channel: 128 \t remaining channel: 89\n",
      "layer index: 264 \t total channel: 32 \t remaining channel: 30\n",
      "layer index: 266 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 270 \t total channel: 128 \t remaining channel: 90\n",
      "layer index: 273 \t total channel: 32 \t remaining channel: 31\n",
      "layer index: 275 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 279 \t total channel: 128 \t remaining channel: 87\n",
      "layer index: 282 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 284 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 288 \t total channel: 128 \t remaining channel: 87\n",
      "layer index: 291 \t total channel: 32 \t remaining channel: 30\n",
      "layer index: 293 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 297 \t total channel: 128 \t remaining channel: 82\n",
      "layer index: 300 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 302 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 306 \t total channel: 128 \t remaining channel: 86\n",
      "layer index: 309 \t total channel: 32 \t remaining channel: 30\n",
      "layer index: 311 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 315 \t total channel: 128 \t remaining channel: 92\n",
      "layer index: 318 \t total channel: 32 \t remaining channel: 27\n",
      "layer index: 320 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 324 \t total channel: 128 \t remaining channel: 75\n",
      "layer index: 327 \t total channel: 32 \t remaining channel: 30\n",
      "layer index: 329 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 334 \t total channel: 128 \t remaining channel: 99\n",
      "layer index: 337 \t total channel: 64 \t remaining channel: 52\n",
      "layer index: 339 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 345 \t total channel: 256 \t remaining channel: 120\n",
      "layer index: 348 \t total channel: 64 \t remaining channel: 52\n",
      "layer index: 350 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 354 \t total channel: 256 \t remaining channel: 123\n",
      "layer index: 357 \t total channel: 64 \t remaining channel: 57\n",
      "layer index: 359 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 363 \t total channel: 256 \t remaining channel: 127\n",
      "layer index: 366 \t total channel: 64 \t remaining channel: 59\n",
      "layer index: 368 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 372 \t total channel: 256 \t remaining channel: 129\n",
      "layer index: 375 \t total channel: 64 \t remaining channel: 56\n",
      "layer index: 377 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 381 \t total channel: 256 \t remaining channel: 135\n",
      "layer index: 384 \t total channel: 64 \t remaining channel: 59\n",
      "layer index: 386 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 390 \t total channel: 256 \t remaining channel: 136\n",
      "layer index: 393 \t total channel: 64 \t remaining channel: 55\n",
      "layer index: 395 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 399 \t total channel: 256 \t remaining channel: 142\n",
      "layer index: 402 \t total channel: 64 \t remaining channel: 56\n",
      "layer index: 404 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 408 \t total channel: 256 \t remaining channel: 128\n",
      "layer index: 411 \t total channel: 64 \t remaining channel: 48\n",
      "layer index: 413 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 417 \t total channel: 256 \t remaining channel: 131\n",
      "layer index: 420 \t total channel: 64 \t remaining channel: 52\n",
      "layer index: 422 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 426 \t total channel: 256 \t remaining channel: 126\n",
      "layer index: 429 \t total channel: 64 \t remaining channel: 51\n",
      "layer index: 431 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 435 \t total channel: 256 \t remaining channel: 143\n",
      "layer index: 438 \t total channel: 64 \t remaining channel: 59\n",
      "layer index: 440 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 444 \t total channel: 256 \t remaining channel: 117\n",
      "layer index: 447 \t total channel: 64 \t remaining channel: 51\n",
      "layer index: 449 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 453 \t total channel: 256 \t remaining channel: 120\n",
      "layer index: 456 \t total channel: 64 \t remaining channel: 53\n",
      "layer index: 458 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 462 \t total channel: 256 \t remaining channel: 128\n",
      "layer index: 465 \t total channel: 64 \t remaining channel: 50\n",
      "layer index: 467 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 471 \t total channel: 256 \t remaining channel: 138\n",
      "layer index: 474 \t total channel: 64 \t remaining channel: 48\n",
      "layer index: 476 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 480 \t total channel: 256 \t remaining channel: 135\n",
      "layer index: 483 \t total channel: 64 \t remaining channel: 49\n",
      "layer index: 485 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 489 \t total channel: 256 \t remaining channel: 128\n",
      "layer index: 492 \t total channel: 64 \t remaining channel: 47\n",
      "layer index: 494 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 497 \t total channel: 256 \t remaining channel: 238\n",
      "Pre-processing Successful!\n",
      "\n",
      "Test set: Accuracy: 7858/10000 (78.6%)\n",
      "\n",
      "Cfg:\n",
      "[16, 15, 16, 44, 15, 16, 42, 16, 16, 40, 15, 16, 40, 13, 16, 37, 15, 16, 33, 13, 14, 41, 15, 16, 35, 15, 15, 38, 15, 16, 40, 14, 16, 32, 9, 16, 41, 15, 14, 43, 15, 15, 39, 14, 16, 40, 14, 16, 47, 13, 15, 36, 13, 16, 55, 32, 32, 82, 31, 32, 81, 31, 32, 86, 31, 32, 85, 31, 32, 81, 31, 32, 83, 32, 32, 82, 29, 32, 78, 29, 32, 85, 29, 32, 89, 30, 32, 90, 31, 32, 87, 32, 32, 87, 30, 32, 82, 32, 32, 86, 30, 32, 92, 27, 32, 75, 30, 32, 99, 52, 64, 120, 52, 64, 123, 57, 64, 127, 59, 64, 129, 56, 64, 135, 59, 64, 136, 55, 64, 142, 56, 64, 128, 48, 64, 131, 52, 64, 126, 51, 64, 143, 59, 64, 117, 51, 64, 120, 53, 64, 128, 50, 64, 138, 48, 64, 135, 49, 64, 128, 47, 64, 238]\n",
      "In shape: 16, Out shape 15.\n",
      "In shape: 15, Out shape 16.\n",
      "In shape: 16, Out shape 44.\n",
      "In shape: 44, Out shape 15.\n",
      "In shape: 15, Out shape 16.\n",
      "In shape: 16, Out shape 42.\n",
      "In shape: 42, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 40.\n",
      "In shape: 40, Out shape 15.\n",
      "In shape: 15, Out shape 16.\n",
      "In shape: 16, Out shape 40.\n",
      "In shape: 40, Out shape 13.\n",
      "In shape: 13, Out shape 16.\n",
      "In shape: 16, Out shape 37.\n",
      "In shape: 37, Out shape 15.\n",
      "In shape: 15, Out shape 16.\n",
      "In shape: 16, Out shape 33.\n",
      "In shape: 33, Out shape 13.\n",
      "In shape: 13, Out shape 14.\n",
      "In shape: 14, Out shape 41.\n",
      "In shape: 41, Out shape 15.\n",
      "In shape: 15, Out shape 16.\n",
      "In shape: 16, Out shape 35.\n",
      "In shape: 35, Out shape 15.\n",
      "In shape: 15, Out shape 15.\n",
      "In shape: 15, Out shape 38.\n",
      "In shape: 38, Out shape 15.\n",
      "In shape: 15, Out shape 16.\n",
      "In shape: 16, Out shape 40.\n",
      "In shape: 40, Out shape 14.\n",
      "In shape: 14, Out shape 16.\n",
      "In shape: 16, Out shape 32.\n",
      "In shape: 32, Out shape 9.\n",
      "In shape: 9, Out shape 16.\n",
      "In shape: 16, Out shape 41.\n",
      "In shape: 41, Out shape 15.\n",
      "In shape: 15, Out shape 14.\n",
      "In shape: 14, Out shape 43.\n",
      "In shape: 43, Out shape 15.\n",
      "In shape: 15, Out shape 15.\n",
      "In shape: 15, Out shape 39.\n",
      "In shape: 39, Out shape 14.\n",
      "In shape: 14, Out shape 16.\n",
      "In shape: 16, Out shape 40.\n",
      "In shape: 40, Out shape 14.\n",
      "In shape: 14, Out shape 16.\n",
      "In shape: 16, Out shape 47.\n",
      "In shape: 47, Out shape 13.\n",
      "In shape: 13, Out shape 15.\n",
      "In shape: 15, Out shape 36.\n",
      "In shape: 36, Out shape 13.\n",
      "In shape: 13, Out shape 16.\n",
      "In shape: 16, Out shape 55.\n",
      "In shape: 55, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 82.\n",
      "In shape: 82, Out shape 31.\n",
      "In shape: 31, Out shape 32.\n",
      "In shape: 32, Out shape 81.\n",
      "In shape: 81, Out shape 31.\n",
      "In shape: 31, Out shape 32.\n",
      "In shape: 32, Out shape 86.\n",
      "In shape: 86, Out shape 31.\n",
      "In shape: 31, Out shape 32.\n",
      "In shape: 32, Out shape 85.\n",
      "In shape: 85, Out shape 31.\n",
      "In shape: 31, Out shape 32.\n",
      "In shape: 32, Out shape 81.\n",
      "In shape: 81, Out shape 31.\n",
      "In shape: 31, Out shape 32.\n",
      "In shape: 32, Out shape 83.\n",
      "In shape: 83, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 82.\n",
      "In shape: 82, Out shape 29.\n",
      "In shape: 29, Out shape 32.\n",
      "In shape: 32, Out shape 78.\n",
      "In shape: 78, Out shape 29.\n",
      "In shape: 29, Out shape 32.\n",
      "In shape: 32, Out shape 85.\n",
      "In shape: 85, Out shape 29.\n",
      "In shape: 29, Out shape 32.\n",
      "In shape: 32, Out shape 89.\n",
      "In shape: 89, Out shape 30.\n",
      "In shape: 30, Out shape 32.\n",
      "In shape: 32, Out shape 90.\n",
      "In shape: 90, Out shape 31.\n",
      "In shape: 31, Out shape 32.\n",
      "In shape: 32, Out shape 87.\n",
      "In shape: 87, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 87.\n",
      "In shape: 87, Out shape 30.\n",
      "In shape: 30, Out shape 32.\n",
      "In shape: 32, Out shape 82.\n",
      "In shape: 82, Out shape 32.\n",
      "In shape: 32, Out shape 32.\n",
      "In shape: 32, Out shape 86.\n",
      "In shape: 86, Out shape 30.\n",
      "In shape: 30, Out shape 32.\n",
      "In shape: 32, Out shape 92.\n",
      "In shape: 92, Out shape 27.\n",
      "In shape: 27, Out shape 32.\n",
      "In shape: 32, Out shape 75.\n",
      "In shape: 75, Out shape 30.\n",
      "In shape: 30, Out shape 32.\n",
      "In shape: 32, Out shape 99.\n",
      "In shape: 99, Out shape 52.\n",
      "In shape: 52, Out shape 64.\n",
      "In shape: 64, Out shape 120.\n",
      "In shape: 120, Out shape 52.\n",
      "In shape: 52, Out shape 64.\n",
      "In shape: 64, Out shape 123.\n",
      "In shape: 123, Out shape 57.\n",
      "In shape: 57, Out shape 64.\n",
      "In shape: 64, Out shape 127.\n",
      "In shape: 127, Out shape 59.\n",
      "In shape: 59, Out shape 64.\n",
      "In shape: 64, Out shape 129.\n",
      "In shape: 129, Out shape 56.\n",
      "In shape: 56, Out shape 64.\n",
      "In shape: 64, Out shape 135.\n",
      "In shape: 135, Out shape 59.\n",
      "In shape: 59, Out shape 64.\n",
      "In shape: 64, Out shape 136.\n",
      "In shape: 136, Out shape 55.\n",
      "In shape: 55, Out shape 64.\n",
      "In shape: 64, Out shape 142.\n",
      "In shape: 142, Out shape 56.\n",
      "In shape: 56, Out shape 64.\n",
      "In shape: 64, Out shape 128.\n",
      "In shape: 128, Out shape 48.\n",
      "In shape: 48, Out shape 64.\n",
      "In shape: 64, Out shape 131.\n",
      "In shape: 131, Out shape 52.\n",
      "In shape: 52, Out shape 64.\n",
      "In shape: 64, Out shape 126.\n",
      "In shape: 126, Out shape 51.\n",
      "In shape: 51, Out shape 64.\n",
      "In shape: 64, Out shape 143.\n",
      "In shape: 143, Out shape 59.\n",
      "In shape: 59, Out shape 64.\n",
      "In shape: 64, Out shape 117.\n",
      "In shape: 117, Out shape 51.\n",
      "In shape: 51, Out shape 64.\n",
      "In shape: 64, Out shape 120.\n",
      "In shape: 120, Out shape 53.\n",
      "In shape: 53, Out shape 64.\n",
      "In shape: 64, Out shape 128.\n",
      "In shape: 128, Out shape 50.\n",
      "In shape: 50, Out shape 64.\n",
      "In shape: 64, Out shape 138.\n",
      "In shape: 138, Out shape 48.\n",
      "In shape: 48, Out shape 64.\n",
      "In shape: 64, Out shape 135.\n",
      "In shape: 135, Out shape 49.\n",
      "In shape: 49, Out shape 64.\n",
      "In shape: 64, Out shape 128.\n",
      "In shape: 128, Out shape 47.\n",
      "In shape: 47, Out shape 64.\n",
      "In shape: 64, Out shape 238.\n",
      "resnet(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(16, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(44, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(42, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(40, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(40, 13, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(13, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(37, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(33, 13, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(13, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(14, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(41, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(35, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(15, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(38, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(40, 14, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(14, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(32, 9, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(9, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(41, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(14, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(43, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(15, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(39, 14, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(14, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(40, 14, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(14, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(47, 13, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(13, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(15, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(36, 13, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(13, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(55, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(82, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(31, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(81, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(31, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(86, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(31, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(85, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(31, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(81, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(31, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(83, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(82, 29, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(29, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(78, 29, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(29, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(85, 29, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(29, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(89, 30, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(30, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(90, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(31, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(87, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(87, 30, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(30, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(82, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(86, 30, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(30, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(92, 27, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(27, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(75, 30, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(30, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(99, 52, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(52, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(120, 52, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(52, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(123, 57, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(57, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(57, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(127, 59, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(59, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(129, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(56, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(135, 59, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(59, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(136, 55, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(55, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(142, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(56, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(128, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(131, 52, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(52, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(126, 51, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(51, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(51, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(143, 59, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(59, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(117, 51, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(51, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(51, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(120, 53, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(53, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(128, 50, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(50, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(138, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(135, 49, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(49, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(128, 47, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(47, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(47, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (select): channel_selection()\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
      "  (fc): Linear(in_features=238, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "Test set: Accuracy: 7858/10000 (78.6%)\n",
      "\n",
      "Train Epoch: 0 [0/50000 (0.0%)]\tLoss: 0.176476\n",
      "Train Epoch: 0 [6400/50000 (12.8%)]\tLoss: 0.789386\n",
      "Train Epoch: 0 [12800/50000 (25.6%)]\tLoss: 0.528900\n",
      "Train Epoch: 0 [19200/50000 (38.4%)]\tLoss: 0.533267\n",
      "Train Epoch: 0 [25600/50000 (51.2%)]\tLoss: 0.394708\n",
      "Train Epoch: 0 [32000/50000 (63.9%)]\tLoss: 0.577739\n",
      "Train Epoch: 0 [38400/50000 (76.7%)]\tLoss: 0.545247\n",
      "Train Epoch: 0 [44800/50000 (89.5%)]\tLoss: 0.459398\n",
      "\n",
      "Test set: Average loss: 0.7833, Accuracy: 7456/10000 (74.6%)\n",
      "\n",
      "Train Epoch: 1 [0/50000 (0.0%)]\tLoss: 0.556664\n",
      "Train Epoch: 1 [6400/50000 (12.8%)]\tLoss: 0.611502\n",
      "Train Epoch: 1 [12800/50000 (25.6%)]\tLoss: 0.586387\n",
      "Train Epoch: 1 [19200/50000 (38.4%)]\tLoss: 0.280237\n",
      "Train Epoch: 1 [25600/50000 (51.2%)]\tLoss: 0.467632\n",
      "Train Epoch: 1 [32000/50000 (63.9%)]\tLoss: 0.598943\n",
      "Train Epoch: 1 [38400/50000 (76.7%)]\tLoss: 0.569828\n",
      "Train Epoch: 1 [44800/50000 (89.5%)]\tLoss: 0.511278\n",
      "\n",
      "Test set: Average loss: 0.6914, Accuracy: 7647/10000 (76.5%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0.0%)]\tLoss: 0.455748\n",
      "Train Epoch: 2 [6400/50000 (12.8%)]\tLoss: 0.328474\n",
      "Train Epoch: 2 [12800/50000 (25.6%)]\tLoss: 0.317820\n",
      "Train Epoch: 2 [19200/50000 (38.4%)]\tLoss: 0.390583\n",
      "Train Epoch: 2 [25600/50000 (51.2%)]\tLoss: 0.300926\n",
      "Train Epoch: 2 [32000/50000 (63.9%)]\tLoss: 0.461788\n",
      "Train Epoch: 2 [38400/50000 (76.7%)]\tLoss: 0.557857\n",
      "Train Epoch: 2 [44800/50000 (89.5%)]\tLoss: 0.493051\n",
      "\n",
      "Test set: Average loss: 0.6580, Accuracy: 7895/10000 (78.9%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0.0%)]\tLoss: 0.586522\n",
      "Train Epoch: 3 [6400/50000 (12.8%)]\tLoss: 0.506155\n",
      "Train Epoch: 3 [12800/50000 (25.6%)]\tLoss: 0.439355\n",
      "Train Epoch: 3 [19200/50000 (38.4%)]\tLoss: 0.215941\n",
      "Train Epoch: 3 [25600/50000 (51.2%)]\tLoss: 0.707195\n",
      "Train Epoch: 3 [32000/50000 (63.9%)]\tLoss: 0.330381\n",
      "Train Epoch: 3 [38400/50000 (76.7%)]\tLoss: 0.366999\n",
      "Train Epoch: 3 [44800/50000 (89.5%)]\tLoss: 0.422279\n",
      "\n",
      "Test set: Average loss: 0.5492, Accuracy: 8159/10000 (81.6%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0.0%)]\tLoss: 0.654559\n",
      "Train Epoch: 4 [6400/50000 (12.8%)]\tLoss: 0.280712\n",
      "Train Epoch: 4 [12800/50000 (25.6%)]\tLoss: 0.372238\n",
      "Train Epoch: 4 [19200/50000 (38.4%)]\tLoss: 0.538721\n",
      "Train Epoch: 4 [25600/50000 (51.2%)]\tLoss: 0.434110\n",
      "Train Epoch: 4 [32000/50000 (63.9%)]\tLoss: 0.404744\n",
      "Train Epoch: 4 [38400/50000 (76.7%)]\tLoss: 0.368911\n",
      "Train Epoch: 4 [44800/50000 (89.5%)]\tLoss: 0.512128\n",
      "\n",
      "Test set: Average loss: 0.5521, Accuracy: 8193/10000 (81.9%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0.0%)]\tLoss: 0.419938\n",
      "Train Epoch: 5 [6400/50000 (12.8%)]\tLoss: 0.493581\n",
      "Train Epoch: 5 [12800/50000 (25.6%)]\tLoss: 0.397558\n",
      "Train Epoch: 5 [19200/50000 (38.4%)]\tLoss: 0.392688\n",
      "Train Epoch: 5 [25600/50000 (51.2%)]\tLoss: 0.480735\n",
      "Train Epoch: 5 [32000/50000 (63.9%)]\tLoss: 0.458744\n",
      "Train Epoch: 5 [38400/50000 (76.7%)]\tLoss: 0.591905\n",
      "Train Epoch: 5 [44800/50000 (89.5%)]\tLoss: 0.406094\n",
      "\n",
      "Test set: Average loss: 0.6449, Accuracy: 7933/10000 (79.3%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0.0%)]\tLoss: 0.398391\n",
      "Train Epoch: 6 [6400/50000 (12.8%)]\tLoss: 0.457405\n",
      "Train Epoch: 6 [12800/50000 (25.6%)]\tLoss: 0.343238\n",
      "Train Epoch: 6 [19200/50000 (38.4%)]\tLoss: 0.643296\n",
      "Train Epoch: 6 [25600/50000 (51.2%)]\tLoss: 0.595860\n",
      "Train Epoch: 6 [32000/50000 (63.9%)]\tLoss: 0.291638\n",
      "Train Epoch: 6 [38400/50000 (76.7%)]\tLoss: 0.500522\n",
      "Train Epoch: 6 [44800/50000 (89.5%)]\tLoss: 0.418018\n",
      "\n",
      "Test set: Average loss: 0.4796, Accuracy: 8394/10000 (83.9%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0.0%)]\tLoss: 0.382592\n",
      "Train Epoch: 7 [6400/50000 (12.8%)]\tLoss: 0.509203\n",
      "Train Epoch: 7 [12800/50000 (25.6%)]\tLoss: 0.248973\n",
      "Train Epoch: 7 [19200/50000 (38.4%)]\tLoss: 0.518930\n",
      "Train Epoch: 7 [25600/50000 (51.2%)]\tLoss: 0.752511\n",
      "Train Epoch: 7 [32000/50000 (63.9%)]\tLoss: 0.370962\n",
      "Train Epoch: 7 [38400/50000 (76.7%)]\tLoss: 0.482879\n",
      "Train Epoch: 7 [44800/50000 (89.5%)]\tLoss: 0.342014\n",
      "\n",
      "Test set: Average loss: 0.4705, Accuracy: 8377/10000 (83.8%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0.0%)]\tLoss: 0.448996\n",
      "Train Epoch: 8 [6400/50000 (12.8%)]\tLoss: 0.558634\n",
      "Train Epoch: 8 [12800/50000 (25.6%)]\tLoss: 0.370912\n",
      "Train Epoch: 8 [19200/50000 (38.4%)]\tLoss: 0.537844\n",
      "Train Epoch: 8 [25600/50000 (51.2%)]\tLoss: 0.567939\n",
      "Train Epoch: 8 [32000/50000 (63.9%)]\tLoss: 0.422476\n",
      "Train Epoch: 8 [38400/50000 (76.7%)]\tLoss: 0.551155\n",
      "Train Epoch: 8 [44800/50000 (89.5%)]\tLoss: 0.478584\n",
      "\n",
      "Test set: Average loss: 0.5402, Accuracy: 8276/10000 (82.8%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0.0%)]\tLoss: 0.424838\n",
      "Train Epoch: 9 [6400/50000 (12.8%)]\tLoss: 0.391087\n",
      "Train Epoch: 9 [12800/50000 (25.6%)]\tLoss: 0.449717\n",
      "Train Epoch: 9 [19200/50000 (38.4%)]\tLoss: 0.451821\n",
      "Train Epoch: 9 [25600/50000 (51.2%)]\tLoss: 0.474228\n",
      "Train Epoch: 9 [32000/50000 (63.9%)]\tLoss: 0.361174\n",
      "Train Epoch: 9 [38400/50000 (76.7%)]\tLoss: 0.410374\n",
      "Train Epoch: 9 [44800/50000 (89.5%)]\tLoss: 0.261033\n",
      "\n",
      "Test set: Average loss: 0.4615, Accuracy: 8432/10000 (84.3%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0.0%)]\tLoss: 0.347392\n",
      "Train Epoch: 10 [6400/50000 (12.8%)]\tLoss: 0.231784\n",
      "Train Epoch: 10 [12800/50000 (25.6%)]\tLoss: 0.140785\n",
      "Train Epoch: 10 [19200/50000 (38.4%)]\tLoss: 0.140633\n",
      "Train Epoch: 10 [25600/50000 (51.2%)]\tLoss: 0.200627\n",
      "Train Epoch: 10 [32000/50000 (63.9%)]\tLoss: 0.207772\n",
      "Train Epoch: 10 [38400/50000 (76.7%)]\tLoss: 0.190477\n",
      "Train Epoch: 10 [44800/50000 (89.5%)]\tLoss: 0.164506\n",
      "\n",
      "Test set: Average loss: 0.2692, Accuracy: 9070/10000 (90.7%)\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0.0%)]\tLoss: 0.209256\n",
      "Train Epoch: 11 [6400/50000 (12.8%)]\tLoss: 0.193125\n",
      "Train Epoch: 11 [12800/50000 (25.6%)]\tLoss: 0.340675\n",
      "Train Epoch: 11 [19200/50000 (38.4%)]\tLoss: 0.227546\n",
      "Train Epoch: 11 [25600/50000 (51.2%)]\tLoss: 0.239743\n",
      "Train Epoch: 11 [32000/50000 (63.9%)]\tLoss: 0.203939\n",
      "Train Epoch: 11 [38400/50000 (76.7%)]\tLoss: 0.112554\n",
      "Train Epoch: 11 [44800/50000 (89.5%)]\tLoss: 0.196268\n",
      "\n",
      "Test set: Average loss: 0.2596, Accuracy: 9103/10000 (91.0%)\n",
      "\n",
      "Train Epoch: 12 [0/50000 (0.0%)]\tLoss: 0.106878\n",
      "Train Epoch: 12 [6400/50000 (12.8%)]\tLoss: 0.217181\n",
      "Train Epoch: 12 [12800/50000 (25.6%)]\tLoss: 0.238310\n",
      "Train Epoch: 12 [19200/50000 (38.4%)]\tLoss: 0.388387\n",
      "Train Epoch: 12 [25600/50000 (51.2%)]\tLoss: 0.204364\n",
      "Train Epoch: 12 [32000/50000 (63.9%)]\tLoss: 0.105604\n",
      "Train Epoch: 12 [38400/50000 (76.7%)]\tLoss: 0.187165\n",
      "Train Epoch: 12 [44800/50000 (89.5%)]\tLoss: 0.199502\n",
      "\n",
      "Test set: Average loss: 0.2589, Accuracy: 9136/10000 (91.4%)\n",
      "\n",
      "Train Epoch: 13 [0/50000 (0.0%)]\tLoss: 0.102888\n",
      "Train Epoch: 13 [6400/50000 (12.8%)]\tLoss: 0.229347\n",
      "Train Epoch: 13 [12800/50000 (25.6%)]\tLoss: 0.140589\n",
      "Train Epoch: 13 [19200/50000 (38.4%)]\tLoss: 0.168074\n",
      "Train Epoch: 13 [25600/50000 (51.2%)]\tLoss: 0.074488\n",
      "Train Epoch: 13 [32000/50000 (63.9%)]\tLoss: 0.223121\n",
      "Train Epoch: 13 [38400/50000 (76.7%)]\tLoss: 0.213242\n",
      "Train Epoch: 13 [44800/50000 (89.5%)]\tLoss: 0.097022\n",
      "\n",
      "Test set: Average loss: 0.2520, Accuracy: 9169/10000 (91.7%)\n",
      "\n",
      "Train Epoch: 14 [0/50000 (0.0%)]\tLoss: 0.219952\n",
      "Train Epoch: 14 [6400/50000 (12.8%)]\tLoss: 0.367409\n",
      "Train Epoch: 14 [12800/50000 (25.6%)]\tLoss: 0.103446\n",
      "Train Epoch: 14 [19200/50000 (38.4%)]\tLoss: 0.111564\n",
      "Train Epoch: 14 [25600/50000 (51.2%)]\tLoss: 0.274906\n",
      "Train Epoch: 14 [32000/50000 (63.9%)]\tLoss: 0.137878\n",
      "Train Epoch: 14 [38400/50000 (76.7%)]\tLoss: 0.147734\n",
      "Train Epoch: 14 [44800/50000 (89.5%)]\tLoss: 0.218499\n",
      "\n",
      "Test set: Average loss: 0.2463, Accuracy: 9183/10000 (91.8%)\n",
      "\n",
      "Train Epoch: 15 [0/50000 (0.0%)]\tLoss: 0.119354\n",
      "Train Epoch: 15 [6400/50000 (12.8%)]\tLoss: 0.169518\n",
      "Train Epoch: 15 [12800/50000 (25.6%)]\tLoss: 0.269594\n",
      "Train Epoch: 15 [19200/50000 (38.4%)]\tLoss: 0.201677\n",
      "Train Epoch: 15 [25600/50000 (51.2%)]\tLoss: 0.088532\n",
      "Train Epoch: 15 [32000/50000 (63.9%)]\tLoss: 0.192103\n",
      "Train Epoch: 15 [38400/50000 (76.7%)]\tLoss: 0.081226\n",
      "Train Epoch: 15 [44800/50000 (89.5%)]\tLoss: 0.237218\n",
      "\n",
      "Test set: Average loss: 0.2364, Accuracy: 9201/10000 (92.0%)\n",
      "\n",
      "Train Epoch: 16 [0/50000 (0.0%)]\tLoss: 0.096877\n",
      "Train Epoch: 16 [6400/50000 (12.8%)]\tLoss: 0.246378\n",
      "Train Epoch: 16 [12800/50000 (25.6%)]\tLoss: 0.119117\n",
      "Train Epoch: 16 [19200/50000 (38.4%)]\tLoss: 0.116099\n",
      "Train Epoch: 16 [25600/50000 (51.2%)]\tLoss: 0.199861\n",
      "Train Epoch: 16 [32000/50000 (63.9%)]\tLoss: 0.139867\n",
      "Train Epoch: 16 [38400/50000 (76.7%)]\tLoss: 0.141017\n",
      "Train Epoch: 16 [44800/50000 (89.5%)]\tLoss: 0.068826\n",
      "\n",
      "Test set: Average loss: 0.2391, Accuracy: 9208/10000 (92.1%)\n",
      "\n",
      "Train Epoch: 17 [0/50000 (0.0%)]\tLoss: 0.232671\n",
      "Train Epoch: 17 [6400/50000 (12.8%)]\tLoss: 0.111605\n",
      "Train Epoch: 17 [12800/50000 (25.6%)]\tLoss: 0.072770\n",
      "Train Epoch: 17 [19200/50000 (38.4%)]\tLoss: 0.170571\n",
      "Train Epoch: 17 [25600/50000 (51.2%)]\tLoss: 0.118324\n",
      "Train Epoch: 17 [32000/50000 (63.9%)]\tLoss: 0.203191\n",
      "Train Epoch: 17 [38400/50000 (76.7%)]\tLoss: 0.097684\n",
      "Train Epoch: 17 [44800/50000 (89.5%)]\tLoss: 0.087988\n",
      "\n",
      "Test set: Average loss: 0.2369, Accuracy: 9209/10000 (92.1%)\n",
      "\n",
      "Train Epoch: 18 [0/50000 (0.0%)]\tLoss: 0.164772\n",
      "Train Epoch: 18 [6400/50000 (12.8%)]\tLoss: 0.176228\n",
      "Train Epoch: 18 [12800/50000 (25.6%)]\tLoss: 0.142501\n",
      "Train Epoch: 18 [19200/50000 (38.4%)]\tLoss: 0.110534\n",
      "Train Epoch: 18 [25600/50000 (51.2%)]\tLoss: 0.208821\n",
      "Train Epoch: 18 [32000/50000 (63.9%)]\tLoss: 0.201078\n",
      "Train Epoch: 18 [38400/50000 (76.7%)]\tLoss: 0.131356\n",
      "Train Epoch: 18 [44800/50000 (89.5%)]\tLoss: 0.105702\n",
      "\n",
      "Test set: Average loss: 0.2415, Accuracy: 9198/10000 (92.0%)\n",
      "\n",
      "Train Epoch: 19 [0/50000 (0.0%)]\tLoss: 0.154018\n",
      "Train Epoch: 19 [6400/50000 (12.8%)]\tLoss: 0.119392\n",
      "Train Epoch: 19 [12800/50000 (25.6%)]\tLoss: 0.163003\n",
      "Train Epoch: 19 [19200/50000 (38.4%)]\tLoss: 0.216046\n",
      "Train Epoch: 19 [25600/50000 (51.2%)]\tLoss: 0.083885\n",
      "Train Epoch: 19 [32000/50000 (63.9%)]\tLoss: 0.242502\n",
      "Train Epoch: 19 [38400/50000 (76.7%)]\tLoss: 0.088636\n",
      "Train Epoch: 19 [44800/50000 (89.5%)]\tLoss: 0.251034\n",
      "\n",
      "Test set: Average loss: 0.2364, Accuracy: 9222/10000 (92.2%)\n",
      "\n",
      "Best accuracy: tensor(0.9222)\n",
      "Number of parameters: 1383384\n",
      "Average Time taken: 131.31474441289902\n",
      "Iteration:  5 Percent:  0.4\n",
      "=> loading checkpoint '/kaggle/working/model_best.pth.tar'\n",
      "=> loaded checkpoint '/kaggle/working/model_best.pth.tar' (epoch 19) Prec1: 0.895400\n",
      "layer index: 4 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 7 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 9 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 15 \t total channel: 64 \t remaining channel: 43\n",
      "layer index: 18 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 20 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 24 \t total channel: 64 \t remaining channel: 39\n",
      "layer index: 27 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 29 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 33 \t total channel: 64 \t remaining channel: 36\n",
      "layer index: 36 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 38 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 42 \t total channel: 64 \t remaining channel: 35\n",
      "layer index: 45 \t total channel: 16 \t remaining channel: 13\n",
      "layer index: 47 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 51 \t total channel: 64 \t remaining channel: 33\n",
      "layer index: 54 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 56 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 60 \t total channel: 64 \t remaining channel: 30\n",
      "layer index: 63 \t total channel: 16 \t remaining channel: 11\n",
      "layer index: 65 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 69 \t total channel: 64 \t remaining channel: 36\n",
      "layer index: 72 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 74 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 78 \t total channel: 64 \t remaining channel: 33\n",
      "layer index: 81 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 83 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 87 \t total channel: 64 \t remaining channel: 35\n",
      "layer index: 90 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 92 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 96 \t total channel: 64 \t remaining channel: 35\n",
      "layer index: 99 \t total channel: 16 \t remaining channel: 13\n",
      "layer index: 101 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 105 \t total channel: 64 \t remaining channel: 28\n",
      "layer index: 108 \t total channel: 16 \t remaining channel: 9\n",
      "layer index: 110 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 114 \t total channel: 64 \t remaining channel: 36\n",
      "layer index: 117 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 119 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 123 \t total channel: 64 \t remaining channel: 36\n",
      "layer index: 126 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 128 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 132 \t total channel: 64 \t remaining channel: 34\n",
      "layer index: 135 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 137 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 141 \t total channel: 64 \t remaining channel: 36\n",
      "layer index: 144 \t total channel: 16 \t remaining channel: 13\n",
      "layer index: 146 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 150 \t total channel: 64 \t remaining channel: 36\n",
      "layer index: 153 \t total channel: 16 \t remaining channel: 12\n",
      "layer index: 155 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 159 \t total channel: 64 \t remaining channel: 31\n",
      "layer index: 162 \t total channel: 16 \t remaining channel: 13\n",
      "layer index: 164 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 169 \t total channel: 64 \t remaining channel: 49\n",
      "layer index: 172 \t total channel: 32 \t remaining channel: 31\n",
      "layer index: 174 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 180 \t total channel: 128 \t remaining channel: 70\n",
      "layer index: 183 \t total channel: 32 \t remaining channel: 26\n",
      "layer index: 185 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 189 \t total channel: 128 \t remaining channel: 63\n",
      "layer index: 192 \t total channel: 32 \t remaining channel: 29\n",
      "layer index: 194 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 198 \t total channel: 128 \t remaining channel: 76\n",
      "layer index: 201 \t total channel: 32 \t remaining channel: 30\n",
      "layer index: 203 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 207 \t total channel: 128 \t remaining channel: 74\n",
      "layer index: 210 \t total channel: 32 \t remaining channel: 31\n",
      "layer index: 212 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 216 \t total channel: 128 \t remaining channel: 67\n",
      "layer index: 219 \t total channel: 32 \t remaining channel: 29\n",
      "layer index: 221 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 225 \t total channel: 128 \t remaining channel: 75\n",
      "layer index: 228 \t total channel: 32 \t remaining channel: 31\n",
      "layer index: 230 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 234 \t total channel: 128 \t remaining channel: 69\n",
      "layer index: 237 \t total channel: 32 \t remaining channel: 28\n",
      "layer index: 239 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 243 \t total channel: 128 \t remaining channel: 71\n",
      "layer index: 246 \t total channel: 32 \t remaining channel: 29\n",
      "layer index: 248 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 252 \t total channel: 128 \t remaining channel: 66\n",
      "layer index: 255 \t total channel: 32 \t remaining channel: 28\n",
      "layer index: 257 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 261 \t total channel: 128 \t remaining channel: 68\n",
      "layer index: 264 \t total channel: 32 \t remaining channel: 28\n",
      "layer index: 266 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 270 \t total channel: 128 \t remaining channel: 69\n",
      "layer index: 273 \t total channel: 32 \t remaining channel: 28\n",
      "layer index: 275 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 279 \t total channel: 128 \t remaining channel: 77\n",
      "layer index: 282 \t total channel: 32 \t remaining channel: 31\n",
      "layer index: 284 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 288 \t total channel: 128 \t remaining channel: 73\n",
      "layer index: 291 \t total channel: 32 \t remaining channel: 28\n",
      "layer index: 293 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 297 \t total channel: 128 \t remaining channel: 67\n",
      "layer index: 300 \t total channel: 32 \t remaining channel: 29\n",
      "layer index: 302 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 306 \t total channel: 128 \t remaining channel: 73\n",
      "layer index: 309 \t total channel: 32 \t remaining channel: 30\n",
      "layer index: 311 \t total channel: 32 \t remaining channel: 30\n",
      "layer index: 315 \t total channel: 128 \t remaining channel: 74\n",
      "layer index: 318 \t total channel: 32 \t remaining channel: 25\n",
      "layer index: 320 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 324 \t total channel: 128 \t remaining channel: 66\n",
      "layer index: 327 \t total channel: 32 \t remaining channel: 29\n",
      "layer index: 329 \t total channel: 32 \t remaining channel: 31\n",
      "layer index: 334 \t total channel: 128 \t remaining channel: 87\n",
      "layer index: 337 \t total channel: 64 \t remaining channel: 43\n",
      "layer index: 339 \t total channel: 64 \t remaining channel: 63\n",
      "layer index: 345 \t total channel: 256 \t remaining channel: 89\n",
      "layer index: 348 \t total channel: 64 \t remaining channel: 42\n",
      "layer index: 350 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 354 \t total channel: 256 \t remaining channel: 82\n",
      "layer index: 357 \t total channel: 64 \t remaining channel: 48\n",
      "layer index: 359 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 363 \t total channel: 256 \t remaining channel: 88\n",
      "layer index: 366 \t total channel: 64 \t remaining channel: 47\n",
      "layer index: 368 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 372 \t total channel: 256 \t remaining channel: 93\n",
      "layer index: 375 \t total channel: 64 \t remaining channel: 49\n",
      "layer index: 377 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 381 \t total channel: 256 \t remaining channel: 102\n",
      "layer index: 384 \t total channel: 64 \t remaining channel: 50\n",
      "layer index: 386 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 390 \t total channel: 256 \t remaining channel: 92\n",
      "layer index: 393 \t total channel: 64 \t remaining channel: 46\n",
      "layer index: 395 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 399 \t total channel: 256 \t remaining channel: 104\n",
      "layer index: 402 \t total channel: 64 \t remaining channel: 52\n",
      "layer index: 404 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 408 \t total channel: 256 \t remaining channel: 89\n",
      "layer index: 411 \t total channel: 64 \t remaining channel: 45\n",
      "layer index: 413 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 417 \t total channel: 256 \t remaining channel: 95\n",
      "layer index: 420 \t total channel: 64 \t remaining channel: 45\n",
      "layer index: 422 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 426 \t total channel: 256 \t remaining channel: 88\n",
      "layer index: 429 \t total channel: 64 \t remaining channel: 46\n",
      "layer index: 431 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 435 \t total channel: 256 \t remaining channel: 98\n",
      "layer index: 438 \t total channel: 64 \t remaining channel: 53\n",
      "layer index: 440 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 444 \t total channel: 256 \t remaining channel: 74\n",
      "layer index: 447 \t total channel: 64 \t remaining channel: 41\n",
      "layer index: 449 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 453 \t total channel: 256 \t remaining channel: 88\n",
      "layer index: 456 \t total channel: 64 \t remaining channel: 44\n",
      "layer index: 458 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 462 \t total channel: 256 \t remaining channel: 91\n",
      "layer index: 465 \t total channel: 64 \t remaining channel: 42\n",
      "layer index: 467 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 471 \t total channel: 256 \t remaining channel: 88\n",
      "layer index: 474 \t total channel: 64 \t remaining channel: 36\n",
      "layer index: 476 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 480 \t total channel: 256 \t remaining channel: 83\n",
      "layer index: 483 \t total channel: 64 \t remaining channel: 38\n",
      "layer index: 485 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 489 \t total channel: 256 \t remaining channel: 80\n",
      "layer index: 492 \t total channel: 64 \t remaining channel: 40\n",
      "layer index: 494 \t total channel: 64 \t remaining channel: 62\n",
      "layer index: 497 \t total channel: 256 \t remaining channel: 233\n",
      "Pre-processing Successful!\n",
      "\n",
      "Test set: Accuracy: 5071/10000 (50.7%)\n",
      "\n",
      "Cfg:\n",
      "[16, 15, 16, 43, 15, 16, 39, 16, 16, 36, 15, 16, 35, 13, 15, 33, 15, 15, 30, 11, 14, 36, 15, 15, 33, 15, 15, 35, 15, 16, 35, 13, 14, 28, 9, 15, 36, 14, 14, 36, 14, 14, 34, 14, 15, 36, 13, 16, 36, 12, 14, 31, 13, 16, 49, 31, 32, 70, 26, 32, 63, 29, 32, 76, 30, 32, 74, 31, 32, 67, 29, 32, 75, 31, 32, 69, 28, 32, 71, 29, 32, 66, 28, 32, 68, 28, 32, 69, 28, 32, 77, 31, 32, 73, 28, 32, 67, 29, 32, 73, 30, 30, 74, 25, 32, 66, 29, 31, 87, 43, 63, 89, 42, 64, 82, 48, 64, 88, 47, 64, 93, 49, 64, 102, 50, 64, 92, 46, 64, 104, 52, 64, 89, 45, 64, 95, 45, 64, 88, 46, 64, 98, 53, 64, 74, 41, 64, 88, 44, 64, 91, 42, 64, 88, 36, 64, 83, 38, 64, 80, 40, 62, 233]\n",
      "In shape: 16, Out shape 15.\n",
      "In shape: 15, Out shape 16.\n",
      "In shape: 16, Out shape 43.\n",
      "In shape: 43, Out shape 15.\n",
      "In shape: 15, Out shape 16.\n",
      "In shape: 16, Out shape 39.\n",
      "In shape: 39, Out shape 16.\n",
      "In shape: 16, Out shape 16.\n",
      "In shape: 16, Out shape 36.\n",
      "In shape: 36, Out shape 15.\n",
      "In shape: 15, Out shape 16.\n",
      "In shape: 16, Out shape 35.\n",
      "In shape: 35, Out shape 13.\n",
      "In shape: 13, Out shape 15.\n",
      "In shape: 15, Out shape 33.\n",
      "In shape: 33, Out shape 15.\n",
      "In shape: 15, Out shape 15.\n",
      "In shape: 15, Out shape 30.\n",
      "In shape: 30, Out shape 11.\n",
      "In shape: 11, Out shape 14.\n",
      "In shape: 14, Out shape 36.\n",
      "In shape: 36, Out shape 15.\n",
      "In shape: 15, Out shape 15.\n",
      "In shape: 15, Out shape 33.\n",
      "In shape: 33, Out shape 15.\n",
      "In shape: 15, Out shape 15.\n",
      "In shape: 15, Out shape 35.\n",
      "In shape: 35, Out shape 15.\n",
      "In shape: 15, Out shape 16.\n",
      "In shape: 16, Out shape 35.\n",
      "In shape: 35, Out shape 13.\n",
      "In shape: 13, Out shape 14.\n",
      "In shape: 14, Out shape 28.\n",
      "In shape: 28, Out shape 9.\n",
      "In shape: 9, Out shape 15.\n",
      "In shape: 15, Out shape 36.\n",
      "In shape: 36, Out shape 14.\n",
      "In shape: 14, Out shape 14.\n",
      "In shape: 14, Out shape 36.\n",
      "In shape: 36, Out shape 14.\n",
      "In shape: 14, Out shape 14.\n",
      "In shape: 14, Out shape 34.\n",
      "In shape: 34, Out shape 14.\n",
      "In shape: 14, Out shape 15.\n",
      "In shape: 15, Out shape 36.\n",
      "In shape: 36, Out shape 13.\n",
      "In shape: 13, Out shape 16.\n",
      "In shape: 16, Out shape 36.\n",
      "In shape: 36, Out shape 12.\n",
      "In shape: 12, Out shape 14.\n",
      "In shape: 14, Out shape 31.\n",
      "In shape: 31, Out shape 13.\n",
      "In shape: 13, Out shape 16.\n",
      "In shape: 16, Out shape 49.\n",
      "In shape: 49, Out shape 31.\n",
      "In shape: 31, Out shape 32.\n",
      "In shape: 32, Out shape 70.\n",
      "In shape: 70, Out shape 26.\n",
      "In shape: 26, Out shape 32.\n",
      "In shape: 32, Out shape 63.\n",
      "In shape: 63, Out shape 29.\n",
      "In shape: 29, Out shape 32.\n",
      "In shape: 32, Out shape 76.\n",
      "In shape: 76, Out shape 30.\n",
      "In shape: 30, Out shape 32.\n",
      "In shape: 32, Out shape 74.\n",
      "In shape: 74, Out shape 31.\n",
      "In shape: 31, Out shape 32.\n",
      "In shape: 32, Out shape 67.\n",
      "In shape: 67, Out shape 29.\n",
      "In shape: 29, Out shape 32.\n",
      "In shape: 32, Out shape 75.\n",
      "In shape: 75, Out shape 31.\n",
      "In shape: 31, Out shape 32.\n",
      "In shape: 32, Out shape 69.\n",
      "In shape: 69, Out shape 28.\n",
      "In shape: 28, Out shape 32.\n",
      "In shape: 32, Out shape 71.\n",
      "In shape: 71, Out shape 29.\n",
      "In shape: 29, Out shape 32.\n",
      "In shape: 32, Out shape 66.\n",
      "In shape: 66, Out shape 28.\n",
      "In shape: 28, Out shape 32.\n",
      "In shape: 32, Out shape 68.\n",
      "In shape: 68, Out shape 28.\n",
      "In shape: 28, Out shape 32.\n",
      "In shape: 32, Out shape 69.\n",
      "In shape: 69, Out shape 28.\n",
      "In shape: 28, Out shape 32.\n",
      "In shape: 32, Out shape 77.\n",
      "In shape: 77, Out shape 31.\n",
      "In shape: 31, Out shape 32.\n",
      "In shape: 32, Out shape 73.\n",
      "In shape: 73, Out shape 28.\n",
      "In shape: 28, Out shape 32.\n",
      "In shape: 32, Out shape 67.\n",
      "In shape: 67, Out shape 29.\n",
      "In shape: 29, Out shape 32.\n",
      "In shape: 32, Out shape 73.\n",
      "In shape: 73, Out shape 30.\n",
      "In shape: 30, Out shape 30.\n",
      "In shape: 30, Out shape 74.\n",
      "In shape: 74, Out shape 25.\n",
      "In shape: 25, Out shape 32.\n",
      "In shape: 32, Out shape 66.\n",
      "In shape: 66, Out shape 29.\n",
      "In shape: 29, Out shape 31.\n",
      "In shape: 31, Out shape 87.\n",
      "In shape: 87, Out shape 43.\n",
      "In shape: 43, Out shape 63.\n",
      "In shape: 63, Out shape 89.\n",
      "In shape: 89, Out shape 42.\n",
      "In shape: 42, Out shape 64.\n",
      "In shape: 64, Out shape 82.\n",
      "In shape: 82, Out shape 48.\n",
      "In shape: 48, Out shape 64.\n",
      "In shape: 64, Out shape 88.\n",
      "In shape: 88, Out shape 47.\n",
      "In shape: 47, Out shape 64.\n",
      "In shape: 64, Out shape 93.\n",
      "In shape: 93, Out shape 49.\n",
      "In shape: 49, Out shape 64.\n",
      "In shape: 64, Out shape 102.\n",
      "In shape: 102, Out shape 50.\n",
      "In shape: 50, Out shape 64.\n",
      "In shape: 64, Out shape 92.\n",
      "In shape: 92, Out shape 46.\n",
      "In shape: 46, Out shape 64.\n",
      "In shape: 64, Out shape 104.\n",
      "In shape: 104, Out shape 52.\n",
      "In shape: 52, Out shape 64.\n",
      "In shape: 64, Out shape 89.\n",
      "In shape: 89, Out shape 45.\n",
      "In shape: 45, Out shape 64.\n",
      "In shape: 64, Out shape 95.\n",
      "In shape: 95, Out shape 45.\n",
      "In shape: 45, Out shape 64.\n",
      "In shape: 64, Out shape 88.\n",
      "In shape: 88, Out shape 46.\n",
      "In shape: 46, Out shape 64.\n",
      "In shape: 64, Out shape 98.\n",
      "In shape: 98, Out shape 53.\n",
      "In shape: 53, Out shape 64.\n",
      "In shape: 64, Out shape 74.\n",
      "In shape: 74, Out shape 41.\n",
      "In shape: 41, Out shape 64.\n",
      "In shape: 64, Out shape 88.\n",
      "In shape: 88, Out shape 44.\n",
      "In shape: 44, Out shape 64.\n",
      "In shape: 64, Out shape 91.\n",
      "In shape: 91, Out shape 42.\n",
      "In shape: 42, Out shape 64.\n",
      "In shape: 64, Out shape 88.\n",
      "In shape: 88, Out shape 36.\n",
      "In shape: 36, Out shape 64.\n",
      "In shape: 64, Out shape 83.\n",
      "In shape: 83, Out shape 38.\n",
      "In shape: 38, Out shape 64.\n",
      "In shape: 64, Out shape 80.\n",
      "In shape: 80, Out shape 40.\n",
      "In shape: 40, Out shape 62.\n",
      "In shape: 62, Out shape 233.\n",
      "resnet(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(16, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(43, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(39, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(36, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(35, 13, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(13, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(15, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(33, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(15, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(30, 11, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(11, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(14, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(36, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(15, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(33, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(15, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(35, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(35, 13, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(13, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(14, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(28, 9, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(9, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(15, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(36, 14, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(14, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(14, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(36, 14, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(14, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(14, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(34, 14, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(14, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(15, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(36, 13, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(13, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(36, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(12, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(14, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(31, 13, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(13, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(49, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(31, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(70, 26, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(26, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(63, 29, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(29, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(76, 30, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(30, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(74, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(31, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(67, 29, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(29, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(75, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(31, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(69, 28, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(28, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(71, 29, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(29, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(66, 28, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(28, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(68, 28, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(28, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(69, 28, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(28, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(77, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(31, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(73, 28, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(28, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(67, 29, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(29, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(73, 30, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(30, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(74, 25, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(25, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(66, 29, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(29, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(31, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(87, 43, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(43, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(43, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(63, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(89, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(42, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(42, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(82, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(88, 47, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(47, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(47, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(93, 49, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(49, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(102, 50, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(50, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(92, 46, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(46, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(104, 52, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(52, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(89, 45, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(45, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(95, 45, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(45, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(88, 46, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(46, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(98, 53, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(53, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(74, 41, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(41, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(41, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(88, 44, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(44, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(91, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(42, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(42, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(88, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(36, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(83, 38, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(38, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(40, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(62, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (select): channel_selection()\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
      "  (fc): Linear(in_features=233, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "Test set: Accuracy: 5071/10000 (50.7%)\n",
      "\n",
      "Train Epoch: 0 [0/50000 (0.0%)]\tLoss: 0.340380\n",
      "Train Epoch: 0 [6400/50000 (12.8%)]\tLoss: 0.407786\n",
      "Train Epoch: 0 [12800/50000 (25.6%)]\tLoss: 0.465974\n",
      "Train Epoch: 0 [19200/50000 (38.4%)]\tLoss: 0.664307\n",
      "Train Epoch: 0 [25600/50000 (51.2%)]\tLoss: 0.476531\n",
      "Train Epoch: 0 [32000/50000 (63.9%)]\tLoss: 0.513288\n",
      "Train Epoch: 0 [38400/50000 (76.7%)]\tLoss: 0.566484\n",
      "Train Epoch: 0 [44800/50000 (89.5%)]\tLoss: 0.479722\n",
      "\n",
      "Test set: Average loss: 0.6705, Accuracy: 7769/10000 (77.7%)\n",
      "\n",
      "Train Epoch: 1 [0/50000 (0.0%)]\tLoss: 0.567451\n",
      "Train Epoch: 1 [6400/50000 (12.8%)]\tLoss: 0.560851\n",
      "Train Epoch: 1 [12800/50000 (25.6%)]\tLoss: 0.413463\n",
      "Train Epoch: 1 [19200/50000 (38.4%)]\tLoss: 0.591619\n",
      "Train Epoch: 1 [25600/50000 (51.2%)]\tLoss: 0.581424\n",
      "Train Epoch: 1 [32000/50000 (63.9%)]\tLoss: 0.401528\n",
      "Train Epoch: 1 [38400/50000 (76.7%)]\tLoss: 0.616680\n",
      "Train Epoch: 1 [44800/50000 (89.5%)]\tLoss: 0.409103\n",
      "\n",
      "Test set: Average loss: 0.7600, Accuracy: 7549/10000 (75.5%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0.0%)]\tLoss: 0.509668\n",
      "Train Epoch: 2 [6400/50000 (12.8%)]\tLoss: 0.545717\n",
      "Train Epoch: 2 [12800/50000 (25.6%)]\tLoss: 0.534903\n",
      "Train Epoch: 2 [19200/50000 (38.4%)]\tLoss: 0.581557\n",
      "Train Epoch: 2 [25600/50000 (51.2%)]\tLoss: 0.572267\n",
      "Train Epoch: 2 [32000/50000 (63.9%)]\tLoss: 0.467849\n",
      "Train Epoch: 2 [38400/50000 (76.7%)]\tLoss: 0.620295\n",
      "Train Epoch: 2 [44800/50000 (89.5%)]\tLoss: 0.340722\n",
      "\n",
      "Test set: Average loss: 0.5934, Accuracy: 8022/10000 (80.2%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0.0%)]\tLoss: 0.600450\n",
      "Train Epoch: 3 [6400/50000 (12.8%)]\tLoss: 0.418644\n",
      "Train Epoch: 3 [12800/50000 (25.6%)]\tLoss: 0.480456\n",
      "Train Epoch: 3 [19200/50000 (38.4%)]\tLoss: 0.651853\n",
      "Train Epoch: 3 [25600/50000 (51.2%)]\tLoss: 0.342786\n",
      "Train Epoch: 3 [32000/50000 (63.9%)]\tLoss: 0.600052\n",
      "Train Epoch: 3 [38400/50000 (76.7%)]\tLoss: 0.533009\n",
      "Train Epoch: 3 [44800/50000 (89.5%)]\tLoss: 0.710905\n",
      "\n",
      "Test set: Average loss: 0.5522, Accuracy: 8151/10000 (81.5%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0.0%)]\tLoss: 0.343310\n",
      "Train Epoch: 4 [6400/50000 (12.8%)]\tLoss: 0.499304\n",
      "Train Epoch: 4 [12800/50000 (25.6%)]\tLoss: 0.360875\n",
      "Train Epoch: 4 [19200/50000 (38.4%)]\tLoss: 0.536272\n",
      "Train Epoch: 4 [25600/50000 (51.2%)]\tLoss: 0.331925\n",
      "Train Epoch: 4 [32000/50000 (63.9%)]\tLoss: 0.336693\n",
      "Train Epoch: 4 [38400/50000 (76.7%)]\tLoss: 0.273724\n",
      "Train Epoch: 4 [44800/50000 (89.5%)]\tLoss: 0.508440\n",
      "\n",
      "Test set: Average loss: 0.6074, Accuracy: 8033/10000 (80.3%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0.0%)]\tLoss: 0.505743\n",
      "Train Epoch: 5 [6400/50000 (12.8%)]\tLoss: 0.413205\n",
      "Train Epoch: 5 [12800/50000 (25.6%)]\tLoss: 0.673968\n",
      "Train Epoch: 5 [19200/50000 (38.4%)]\tLoss: 0.410198\n",
      "Train Epoch: 5 [25600/50000 (51.2%)]\tLoss: 0.487667\n",
      "Train Epoch: 5 [32000/50000 (63.9%)]\tLoss: 0.472004\n",
      "Train Epoch: 5 [38400/50000 (76.7%)]\tLoss: 0.477765\n",
      "Train Epoch: 5 [44800/50000 (89.5%)]\tLoss: 0.360194\n",
      "\n",
      "Test set: Average loss: 0.6122, Accuracy: 8044/10000 (80.4%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0.0%)]\tLoss: 0.480790\n",
      "Train Epoch: 6 [6400/50000 (12.8%)]\tLoss: 0.429151\n",
      "Train Epoch: 6 [12800/50000 (25.6%)]\tLoss: 0.499817\n",
      "Train Epoch: 6 [19200/50000 (38.4%)]\tLoss: 0.329695\n",
      "Train Epoch: 6 [25600/50000 (51.2%)]\tLoss: 0.489145\n",
      "Train Epoch: 6 [32000/50000 (63.9%)]\tLoss: 0.436217\n",
      "Train Epoch: 6 [38400/50000 (76.7%)]\tLoss: 0.406520\n",
      "Train Epoch: 6 [44800/50000 (89.5%)]\tLoss: 0.305589\n",
      "\n",
      "Test set: Average loss: 0.6701, Accuracy: 7768/10000 (77.7%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0.0%)]\tLoss: 0.502946\n",
      "Train Epoch: 7 [6400/50000 (12.8%)]\tLoss: 0.511851\n",
      "Train Epoch: 7 [12800/50000 (25.6%)]\tLoss: 0.476492\n",
      "Train Epoch: 7 [19200/50000 (38.4%)]\tLoss: 0.504180\n",
      "Train Epoch: 7 [25600/50000 (51.2%)]\tLoss: 0.502774\n",
      "Train Epoch: 7 [32000/50000 (63.9%)]\tLoss: 0.313034\n",
      "Train Epoch: 7 [38400/50000 (76.7%)]\tLoss: 0.812110\n",
      "Train Epoch: 7 [44800/50000 (89.5%)]\tLoss: 0.476811\n",
      "\n",
      "Test set: Average loss: 0.5191, Accuracy: 8278/10000 (82.8%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0.0%)]\tLoss: 0.507984\n",
      "Train Epoch: 8 [6400/50000 (12.8%)]\tLoss: 0.319811\n",
      "Train Epoch: 8 [12800/50000 (25.6%)]\tLoss: 0.340097\n",
      "Train Epoch: 8 [19200/50000 (38.4%)]\tLoss: 0.382400\n",
      "Train Epoch: 8 [25600/50000 (51.2%)]\tLoss: 0.411830\n",
      "Train Epoch: 8 [32000/50000 (63.9%)]\tLoss: 0.469350\n",
      "Train Epoch: 8 [38400/50000 (76.7%)]\tLoss: 0.460735\n",
      "Train Epoch: 8 [44800/50000 (89.5%)]\tLoss: 0.362270\n",
      "\n",
      "Test set: Average loss: 0.5085, Accuracy: 8337/10000 (83.4%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0.0%)]\tLoss: 0.513563\n",
      "Train Epoch: 9 [6400/50000 (12.8%)]\tLoss: 0.372339\n",
      "Train Epoch: 9 [12800/50000 (25.6%)]\tLoss: 0.335633\n",
      "Train Epoch: 9 [19200/50000 (38.4%)]\tLoss: 0.368269\n",
      "Train Epoch: 9 [25600/50000 (51.2%)]\tLoss: 0.500171\n",
      "Train Epoch: 9 [32000/50000 (63.9%)]\tLoss: 0.567160\n",
      "Train Epoch: 9 [38400/50000 (76.7%)]\tLoss: 0.500533\n",
      "Train Epoch: 9 [44800/50000 (89.5%)]\tLoss: 0.315567\n",
      "\n",
      "Test set: Average loss: 0.5671, Accuracy: 8125/10000 (81.2%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0.0%)]\tLoss: 0.301237\n",
      "Train Epoch: 10 [6400/50000 (12.8%)]\tLoss: 0.210501\n",
      "Train Epoch: 10 [12800/50000 (25.6%)]\tLoss: 0.175927\n",
      "Train Epoch: 10 [19200/50000 (38.4%)]\tLoss: 0.135640\n",
      "Train Epoch: 10 [25600/50000 (51.2%)]\tLoss: 0.339151\n",
      "Train Epoch: 10 [32000/50000 (63.9%)]\tLoss: 0.211436\n",
      "Train Epoch: 10 [38400/50000 (76.7%)]\tLoss: 0.209392\n",
      "Train Epoch: 10 [44800/50000 (89.5%)]\tLoss: 0.150578\n",
      "\n",
      "Test set: Average loss: 0.2723, Accuracy: 9074/10000 (90.7%)\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0.0%)]\tLoss: 0.206269\n",
      "Train Epoch: 11 [6400/50000 (12.8%)]\tLoss: 0.218167\n",
      "Train Epoch: 11 [12800/50000 (25.6%)]\tLoss: 0.266649\n",
      "Train Epoch: 11 [19200/50000 (38.4%)]\tLoss: 0.160186\n",
      "Train Epoch: 11 [25600/50000 (51.2%)]\tLoss: 0.336245\n",
      "Train Epoch: 11 [32000/50000 (63.9%)]\tLoss: 0.126277\n",
      "Train Epoch: 11 [38400/50000 (76.7%)]\tLoss: 0.178978\n",
      "Train Epoch: 11 [44800/50000 (89.5%)]\tLoss: 0.279421\n",
      "\n",
      "Test set: Average loss: 0.2674, Accuracy: 9090/10000 (90.9%)\n",
      "\n",
      "Train Epoch: 12 [0/50000 (0.0%)]\tLoss: 0.206797\n",
      "Train Epoch: 12 [6400/50000 (12.8%)]\tLoss: 0.280312\n",
      "Train Epoch: 12 [12800/50000 (25.6%)]\tLoss: 0.142262\n",
      "Train Epoch: 12 [19200/50000 (38.4%)]\tLoss: 0.318192\n",
      "Train Epoch: 12 [25600/50000 (51.2%)]\tLoss: 0.194019\n",
      "Train Epoch: 12 [32000/50000 (63.9%)]\tLoss: 0.130461\n",
      "Train Epoch: 12 [38400/50000 (76.7%)]\tLoss: 0.122439\n",
      "Train Epoch: 12 [44800/50000 (89.5%)]\tLoss: 0.265002\n",
      "\n",
      "Test set: Average loss: 0.2649, Accuracy: 9122/10000 (91.2%)\n",
      "\n",
      "Train Epoch: 13 [0/50000 (0.0%)]\tLoss: 0.139099\n",
      "Train Epoch: 13 [6400/50000 (12.8%)]\tLoss: 0.192176\n",
      "Train Epoch: 13 [12800/50000 (25.6%)]\tLoss: 0.140831\n",
      "Train Epoch: 13 [19200/50000 (38.4%)]\tLoss: 0.024072\n",
      "Train Epoch: 13 [25600/50000 (51.2%)]\tLoss: 0.222601\n",
      "Train Epoch: 13 [32000/50000 (63.9%)]\tLoss: 0.188876\n",
      "Train Epoch: 13 [38400/50000 (76.7%)]\tLoss: 0.214810\n",
      "Train Epoch: 13 [44800/50000 (89.5%)]\tLoss: 0.145241\n",
      "\n",
      "Test set: Average loss: 0.2523, Accuracy: 9156/10000 (91.6%)\n",
      "\n",
      "Train Epoch: 14 [0/50000 (0.0%)]\tLoss: 0.169011\n",
      "Train Epoch: 14 [6400/50000 (12.8%)]\tLoss: 0.241539\n",
      "Train Epoch: 14 [12800/50000 (25.6%)]\tLoss: 0.089870\n",
      "Train Epoch: 14 [19200/50000 (38.4%)]\tLoss: 0.268935\n",
      "Train Epoch: 14 [25600/50000 (51.2%)]\tLoss: 0.140598\n",
      "Train Epoch: 14 [32000/50000 (63.9%)]\tLoss: 0.135935\n",
      "Train Epoch: 14 [38400/50000 (76.7%)]\tLoss: 0.238244\n",
      "Train Epoch: 14 [44800/50000 (89.5%)]\tLoss: 0.121540\n",
      "\n",
      "Test set: Average loss: 0.2583, Accuracy: 9141/10000 (91.4%)\n",
      "\n",
      "Train Epoch: 15 [0/50000 (0.0%)]\tLoss: 0.164817\n",
      "Train Epoch: 15 [6400/50000 (12.8%)]\tLoss: 0.239292\n",
      "Train Epoch: 15 [12800/50000 (25.6%)]\tLoss: 0.183122\n",
      "Train Epoch: 15 [19200/50000 (38.4%)]\tLoss: 0.134522\n",
      "Train Epoch: 15 [25600/50000 (51.2%)]\tLoss: 0.161290\n",
      "Train Epoch: 15 [32000/50000 (63.9%)]\tLoss: 0.202066\n",
      "Train Epoch: 15 [38400/50000 (76.7%)]\tLoss: 0.065166\n",
      "Train Epoch: 15 [44800/50000 (89.5%)]\tLoss: 0.216897\n",
      "\n",
      "Test set: Average loss: 0.2496, Accuracy: 9163/10000 (91.6%)\n",
      "\n",
      "Train Epoch: 16 [0/50000 (0.0%)]\tLoss: 0.186197\n",
      "Train Epoch: 16 [6400/50000 (12.8%)]\tLoss: 0.155064\n",
      "Train Epoch: 16 [12800/50000 (25.6%)]\tLoss: 0.279109\n",
      "Train Epoch: 16 [19200/50000 (38.4%)]\tLoss: 0.249913\n",
      "Train Epoch: 16 [25600/50000 (51.2%)]\tLoss: 0.143506\n",
      "Train Epoch: 16 [32000/50000 (63.9%)]\tLoss: 0.267092\n",
      "Train Epoch: 16 [38400/50000 (76.7%)]\tLoss: 0.099812\n",
      "Train Epoch: 16 [44800/50000 (89.5%)]\tLoss: 0.157468\n",
      "\n",
      "Test set: Average loss: 0.2466, Accuracy: 9191/10000 (91.9%)\n",
      "\n",
      "Train Epoch: 17 [0/50000 (0.0%)]\tLoss: 0.159470\n",
      "Train Epoch: 17 [6400/50000 (12.8%)]\tLoss: 0.108124\n",
      "Train Epoch: 17 [12800/50000 (25.6%)]\tLoss: 0.169232\n",
      "Train Epoch: 17 [19200/50000 (38.4%)]\tLoss: 0.102543\n",
      "Train Epoch: 17 [25600/50000 (51.2%)]\tLoss: 0.093452\n",
      "Train Epoch: 17 [32000/50000 (63.9%)]\tLoss: 0.231656\n",
      "Train Epoch: 17 [38400/50000 (76.7%)]\tLoss: 0.091814\n",
      "Train Epoch: 17 [44800/50000 (89.5%)]\tLoss: 0.168386\n",
      "\n",
      "Test set: Average loss: 0.2449, Accuracy: 9208/10000 (92.1%)\n",
      "\n",
      "Train Epoch: 18 [0/50000 (0.0%)]\tLoss: 0.116458\n",
      "Train Epoch: 18 [6400/50000 (12.8%)]\tLoss: 0.138037\n",
      "Train Epoch: 18 [12800/50000 (25.6%)]\tLoss: 0.058047\n",
      "Train Epoch: 18 [19200/50000 (38.4%)]\tLoss: 0.134126\n",
      "Train Epoch: 18 [25600/50000 (51.2%)]\tLoss: 0.153946\n",
      "Train Epoch: 18 [32000/50000 (63.9%)]\tLoss: 0.101658\n",
      "Train Epoch: 18 [38400/50000 (76.7%)]\tLoss: 0.079468\n",
      "Train Epoch: 18 [44800/50000 (89.5%)]\tLoss: 0.169180\n",
      "\n",
      "Test set: Average loss: 0.2500, Accuracy: 9178/10000 (91.8%)\n",
      "\n",
      "Train Epoch: 19 [0/50000 (0.0%)]\tLoss: 0.166271\n",
      "Train Epoch: 19 [6400/50000 (12.8%)]\tLoss: 0.234754\n",
      "Train Epoch: 19 [12800/50000 (25.6%)]\tLoss: 0.273506\n",
      "Train Epoch: 19 [19200/50000 (38.4%)]\tLoss: 0.237838\n",
      "Train Epoch: 19 [25600/50000 (51.2%)]\tLoss: 0.161236\n",
      "Train Epoch: 19 [32000/50000 (63.9%)]\tLoss: 0.152900\n",
      "Train Epoch: 19 [38400/50000 (76.7%)]\tLoss: 0.136114\n",
      "Train Epoch: 19 [44800/50000 (89.5%)]\tLoss: 0.140224\n",
      "\n",
      "Test set: Average loss: 0.2456, Accuracy: 9200/10000 (92.0%)\n",
      "\n",
      "Best accuracy: tensor(0.9208)\n",
      "Number of parameters: 1224413\n",
      "Average Time taken: 129.04645744562148\n",
      "Iteration:  6 Percent:  0.5\n",
      "=> loading checkpoint '/kaggle/working/model_best.pth.tar'\n",
      "=> loaded checkpoint '/kaggle/working/model_best.pth.tar' (epoch 19) Prec1: 0.895400\n",
      "layer index: 4 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 7 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 9 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 15 \t total channel: 64 \t remaining channel: 39\n",
      "layer index: 18 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 20 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 24 \t total channel: 64 \t remaining channel: 37\n",
      "layer index: 27 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 29 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 33 \t total channel: 64 \t remaining channel: 33\n",
      "layer index: 36 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 38 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 42 \t total channel: 64 \t remaining channel: 28\n",
      "layer index: 45 \t total channel: 16 \t remaining channel: 13\n",
      "layer index: 47 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 51 \t total channel: 64 \t remaining channel: 31\n",
      "layer index: 54 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 56 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 60 \t total channel: 64 \t remaining channel: 29\n",
      "layer index: 63 \t total channel: 16 \t remaining channel: 11\n",
      "layer index: 65 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 69 \t total channel: 64 \t remaining channel: 32\n",
      "layer index: 72 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 74 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 78 \t total channel: 64 \t remaining channel: 27\n",
      "layer index: 81 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 83 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 87 \t total channel: 64 \t remaining channel: 32\n",
      "layer index: 90 \t total channel: 16 \t remaining channel: 13\n",
      "layer index: 92 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 96 \t total channel: 64 \t remaining channel: 33\n",
      "layer index: 99 \t total channel: 16 \t remaining channel: 13\n",
      "layer index: 101 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 105 \t total channel: 64 \t remaining channel: 26\n",
      "layer index: 108 \t total channel: 16 \t remaining channel: 8\n",
      "layer index: 110 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 114 \t total channel: 64 \t remaining channel: 32\n",
      "layer index: 117 \t total channel: 16 \t remaining channel: 13\n",
      "layer index: 119 \t total channel: 16 \t remaining channel: 13\n",
      "layer index: 123 \t total channel: 64 \t remaining channel: 30\n",
      "layer index: 126 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 128 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 132 \t total channel: 64 \t remaining channel: 30\n",
      "layer index: 135 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 137 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 141 \t total channel: 64 \t remaining channel: 28\n",
      "layer index: 144 \t total channel: 16 \t remaining channel: 11\n",
      "layer index: 146 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 150 \t total channel: 64 \t remaining channel: 28\n",
      "layer index: 153 \t total channel: 16 \t remaining channel: 12\n",
      "layer index: 155 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 159 \t total channel: 64 \t remaining channel: 27\n",
      "layer index: 162 \t total channel: 16 \t remaining channel: 13\n",
      "layer index: 164 \t total channel: 16 \t remaining channel: 13\n",
      "layer index: 169 \t total channel: 64 \t remaining channel: 47\n",
      "layer index: 172 \t total channel: 32 \t remaining channel: 31\n",
      "layer index: 174 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 180 \t total channel: 128 \t remaining channel: 59\n",
      "layer index: 183 \t total channel: 32 \t remaining channel: 26\n",
      "layer index: 185 \t total channel: 32 \t remaining channel: 31\n",
      "layer index: 189 \t total channel: 128 \t remaining channel: 53\n",
      "layer index: 192 \t total channel: 32 \t remaining channel: 26\n",
      "layer index: 194 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 198 \t total channel: 128 \t remaining channel: 57\n",
      "layer index: 201 \t total channel: 32 \t remaining channel: 30\n",
      "layer index: 203 \t total channel: 32 \t remaining channel: 31\n",
      "layer index: 207 \t total channel: 128 \t remaining channel: 60\n",
      "layer index: 210 \t total channel: 32 \t remaining channel: 31\n",
      "layer index: 212 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 216 \t total channel: 128 \t remaining channel: 53\n",
      "layer index: 219 \t total channel: 32 \t remaining channel: 29\n",
      "layer index: 221 \t total channel: 32 \t remaining channel: 31\n",
      "layer index: 225 \t total channel: 128 \t remaining channel: 56\n",
      "layer index: 228 \t total channel: 32 \t remaining channel: 30\n",
      "layer index: 230 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 234 \t total channel: 128 \t remaining channel: 62\n",
      "layer index: 237 \t total channel: 32 \t remaining channel: 24\n",
      "layer index: 239 \t total channel: 32 \t remaining channel: 31\n",
      "layer index: 243 \t total channel: 128 \t remaining channel: 52\n",
      "layer index: 246 \t total channel: 32 \t remaining channel: 29\n",
      "layer index: 248 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 252 \t total channel: 128 \t remaining channel: 52\n",
      "layer index: 255 \t total channel: 32 \t remaining channel: 28\n",
      "layer index: 257 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 261 \t total channel: 128 \t remaining channel: 44\n",
      "layer index: 264 \t total channel: 32 \t remaining channel: 26\n",
      "layer index: 266 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 270 \t total channel: 128 \t remaining channel: 50\n",
      "layer index: 273 \t total channel: 32 \t remaining channel: 27\n",
      "layer index: 275 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 279 \t total channel: 128 \t remaining channel: 59\n",
      "layer index: 282 \t total channel: 32 \t remaining channel: 29\n",
      "layer index: 284 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 288 \t total channel: 128 \t remaining channel: 56\n",
      "layer index: 291 \t total channel: 32 \t remaining channel: 22\n",
      "layer index: 293 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 297 \t total channel: 128 \t remaining channel: 56\n",
      "layer index: 300 \t total channel: 32 \t remaining channel: 27\n",
      "layer index: 302 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 306 \t total channel: 128 \t remaining channel: 58\n",
      "layer index: 309 \t total channel: 32 \t remaining channel: 26\n",
      "layer index: 311 \t total channel: 32 \t remaining channel: 30\n",
      "layer index: 315 \t total channel: 128 \t remaining channel: 59\n",
      "layer index: 318 \t total channel: 32 \t remaining channel: 25\n",
      "layer index: 320 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 324 \t total channel: 128 \t remaining channel: 55\n",
      "layer index: 327 \t total channel: 32 \t remaining channel: 27\n",
      "layer index: 329 \t total channel: 32 \t remaining channel: 31\n",
      "layer index: 334 \t total channel: 128 \t remaining channel: 68\n",
      "layer index: 337 \t total channel: 64 \t remaining channel: 33\n",
      "layer index: 339 \t total channel: 64 \t remaining channel: 63\n",
      "layer index: 345 \t total channel: 256 \t remaining channel: 47\n",
      "layer index: 348 \t total channel: 64 \t remaining channel: 33\n",
      "layer index: 350 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 354 \t total channel: 256 \t remaining channel: 52\n",
      "layer index: 357 \t total channel: 64 \t remaining channel: 42\n",
      "layer index: 359 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 363 \t total channel: 256 \t remaining channel: 52\n",
      "layer index: 366 \t total channel: 64 \t remaining channel: 41\n",
      "layer index: 368 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 372 \t total channel: 256 \t remaining channel: 56\n",
      "layer index: 375 \t total channel: 64 \t remaining channel: 39\n",
      "layer index: 377 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 381 \t total channel: 256 \t remaining channel: 66\n",
      "layer index: 384 \t total channel: 64 \t remaining channel: 42\n",
      "layer index: 386 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 390 \t total channel: 256 \t remaining channel: 61\n",
      "layer index: 393 \t total channel: 64 \t remaining channel: 37\n",
      "layer index: 395 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 399 \t total channel: 256 \t remaining channel: 68\n",
      "layer index: 402 \t total channel: 64 \t remaining channel: 39\n",
      "layer index: 404 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 408 \t total channel: 256 \t remaining channel: 45\n",
      "layer index: 411 \t total channel: 64 \t remaining channel: 33\n",
      "layer index: 413 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 417 \t total channel: 256 \t remaining channel: 51\n",
      "layer index: 420 \t total channel: 64 \t remaining channel: 36\n",
      "layer index: 422 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 426 \t total channel: 256 \t remaining channel: 56\n",
      "layer index: 429 \t total channel: 64 \t remaining channel: 34\n",
      "layer index: 431 \t total channel: 64 \t remaining channel: 63\n",
      "layer index: 435 \t total channel: 256 \t remaining channel: 61\n",
      "layer index: 438 \t total channel: 64 \t remaining channel: 41\n",
      "layer index: 440 \t total channel: 64 \t remaining channel: 63\n",
      "layer index: 444 \t total channel: 256 \t remaining channel: 54\n",
      "layer index: 447 \t total channel: 64 \t remaining channel: 26\n",
      "layer index: 449 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 453 \t total channel: 256 \t remaining channel: 50\n",
      "layer index: 456 \t total channel: 64 \t remaining channel: 29\n",
      "layer index: 458 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 462 \t total channel: 256 \t remaining channel: 55\n",
      "layer index: 465 \t total channel: 64 \t remaining channel: 31\n",
      "layer index: 467 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 471 \t total channel: 256 \t remaining channel: 43\n",
      "layer index: 474 \t total channel: 64 \t remaining channel: 26\n",
      "layer index: 476 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 480 \t total channel: 256 \t remaining channel: 46\n",
      "layer index: 483 \t total channel: 64 \t remaining channel: 23\n",
      "layer index: 485 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 489 \t total channel: 256 \t remaining channel: 44\n",
      "layer index: 492 \t total channel: 64 \t remaining channel: 29\n",
      "layer index: 494 \t total channel: 64 \t remaining channel: 62\n",
      "layer index: 497 \t total channel: 256 \t remaining channel: 227\n",
      "Pre-processing Successful!\n",
      "\n",
      "Test set: Accuracy: 3085/10000 (30.9%)\n",
      "\n",
      "Cfg:\n",
      "[15, 15, 16, 39, 15, 16, 37, 15, 16, 33, 15, 16, 28, 13, 14, 31, 14, 15, 29, 11, 14, 32, 15, 15, 27, 15, 15, 32, 13, 16, 33, 13, 14, 26, 8, 14, 32, 13, 13, 30, 14, 14, 30, 14, 15, 28, 11, 16, 28, 12, 14, 27, 13, 13, 47, 31, 32, 59, 26, 31, 53, 26, 32, 57, 30, 31, 60, 31, 32, 53, 29, 31, 56, 30, 32, 62, 24, 31, 52, 29, 32, 52, 28, 32, 44, 26, 32, 50, 27, 32, 59, 29, 32, 56, 22, 32, 56, 27, 32, 58, 26, 30, 59, 25, 32, 55, 27, 31, 68, 33, 63, 47, 33, 64, 52, 42, 64, 52, 41, 64, 56, 39, 64, 66, 42, 64, 61, 37, 64, 68, 39, 64, 45, 33, 64, 51, 36, 64, 56, 34, 63, 61, 41, 63, 54, 26, 64, 50, 29, 64, 55, 31, 64, 43, 26, 64, 46, 23, 64, 44, 29, 62, 227]\n",
      "In shape: 15, Out shape 15.\n",
      "In shape: 15, Out shape 16.\n",
      "In shape: 16, Out shape 39.\n",
      "In shape: 39, Out shape 15.\n",
      "In shape: 15, Out shape 16.\n",
      "In shape: 16, Out shape 37.\n",
      "In shape: 37, Out shape 15.\n",
      "In shape: 15, Out shape 16.\n",
      "In shape: 16, Out shape 33.\n",
      "In shape: 33, Out shape 15.\n",
      "In shape: 15, Out shape 16.\n",
      "In shape: 16, Out shape 28.\n",
      "In shape: 28, Out shape 13.\n",
      "In shape: 13, Out shape 14.\n",
      "In shape: 14, Out shape 31.\n",
      "In shape: 31, Out shape 14.\n",
      "In shape: 14, Out shape 15.\n",
      "In shape: 15, Out shape 29.\n",
      "In shape: 29, Out shape 11.\n",
      "In shape: 11, Out shape 14.\n",
      "In shape: 14, Out shape 32.\n",
      "In shape: 32, Out shape 15.\n",
      "In shape: 15, Out shape 15.\n",
      "In shape: 15, Out shape 27.\n",
      "In shape: 27, Out shape 15.\n",
      "In shape: 15, Out shape 15.\n",
      "In shape: 15, Out shape 32.\n",
      "In shape: 32, Out shape 13.\n",
      "In shape: 13, Out shape 16.\n",
      "In shape: 16, Out shape 33.\n",
      "In shape: 33, Out shape 13.\n",
      "In shape: 13, Out shape 14.\n",
      "In shape: 14, Out shape 26.\n",
      "In shape: 26, Out shape 8.\n",
      "In shape: 8, Out shape 14.\n",
      "In shape: 14, Out shape 32.\n",
      "In shape: 32, Out shape 13.\n",
      "In shape: 13, Out shape 13.\n",
      "In shape: 13, Out shape 30.\n",
      "In shape: 30, Out shape 14.\n",
      "In shape: 14, Out shape 14.\n",
      "In shape: 14, Out shape 30.\n",
      "In shape: 30, Out shape 14.\n",
      "In shape: 14, Out shape 15.\n",
      "In shape: 15, Out shape 28.\n",
      "In shape: 28, Out shape 11.\n",
      "In shape: 11, Out shape 16.\n",
      "In shape: 16, Out shape 28.\n",
      "In shape: 28, Out shape 12.\n",
      "In shape: 12, Out shape 14.\n",
      "In shape: 14, Out shape 27.\n",
      "In shape: 27, Out shape 13.\n",
      "In shape: 13, Out shape 13.\n",
      "In shape: 13, Out shape 47.\n",
      "In shape: 47, Out shape 31.\n",
      "In shape: 31, Out shape 32.\n",
      "In shape: 32, Out shape 59.\n",
      "In shape: 59, Out shape 26.\n",
      "In shape: 26, Out shape 31.\n",
      "In shape: 31, Out shape 53.\n",
      "In shape: 53, Out shape 26.\n",
      "In shape: 26, Out shape 32.\n",
      "In shape: 32, Out shape 57.\n",
      "In shape: 57, Out shape 30.\n",
      "In shape: 30, Out shape 31.\n",
      "In shape: 31, Out shape 60.\n",
      "In shape: 60, Out shape 31.\n",
      "In shape: 31, Out shape 32.\n",
      "In shape: 32, Out shape 53.\n",
      "In shape: 53, Out shape 29.\n",
      "In shape: 29, Out shape 31.\n",
      "In shape: 31, Out shape 56.\n",
      "In shape: 56, Out shape 30.\n",
      "In shape: 30, Out shape 32.\n",
      "In shape: 32, Out shape 62.\n",
      "In shape: 62, Out shape 24.\n",
      "In shape: 24, Out shape 31.\n",
      "In shape: 31, Out shape 52.\n",
      "In shape: 52, Out shape 29.\n",
      "In shape: 29, Out shape 32.\n",
      "In shape: 32, Out shape 52.\n",
      "In shape: 52, Out shape 28.\n",
      "In shape: 28, Out shape 32.\n",
      "In shape: 32, Out shape 44.\n",
      "In shape: 44, Out shape 26.\n",
      "In shape: 26, Out shape 32.\n",
      "In shape: 32, Out shape 50.\n",
      "In shape: 50, Out shape 27.\n",
      "In shape: 27, Out shape 32.\n",
      "In shape: 32, Out shape 59.\n",
      "In shape: 59, Out shape 29.\n",
      "In shape: 29, Out shape 32.\n",
      "In shape: 32, Out shape 56.\n",
      "In shape: 56, Out shape 22.\n",
      "In shape: 22, Out shape 32.\n",
      "In shape: 32, Out shape 56.\n",
      "In shape: 56, Out shape 27.\n",
      "In shape: 27, Out shape 32.\n",
      "In shape: 32, Out shape 58.\n",
      "In shape: 58, Out shape 26.\n",
      "In shape: 26, Out shape 30.\n",
      "In shape: 30, Out shape 59.\n",
      "In shape: 59, Out shape 25.\n",
      "In shape: 25, Out shape 32.\n",
      "In shape: 32, Out shape 55.\n",
      "In shape: 55, Out shape 27.\n",
      "In shape: 27, Out shape 31.\n",
      "In shape: 31, Out shape 68.\n",
      "In shape: 68, Out shape 33.\n",
      "In shape: 33, Out shape 63.\n",
      "In shape: 63, Out shape 47.\n",
      "In shape: 47, Out shape 33.\n",
      "In shape: 33, Out shape 64.\n",
      "In shape: 64, Out shape 52.\n",
      "In shape: 52, Out shape 42.\n",
      "In shape: 42, Out shape 64.\n",
      "In shape: 64, Out shape 52.\n",
      "In shape: 52, Out shape 41.\n",
      "In shape: 41, Out shape 64.\n",
      "In shape: 64, Out shape 56.\n",
      "In shape: 56, Out shape 39.\n",
      "In shape: 39, Out shape 64.\n",
      "In shape: 64, Out shape 66.\n",
      "In shape: 66, Out shape 42.\n",
      "In shape: 42, Out shape 64.\n",
      "In shape: 64, Out shape 61.\n",
      "In shape: 61, Out shape 37.\n",
      "In shape: 37, Out shape 64.\n",
      "In shape: 64, Out shape 68.\n",
      "In shape: 68, Out shape 39.\n",
      "In shape: 39, Out shape 64.\n",
      "In shape: 64, Out shape 45.\n",
      "In shape: 45, Out shape 33.\n",
      "In shape: 33, Out shape 64.\n",
      "In shape: 64, Out shape 51.\n",
      "In shape: 51, Out shape 36.\n",
      "In shape: 36, Out shape 64.\n",
      "In shape: 64, Out shape 56.\n",
      "In shape: 56, Out shape 34.\n",
      "In shape: 34, Out shape 63.\n",
      "In shape: 63, Out shape 61.\n",
      "In shape: 61, Out shape 41.\n",
      "In shape: 41, Out shape 63.\n",
      "In shape: 63, Out shape 54.\n",
      "In shape: 54, Out shape 26.\n",
      "In shape: 26, Out shape 64.\n",
      "In shape: 64, Out shape 50.\n",
      "In shape: 50, Out shape 29.\n",
      "In shape: 29, Out shape 64.\n",
      "In shape: 64, Out shape 55.\n",
      "In shape: 55, Out shape 31.\n",
      "In shape: 31, Out shape 64.\n",
      "In shape: 64, Out shape 43.\n",
      "In shape: 43, Out shape 26.\n",
      "In shape: 26, Out shape 64.\n",
      "In shape: 64, Out shape 46.\n",
      "In shape: 46, Out shape 23.\n",
      "In shape: 23, Out shape 64.\n",
      "In shape: 64, Out shape 44.\n",
      "In shape: 44, Out shape 29.\n",
      "In shape: 29, Out shape 62.\n",
      "In shape: 62, Out shape 227.\n",
      "resnet(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(15, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(39, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(37, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(33, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(28, 13, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(13, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(14, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(31, 14, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(14, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(15, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(29, 11, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(11, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(14, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(32, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(15, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(27, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(15, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(32, 13, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(13, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(33, 13, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(13, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(14, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(26, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(8, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(14, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(32, 13, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(13, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(13, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(30, 14, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(14, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(14, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(30, 14, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(14, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(15, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(28, 11, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(11, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(28, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(12, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(14, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(27, 13, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(13, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(13, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(47, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(31, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(59, 26, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(26, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(31, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(53, 26, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(26, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(57, 30, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(30, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(31, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(60, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(31, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(53, 29, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(29, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(31, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(56, 30, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(30, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(62, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(24, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(31, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(52, 29, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(29, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(52, 28, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(28, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(44, 26, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(26, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(50, 27, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(27, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(59, 29, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(29, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(56, 22, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(22, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(56, 27, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(27, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(58, 26, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(26, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(30, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(59, 25, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(25, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(55, 27, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(27, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(31, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(68, 33, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(33, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(33, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(63, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(47, 33, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(33, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(33, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(52, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(42, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(42, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(52, 41, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(41, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(41, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(56, 39, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(39, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(39, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(66, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(42, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(42, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(61, 37, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(37, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(68, 39, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(39, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(39, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(45, 33, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(33, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(33, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(51, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(36, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(56, 34, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(34, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(34, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(63, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(61, 41, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(41, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(41, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(63, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(54, 26, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(26, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(50, 29, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(29, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(55, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(31, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(43, 26, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(26, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(46, 23, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(23, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(44, 29, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(29, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(62, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (select): channel_selection()\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
      "  (fc): Linear(in_features=227, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "Test set: Accuracy: 3085/10000 (30.9%)\n",
      "\n",
      "Train Epoch: 0 [0/50000 (0.0%)]\tLoss: 0.498370\n",
      "Train Epoch: 0 [6400/50000 (12.8%)]\tLoss: 0.857831\n",
      "Train Epoch: 0 [12800/50000 (25.6%)]\tLoss: 0.651658\n",
      "Train Epoch: 0 [19200/50000 (38.4%)]\tLoss: 0.805086\n",
      "Train Epoch: 0 [25600/50000 (51.2%)]\tLoss: 0.943530\n",
      "Train Epoch: 0 [32000/50000 (63.9%)]\tLoss: 0.441265\n",
      "Train Epoch: 0 [38400/50000 (76.7%)]\tLoss: 0.449843\n",
      "Train Epoch: 0 [44800/50000 (89.5%)]\tLoss: 0.702210\n",
      "\n",
      "Test set: Average loss: 0.6822, Accuracy: 7746/10000 (77.5%)\n",
      "\n",
      "Train Epoch: 1 [0/50000 (0.0%)]\tLoss: 0.471785\n",
      "Train Epoch: 1 [6400/50000 (12.8%)]\tLoss: 0.435356\n",
      "Train Epoch: 1 [12800/50000 (25.6%)]\tLoss: 0.470744\n",
      "Train Epoch: 1 [19200/50000 (38.4%)]\tLoss: 0.499701\n",
      "Train Epoch: 1 [25600/50000 (51.2%)]\tLoss: 0.493092\n",
      "Train Epoch: 1 [32000/50000 (63.9%)]\tLoss: 0.547760\n",
      "Train Epoch: 1 [38400/50000 (76.7%)]\tLoss: 0.442510\n",
      "Train Epoch: 1 [44800/50000 (89.5%)]\tLoss: 0.461764\n",
      "\n",
      "Test set: Average loss: 0.6659, Accuracy: 7839/10000 (78.4%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0.0%)]\tLoss: 0.580611\n",
      "Train Epoch: 2 [6400/50000 (12.8%)]\tLoss: 0.591452\n",
      "Train Epoch: 2 [12800/50000 (25.6%)]\tLoss: 0.647660\n",
      "Train Epoch: 2 [19200/50000 (38.4%)]\tLoss: 0.315514\n",
      "Train Epoch: 2 [25600/50000 (51.2%)]\tLoss: 0.587500\n",
      "Train Epoch: 2 [32000/50000 (63.9%)]\tLoss: 0.490067\n",
      "Train Epoch: 2 [38400/50000 (76.7%)]\tLoss: 0.272054\n",
      "Train Epoch: 2 [44800/50000 (89.5%)]\tLoss: 0.551883\n",
      "\n",
      "Test set: Average loss: 0.6840, Accuracy: 7681/10000 (76.8%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0.0%)]\tLoss: 0.647672\n",
      "Train Epoch: 3 [6400/50000 (12.8%)]\tLoss: 0.443318\n",
      "Train Epoch: 3 [12800/50000 (25.6%)]\tLoss: 0.596298\n",
      "Train Epoch: 3 [19200/50000 (38.4%)]\tLoss: 0.445512\n",
      "Train Epoch: 3 [25600/50000 (51.2%)]\tLoss: 0.357161\n",
      "Train Epoch: 3 [32000/50000 (63.9%)]\tLoss: 0.580591\n",
      "Train Epoch: 3 [38400/50000 (76.7%)]\tLoss: 0.381098\n",
      "Train Epoch: 3 [44800/50000 (89.5%)]\tLoss: 0.497677\n",
      "\n",
      "Test set: Average loss: 0.5662, Accuracy: 8076/10000 (80.8%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0.0%)]\tLoss: 0.517332\n",
      "Train Epoch: 4 [6400/50000 (12.8%)]\tLoss: 0.454081\n",
      "Train Epoch: 4 [12800/50000 (25.6%)]\tLoss: 0.309570\n",
      "Train Epoch: 4 [19200/50000 (38.4%)]\tLoss: 0.469702\n",
      "Train Epoch: 4 [25600/50000 (51.2%)]\tLoss: 0.385584\n",
      "Train Epoch: 4 [32000/50000 (63.9%)]\tLoss: 0.611337\n",
      "Train Epoch: 4 [38400/50000 (76.7%)]\tLoss: 0.450222\n",
      "Train Epoch: 4 [44800/50000 (89.5%)]\tLoss: 0.321473\n",
      "\n",
      "Test set: Average loss: 0.5418, Accuracy: 8151/10000 (81.5%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0.0%)]\tLoss: 0.727295\n",
      "Train Epoch: 5 [6400/50000 (12.8%)]\tLoss: 0.403863\n",
      "Train Epoch: 5 [12800/50000 (25.6%)]\tLoss: 0.333850\n",
      "Train Epoch: 5 [19200/50000 (38.4%)]\tLoss: 0.408266\n",
      "Train Epoch: 5 [25600/50000 (51.2%)]\tLoss: 0.526784\n",
      "Train Epoch: 5 [32000/50000 (63.9%)]\tLoss: 0.424578\n",
      "Train Epoch: 5 [38400/50000 (76.7%)]\tLoss: 0.332028\n",
      "Train Epoch: 5 [44800/50000 (89.5%)]\tLoss: 0.506917\n",
      "\n",
      "Test set: Average loss: 0.5651, Accuracy: 8133/10000 (81.3%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0.0%)]\tLoss: 0.549595\n",
      "Train Epoch: 6 [6400/50000 (12.8%)]\tLoss: 0.451256\n",
      "Train Epoch: 6 [12800/50000 (25.6%)]\tLoss: 0.240188\n",
      "Train Epoch: 6 [19200/50000 (38.4%)]\tLoss: 0.620831\n",
      "Train Epoch: 6 [25600/50000 (51.2%)]\tLoss: 0.432220\n",
      "Train Epoch: 6 [32000/50000 (63.9%)]\tLoss: 0.575158\n",
      "Train Epoch: 6 [38400/50000 (76.7%)]\tLoss: 0.578589\n",
      "Train Epoch: 6 [44800/50000 (89.5%)]\tLoss: 0.385022\n",
      "\n",
      "Test set: Average loss: 0.5099, Accuracy: 8246/10000 (82.5%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0.0%)]\tLoss: 0.390842\n",
      "Train Epoch: 7 [6400/50000 (12.8%)]\tLoss: 0.480280\n",
      "Train Epoch: 7 [12800/50000 (25.6%)]\tLoss: 0.525148\n",
      "Train Epoch: 7 [19200/50000 (38.4%)]\tLoss: 0.450720\n",
      "Train Epoch: 7 [25600/50000 (51.2%)]\tLoss: 0.665488\n",
      "Train Epoch: 7 [32000/50000 (63.9%)]\tLoss: 0.480201\n",
      "Train Epoch: 7 [38400/50000 (76.7%)]\tLoss: 0.384698\n",
      "Train Epoch: 7 [44800/50000 (89.5%)]\tLoss: 0.424466\n",
      "\n",
      "Test set: Average loss: 0.5219, Accuracy: 8233/10000 (82.3%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0.0%)]\tLoss: 0.351859\n",
      "Train Epoch: 8 [6400/50000 (12.8%)]\tLoss: 0.414173\n",
      "Train Epoch: 8 [12800/50000 (25.6%)]\tLoss: 0.470488\n",
      "Train Epoch: 8 [19200/50000 (38.4%)]\tLoss: 0.487706\n",
      "Train Epoch: 8 [25600/50000 (51.2%)]\tLoss: 0.400160\n",
      "Train Epoch: 8 [32000/50000 (63.9%)]\tLoss: 0.381756\n",
      "Train Epoch: 8 [38400/50000 (76.7%)]\tLoss: 0.364503\n",
      "Train Epoch: 8 [44800/50000 (89.5%)]\tLoss: 0.567797\n",
      "\n",
      "Test set: Average loss: 0.6181, Accuracy: 8032/10000 (80.3%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0.0%)]\tLoss: 0.411831\n",
      "Train Epoch: 9 [6400/50000 (12.8%)]\tLoss: 0.309513\n",
      "Train Epoch: 9 [12800/50000 (25.6%)]\tLoss: 0.431437\n",
      "Train Epoch: 9 [19200/50000 (38.4%)]\tLoss: 0.395230\n",
      "Train Epoch: 9 [25600/50000 (51.2%)]\tLoss: 0.434780\n",
      "Train Epoch: 9 [32000/50000 (63.9%)]\tLoss: 0.345182\n",
      "Train Epoch: 9 [38400/50000 (76.7%)]\tLoss: 0.601626\n",
      "Train Epoch: 9 [44800/50000 (89.5%)]\tLoss: 0.531212\n",
      "\n",
      "Test set: Average loss: 0.5962, Accuracy: 8055/10000 (80.6%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0.0%)]\tLoss: 0.458432\n",
      "Train Epoch: 10 [6400/50000 (12.8%)]\tLoss: 0.369707\n",
      "Train Epoch: 10 [12800/50000 (25.6%)]\tLoss: 0.383750\n",
      "Train Epoch: 10 [19200/50000 (38.4%)]\tLoss: 0.173129\n",
      "Train Epoch: 10 [25600/50000 (51.2%)]\tLoss: 0.341420\n",
      "Train Epoch: 10 [32000/50000 (63.9%)]\tLoss: 0.317743\n",
      "Train Epoch: 10 [38400/50000 (76.7%)]\tLoss: 0.197376\n",
      "Train Epoch: 10 [44800/50000 (89.5%)]\tLoss: 0.273934\n",
      "\n",
      "Test set: Average loss: 0.2784, Accuracy: 9027/10000 (90.3%)\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0.0%)]\tLoss: 0.270344\n",
      "Train Epoch: 11 [6400/50000 (12.8%)]\tLoss: 0.404955\n",
      "Train Epoch: 11 [12800/50000 (25.6%)]\tLoss: 0.168655\n",
      "Train Epoch: 11 [19200/50000 (38.4%)]\tLoss: 0.216186\n",
      "Train Epoch: 11 [25600/50000 (51.2%)]\tLoss: 0.204604\n",
      "Train Epoch: 11 [32000/50000 (63.9%)]\tLoss: 0.160965\n",
      "Train Epoch: 11 [38400/50000 (76.7%)]\tLoss: 0.221424\n",
      "Train Epoch: 11 [44800/50000 (89.5%)]\tLoss: 0.177581\n",
      "\n",
      "Test set: Average loss: 0.2656, Accuracy: 9104/10000 (91.0%)\n",
      "\n",
      "Train Epoch: 12 [0/50000 (0.0%)]\tLoss: 0.262186\n",
      "Train Epoch: 12 [6400/50000 (12.8%)]\tLoss: 0.139213\n",
      "Train Epoch: 12 [12800/50000 (25.6%)]\tLoss: 0.195473\n",
      "Train Epoch: 12 [19200/50000 (38.4%)]\tLoss: 0.235137\n",
      "Train Epoch: 12 [25600/50000 (51.2%)]\tLoss: 0.147436\n",
      "Train Epoch: 12 [32000/50000 (63.9%)]\tLoss: 0.167146\n",
      "Train Epoch: 12 [38400/50000 (76.7%)]\tLoss: 0.188102\n",
      "Train Epoch: 12 [44800/50000 (89.5%)]\tLoss: 0.211093\n",
      "\n",
      "Test set: Average loss: 0.2652, Accuracy: 9099/10000 (91.0%)\n",
      "\n",
      "Train Epoch: 13 [0/50000 (0.0%)]\tLoss: 0.170644\n",
      "Train Epoch: 13 [6400/50000 (12.8%)]\tLoss: 0.163730\n",
      "Train Epoch: 13 [12800/50000 (25.6%)]\tLoss: 0.155836\n",
      "Train Epoch: 13 [19200/50000 (38.4%)]\tLoss: 0.253832\n",
      "Train Epoch: 13 [25600/50000 (51.2%)]\tLoss: 0.237306\n",
      "Train Epoch: 13 [32000/50000 (63.9%)]\tLoss: 0.231632\n",
      "Train Epoch: 13 [38400/50000 (76.7%)]\tLoss: 0.181384\n",
      "Train Epoch: 13 [44800/50000 (89.5%)]\tLoss: 0.241144\n",
      "\n",
      "Test set: Average loss: 0.2665, Accuracy: 9099/10000 (91.0%)\n",
      "\n",
      "Train Epoch: 14 [0/50000 (0.0%)]\tLoss: 0.221038\n",
      "Train Epoch: 14 [6400/50000 (12.8%)]\tLoss: 0.232402\n",
      "Train Epoch: 14 [12800/50000 (25.6%)]\tLoss: 0.268892\n",
      "Train Epoch: 14 [19200/50000 (38.4%)]\tLoss: 0.149832\n",
      "Train Epoch: 14 [25600/50000 (51.2%)]\tLoss: 0.172380\n",
      "Train Epoch: 14 [32000/50000 (63.9%)]\tLoss: 0.157658\n",
      "Train Epoch: 14 [38400/50000 (76.7%)]\tLoss: 0.197946\n",
      "Train Epoch: 14 [44800/50000 (89.5%)]\tLoss: 0.184662\n",
      "\n",
      "Test set: Average loss: 0.2551, Accuracy: 9152/10000 (91.5%)\n",
      "\n",
      "Train Epoch: 15 [0/50000 (0.0%)]\tLoss: 0.198065\n",
      "Train Epoch: 15 [6400/50000 (12.8%)]\tLoss: 0.149177\n",
      "Train Epoch: 15 [12800/50000 (25.6%)]\tLoss: 0.230163\n",
      "Train Epoch: 15 [19200/50000 (38.4%)]\tLoss: 0.088033\n",
      "Train Epoch: 15 [25600/50000 (51.2%)]\tLoss: 0.240655\n",
      "Train Epoch: 15 [32000/50000 (63.9%)]\tLoss: 0.210055\n",
      "Train Epoch: 15 [38400/50000 (76.7%)]\tLoss: 0.115249\n",
      "Train Epoch: 15 [44800/50000 (89.5%)]\tLoss: 0.122875\n",
      "\n",
      "Test set: Average loss: 0.2456, Accuracy: 9179/10000 (91.8%)\n",
      "\n",
      "Train Epoch: 16 [0/50000 (0.0%)]\tLoss: 0.138570\n",
      "Train Epoch: 16 [6400/50000 (12.8%)]\tLoss: 0.135095\n",
      "Train Epoch: 16 [12800/50000 (25.6%)]\tLoss: 0.183721\n",
      "Train Epoch: 16 [19200/50000 (38.4%)]\tLoss: 0.151549\n",
      "Train Epoch: 16 [25600/50000 (51.2%)]\tLoss: 0.166471\n",
      "Train Epoch: 16 [32000/50000 (63.9%)]\tLoss: 0.124125\n",
      "Train Epoch: 16 [38400/50000 (76.7%)]\tLoss: 0.213757\n",
      "Train Epoch: 16 [44800/50000 (89.5%)]\tLoss: 0.137496\n",
      "\n",
      "Test set: Average loss: 0.2433, Accuracy: 9180/10000 (91.8%)\n",
      "\n",
      "Train Epoch: 17 [0/50000 (0.0%)]\tLoss: 0.166519\n",
      "Train Epoch: 17 [6400/50000 (12.8%)]\tLoss: 0.204944\n",
      "Train Epoch: 17 [12800/50000 (25.6%)]\tLoss: 0.152741\n",
      "Train Epoch: 17 [19200/50000 (38.4%)]\tLoss: 0.097500\n",
      "Train Epoch: 17 [25600/50000 (51.2%)]\tLoss: 0.078493\n",
      "Train Epoch: 17 [32000/50000 (63.9%)]\tLoss: 0.247878\n",
      "Train Epoch: 17 [38400/50000 (76.7%)]\tLoss: 0.096635\n",
      "Train Epoch: 17 [44800/50000 (89.5%)]\tLoss: 0.113104\n",
      "\n",
      "Test set: Average loss: 0.2434, Accuracy: 9185/10000 (91.8%)\n",
      "\n",
      "Train Epoch: 18 [0/50000 (0.0%)]\tLoss: 0.128661\n",
      "Train Epoch: 18 [6400/50000 (12.8%)]\tLoss: 0.059679\n",
      "Train Epoch: 18 [12800/50000 (25.6%)]\tLoss: 0.277937\n",
      "Train Epoch: 18 [19200/50000 (38.4%)]\tLoss: 0.202668\n",
      "Train Epoch: 18 [25600/50000 (51.2%)]\tLoss: 0.083767\n",
      "Train Epoch: 18 [32000/50000 (63.9%)]\tLoss: 0.205147\n",
      "Train Epoch: 18 [38400/50000 (76.7%)]\tLoss: 0.238384\n",
      "Train Epoch: 18 [44800/50000 (89.5%)]\tLoss: 0.134299\n",
      "\n",
      "Test set: Average loss: 0.2443, Accuracy: 9190/10000 (91.9%)\n",
      "\n",
      "Train Epoch: 19 [0/50000 (0.0%)]\tLoss: 0.213910\n",
      "Train Epoch: 19 [6400/50000 (12.8%)]\tLoss: 0.138663\n",
      "Train Epoch: 19 [12800/50000 (25.6%)]\tLoss: 0.116740\n",
      "Train Epoch: 19 [19200/50000 (38.4%)]\tLoss: 0.162003\n",
      "Train Epoch: 19 [25600/50000 (51.2%)]\tLoss: 0.199398\n",
      "Train Epoch: 19 [32000/50000 (63.9%)]\tLoss: 0.110459\n",
      "Train Epoch: 19 [38400/50000 (76.7%)]\tLoss: 0.170592\n",
      "Train Epoch: 19 [44800/50000 (89.5%)]\tLoss: 0.279589\n",
      "\n",
      "Test set: Average loss: 0.2415, Accuracy: 9188/10000 (91.9%)\n",
      "\n",
      "Best accuracy: tensor(0.9190)\n",
      "Number of parameters: 1051360\n",
      "Average Time taken: 127.2265581727028\n",
      "Iteration:  7 Percent:  0.6\n",
      "=> loading checkpoint '/kaggle/working/model_best.pth.tar'\n",
      "=> loaded checkpoint '/kaggle/working/model_best.pth.tar' (epoch 19) Prec1: 0.895400\n",
      "layer index: 4 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 7 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 9 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 15 \t total channel: 64 \t remaining channel: 30\n",
      "layer index: 18 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 20 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 24 \t total channel: 64 \t remaining channel: 30\n",
      "layer index: 27 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 29 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 33 \t total channel: 64 \t remaining channel: 26\n",
      "layer index: 36 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 38 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 42 \t total channel: 64 \t remaining channel: 22\n",
      "layer index: 45 \t total channel: 16 \t remaining channel: 10\n",
      "layer index: 47 \t total channel: 16 \t remaining channel: 13\n",
      "layer index: 51 \t total channel: 64 \t remaining channel: 26\n",
      "layer index: 54 \t total channel: 16 \t remaining channel: 13\n",
      "layer index: 56 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 60 \t total channel: 64 \t remaining channel: 23\n",
      "layer index: 63 \t total channel: 16 \t remaining channel: 10\n",
      "layer index: 65 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 69 \t total channel: 64 \t remaining channel: 28\n",
      "layer index: 72 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 74 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 78 \t total channel: 64 \t remaining channel: 23\n",
      "layer index: 81 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 83 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 87 \t total channel: 64 \t remaining channel: 23\n",
      "layer index: 90 \t total channel: 16 \t remaining channel: 13\n",
      "layer index: 92 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 96 \t total channel: 64 \t remaining channel: 23\n",
      "layer index: 99 \t total channel: 16 \t remaining channel: 12\n",
      "layer index: 101 \t total channel: 16 \t remaining channel: 13\n",
      "layer index: 105 \t total channel: 64 \t remaining channel: 18\n",
      "layer index: 108 \t total channel: 16 \t remaining channel: 7\n",
      "layer index: 110 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 114 \t total channel: 64 \t remaining channel: 23\n",
      "layer index: 117 \t total channel: 16 \t remaining channel: 9\n",
      "layer index: 119 \t total channel: 16 \t remaining channel: 11\n",
      "layer index: 123 \t total channel: 64 \t remaining channel: 22\n",
      "layer index: 126 \t total channel: 16 \t remaining channel: 12\n",
      "layer index: 128 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 132 \t total channel: 64 \t remaining channel: 25\n",
      "layer index: 135 \t total channel: 16 \t remaining channel: 13\n",
      "layer index: 137 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 141 \t total channel: 64 \t remaining channel: 23\n",
      "layer index: 144 \t total channel: 16 \t remaining channel: 9\n",
      "layer index: 146 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 150 \t total channel: 64 \t remaining channel: 20\n",
      "layer index: 153 \t total channel: 16 \t remaining channel: 11\n",
      "layer index: 155 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 159 \t total channel: 64 \t remaining channel: 19\n",
      "layer index: 162 \t total channel: 16 \t remaining channel: 10\n",
      "layer index: 164 \t total channel: 16 \t remaining channel: 12\n",
      "layer index: 169 \t total channel: 64 \t remaining channel: 40\n",
      "layer index: 172 \t total channel: 32 \t remaining channel: 27\n",
      "layer index: 174 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 180 \t total channel: 128 \t remaining channel: 40\n",
      "layer index: 183 \t total channel: 32 \t remaining channel: 22\n",
      "layer index: 185 \t total channel: 32 \t remaining channel: 31\n",
      "layer index: 189 \t total channel: 128 \t remaining channel: 36\n",
      "layer index: 192 \t total channel: 32 \t remaining channel: 23\n",
      "layer index: 194 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 198 \t total channel: 128 \t remaining channel: 36\n",
      "layer index: 201 \t total channel: 32 \t remaining channel: 27\n",
      "layer index: 203 \t total channel: 32 \t remaining channel: 31\n",
      "layer index: 207 \t total channel: 128 \t remaining channel: 42\n",
      "layer index: 210 \t total channel: 32 \t remaining channel: 26\n",
      "layer index: 212 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 216 \t total channel: 128 \t remaining channel: 40\n",
      "layer index: 219 \t total channel: 32 \t remaining channel: 23\n",
      "layer index: 221 \t total channel: 32 \t remaining channel: 30\n",
      "layer index: 225 \t total channel: 128 \t remaining channel: 38\n",
      "layer index: 228 \t total channel: 32 \t remaining channel: 26\n",
      "layer index: 230 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 234 \t total channel: 128 \t remaining channel: 44\n",
      "layer index: 237 \t total channel: 32 \t remaining channel: 22\n",
      "layer index: 239 \t total channel: 32 \t remaining channel: 30\n",
      "layer index: 243 \t total channel: 128 \t remaining channel: 39\n",
      "layer index: 246 \t total channel: 32 \t remaining channel: 27\n",
      "layer index: 248 \t total channel: 32 \t remaining channel: 31\n",
      "layer index: 252 \t total channel: 128 \t remaining channel: 37\n",
      "layer index: 255 \t total channel: 32 \t remaining channel: 24\n",
      "layer index: 257 \t total channel: 32 \t remaining channel: 31\n",
      "layer index: 261 \t total channel: 128 \t remaining channel: 32\n",
      "layer index: 264 \t total channel: 32 \t remaining channel: 22\n",
      "layer index: 266 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 270 \t total channel: 128 \t remaining channel: 31\n",
      "layer index: 273 \t total channel: 32 \t remaining channel: 24\n",
      "layer index: 275 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 279 \t total channel: 128 \t remaining channel: 43\n",
      "layer index: 282 \t total channel: 32 \t remaining channel: 25\n",
      "layer index: 284 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 288 \t total channel: 128 \t remaining channel: 36\n",
      "layer index: 291 \t total channel: 32 \t remaining channel: 18\n",
      "layer index: 293 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 297 \t total channel: 128 \t remaining channel: 47\n",
      "layer index: 300 \t total channel: 32 \t remaining channel: 24\n",
      "layer index: 302 \t total channel: 32 \t remaining channel: 31\n",
      "layer index: 306 \t total channel: 128 \t remaining channel: 40\n",
      "layer index: 309 \t total channel: 32 \t remaining channel: 26\n",
      "layer index: 311 \t total channel: 32 \t remaining channel: 30\n",
      "layer index: 315 \t total channel: 128 \t remaining channel: 44\n",
      "layer index: 318 \t total channel: 32 \t remaining channel: 22\n",
      "layer index: 320 \t total channel: 32 \t remaining channel: 31\n",
      "layer index: 324 \t total channel: 128 \t remaining channel: 40\n",
      "layer index: 327 \t total channel: 32 \t remaining channel: 22\n",
      "layer index: 329 \t total channel: 32 \t remaining channel: 31\n",
      "layer index: 334 \t total channel: 128 \t remaining channel: 43\n",
      "layer index: 337 \t total channel: 64 \t remaining channel: 20\n",
      "layer index: 339 \t total channel: 64 \t remaining channel: 63\n",
      "layer index: 345 \t total channel: 256 \t remaining channel: 23\n",
      "layer index: 348 \t total channel: 64 \t remaining channel: 26\n",
      "layer index: 350 \t total channel: 64 \t remaining channel: 63\n",
      "layer index: 354 \t total channel: 256 \t remaining channel: 34\n",
      "layer index: 357 \t total channel: 64 \t remaining channel: 29\n",
      "layer index: 359 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 363 \t total channel: 256 \t remaining channel: 28\n",
      "layer index: 366 \t total channel: 64 \t remaining channel: 31\n",
      "layer index: 368 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 372 \t total channel: 256 \t remaining channel: 27\n",
      "layer index: 375 \t total channel: 64 \t remaining channel: 29\n",
      "layer index: 377 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 381 \t total channel: 256 \t remaining channel: 29\n",
      "layer index: 384 \t total channel: 64 \t remaining channel: 28\n",
      "layer index: 386 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 390 \t total channel: 256 \t remaining channel: 28\n",
      "layer index: 393 \t total channel: 64 \t remaining channel: 26\n",
      "layer index: 395 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 399 \t total channel: 256 \t remaining channel: 34\n",
      "layer index: 402 \t total channel: 64 \t remaining channel: 29\n",
      "layer index: 404 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 408 \t total channel: 256 \t remaining channel: 23\n",
      "layer index: 411 \t total channel: 64 \t remaining channel: 27\n",
      "layer index: 413 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 417 \t total channel: 256 \t remaining channel: 24\n",
      "layer index: 420 \t total channel: 64 \t remaining channel: 23\n",
      "layer index: 422 \t total channel: 64 \t remaining channel: 63\n",
      "layer index: 426 \t total channel: 256 \t remaining channel: 29\n",
      "layer index: 429 \t total channel: 64 \t remaining channel: 19\n",
      "layer index: 431 \t total channel: 64 \t remaining channel: 63\n",
      "layer index: 435 \t total channel: 256 \t remaining channel: 38\n",
      "layer index: 438 \t total channel: 64 \t remaining channel: 27\n",
      "layer index: 440 \t total channel: 64 \t remaining channel: 59\n",
      "layer index: 444 \t total channel: 256 \t remaining channel: 27\n",
      "layer index: 447 \t total channel: 64 \t remaining channel: 17\n",
      "layer index: 449 \t total channel: 64 \t remaining channel: 63\n",
      "layer index: 453 \t total channel: 256 \t remaining channel: 25\n",
      "layer index: 456 \t total channel: 64 \t remaining channel: 16\n",
      "layer index: 458 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 462 \t total channel: 256 \t remaining channel: 24\n",
      "layer index: 465 \t total channel: 64 \t remaining channel: 15\n",
      "layer index: 467 \t total channel: 64 \t remaining channel: 63\n",
      "layer index: 471 \t total channel: 256 \t remaining channel: 20\n",
      "layer index: 474 \t total channel: 64 \t remaining channel: 20\n",
      "layer index: 476 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 480 \t total channel: 256 \t remaining channel: 14\n",
      "layer index: 483 \t total channel: 64 \t remaining channel: 12\n",
      "layer index: 485 \t total channel: 64 \t remaining channel: 62\n",
      "layer index: 489 \t total channel: 256 \t remaining channel: 23\n",
      "layer index: 492 \t total channel: 64 \t remaining channel: 16\n",
      "layer index: 494 \t total channel: 64 \t remaining channel: 61\n",
      "layer index: 497 \t total channel: 256 \t remaining channel: 218\n",
      "Pre-processing Successful!\n",
      "\n",
      "Test set: Accuracy: 1839/10000 (18.4%)\n",
      "\n",
      "Cfg:\n",
      "[14, 15, 16, 30, 14, 15, 30, 15, 15, 26, 15, 16, 22, 10, 13, 26, 13, 14, 23, 10, 14, 28, 15, 14, 23, 14, 14, 23, 13, 16, 23, 12, 13, 18, 7, 14, 23, 9, 11, 22, 12, 14, 25, 13, 14, 23, 9, 15, 20, 11, 14, 19, 10, 12, 40, 27, 32, 40, 22, 31, 36, 23, 32, 36, 27, 31, 42, 26, 32, 40, 23, 30, 38, 26, 32, 44, 22, 30, 39, 27, 31, 37, 24, 31, 32, 22, 32, 31, 24, 32, 43, 25, 32, 36, 18, 32, 47, 24, 31, 40, 26, 30, 44, 22, 31, 40, 22, 31, 43, 20, 63, 23, 26, 63, 34, 29, 64, 28, 31, 64, 27, 29, 64, 29, 28, 64, 28, 26, 64, 34, 29, 64, 23, 27, 64, 24, 23, 63, 29, 19, 63, 38, 27, 59, 27, 17, 63, 25, 16, 64, 24, 15, 63, 20, 20, 64, 14, 12, 62, 23, 16, 61, 218]\n",
      "In shape: 14, Out shape 15.\n",
      "In shape: 15, Out shape 16.\n",
      "In shape: 16, Out shape 30.\n",
      "In shape: 30, Out shape 14.\n",
      "In shape: 14, Out shape 15.\n",
      "In shape: 15, Out shape 30.\n",
      "In shape: 30, Out shape 15.\n",
      "In shape: 15, Out shape 15.\n",
      "In shape: 15, Out shape 26.\n",
      "In shape: 26, Out shape 15.\n",
      "In shape: 15, Out shape 16.\n",
      "In shape: 16, Out shape 22.\n",
      "In shape: 22, Out shape 10.\n",
      "In shape: 10, Out shape 13.\n",
      "In shape: 13, Out shape 26.\n",
      "In shape: 26, Out shape 13.\n",
      "In shape: 13, Out shape 14.\n",
      "In shape: 14, Out shape 23.\n",
      "In shape: 23, Out shape 10.\n",
      "In shape: 10, Out shape 14.\n",
      "In shape: 14, Out shape 28.\n",
      "In shape: 28, Out shape 15.\n",
      "In shape: 15, Out shape 14.\n",
      "In shape: 14, Out shape 23.\n",
      "In shape: 23, Out shape 14.\n",
      "In shape: 14, Out shape 14.\n",
      "In shape: 14, Out shape 23.\n",
      "In shape: 23, Out shape 13.\n",
      "In shape: 13, Out shape 16.\n",
      "In shape: 16, Out shape 23.\n",
      "In shape: 23, Out shape 12.\n",
      "In shape: 12, Out shape 13.\n",
      "In shape: 13, Out shape 18.\n",
      "In shape: 18, Out shape 7.\n",
      "In shape: 7, Out shape 14.\n",
      "In shape: 14, Out shape 23.\n",
      "In shape: 23, Out shape 9.\n",
      "In shape: 9, Out shape 11.\n",
      "In shape: 11, Out shape 22.\n",
      "In shape: 22, Out shape 12.\n",
      "In shape: 12, Out shape 14.\n",
      "In shape: 14, Out shape 25.\n",
      "In shape: 25, Out shape 13.\n",
      "In shape: 13, Out shape 14.\n",
      "In shape: 14, Out shape 23.\n",
      "In shape: 23, Out shape 9.\n",
      "In shape: 9, Out shape 15.\n",
      "In shape: 15, Out shape 20.\n",
      "In shape: 20, Out shape 11.\n",
      "In shape: 11, Out shape 14.\n",
      "In shape: 14, Out shape 19.\n",
      "In shape: 19, Out shape 10.\n",
      "In shape: 10, Out shape 12.\n",
      "In shape: 12, Out shape 40.\n",
      "In shape: 40, Out shape 27.\n",
      "In shape: 27, Out shape 32.\n",
      "In shape: 32, Out shape 40.\n",
      "In shape: 40, Out shape 22.\n",
      "In shape: 22, Out shape 31.\n",
      "In shape: 31, Out shape 36.\n",
      "In shape: 36, Out shape 23.\n",
      "In shape: 23, Out shape 32.\n",
      "In shape: 32, Out shape 36.\n",
      "In shape: 36, Out shape 27.\n",
      "In shape: 27, Out shape 31.\n",
      "In shape: 31, Out shape 42.\n",
      "In shape: 42, Out shape 26.\n",
      "In shape: 26, Out shape 32.\n",
      "In shape: 32, Out shape 40.\n",
      "In shape: 40, Out shape 23.\n",
      "In shape: 23, Out shape 30.\n",
      "In shape: 30, Out shape 38.\n",
      "In shape: 38, Out shape 26.\n",
      "In shape: 26, Out shape 32.\n",
      "In shape: 32, Out shape 44.\n",
      "In shape: 44, Out shape 22.\n",
      "In shape: 22, Out shape 30.\n",
      "In shape: 30, Out shape 39.\n",
      "In shape: 39, Out shape 27.\n",
      "In shape: 27, Out shape 31.\n",
      "In shape: 31, Out shape 37.\n",
      "In shape: 37, Out shape 24.\n",
      "In shape: 24, Out shape 31.\n",
      "In shape: 31, Out shape 32.\n",
      "In shape: 32, Out shape 22.\n",
      "In shape: 22, Out shape 32.\n",
      "In shape: 32, Out shape 31.\n",
      "In shape: 31, Out shape 24.\n",
      "In shape: 24, Out shape 32.\n",
      "In shape: 32, Out shape 43.\n",
      "In shape: 43, Out shape 25.\n",
      "In shape: 25, Out shape 32.\n",
      "In shape: 32, Out shape 36.\n",
      "In shape: 36, Out shape 18.\n",
      "In shape: 18, Out shape 32.\n",
      "In shape: 32, Out shape 47.\n",
      "In shape: 47, Out shape 24.\n",
      "In shape: 24, Out shape 31.\n",
      "In shape: 31, Out shape 40.\n",
      "In shape: 40, Out shape 26.\n",
      "In shape: 26, Out shape 30.\n",
      "In shape: 30, Out shape 44.\n",
      "In shape: 44, Out shape 22.\n",
      "In shape: 22, Out shape 31.\n",
      "In shape: 31, Out shape 40.\n",
      "In shape: 40, Out shape 22.\n",
      "In shape: 22, Out shape 31.\n",
      "In shape: 31, Out shape 43.\n",
      "In shape: 43, Out shape 20.\n",
      "In shape: 20, Out shape 63.\n",
      "In shape: 63, Out shape 23.\n",
      "In shape: 23, Out shape 26.\n",
      "In shape: 26, Out shape 63.\n",
      "In shape: 63, Out shape 34.\n",
      "In shape: 34, Out shape 29.\n",
      "In shape: 29, Out shape 64.\n",
      "In shape: 64, Out shape 28.\n",
      "In shape: 28, Out shape 31.\n",
      "In shape: 31, Out shape 64.\n",
      "In shape: 64, Out shape 27.\n",
      "In shape: 27, Out shape 29.\n",
      "In shape: 29, Out shape 64.\n",
      "In shape: 64, Out shape 29.\n",
      "In shape: 29, Out shape 28.\n",
      "In shape: 28, Out shape 64.\n",
      "In shape: 64, Out shape 28.\n",
      "In shape: 28, Out shape 26.\n",
      "In shape: 26, Out shape 64.\n",
      "In shape: 64, Out shape 34.\n",
      "In shape: 34, Out shape 29.\n",
      "In shape: 29, Out shape 64.\n",
      "In shape: 64, Out shape 23.\n",
      "In shape: 23, Out shape 27.\n",
      "In shape: 27, Out shape 64.\n",
      "In shape: 64, Out shape 24.\n",
      "In shape: 24, Out shape 23.\n",
      "In shape: 23, Out shape 63.\n",
      "In shape: 63, Out shape 29.\n",
      "In shape: 29, Out shape 19.\n",
      "In shape: 19, Out shape 63.\n",
      "In shape: 63, Out shape 38.\n",
      "In shape: 38, Out shape 27.\n",
      "In shape: 27, Out shape 59.\n",
      "In shape: 59, Out shape 27.\n",
      "In shape: 27, Out shape 17.\n",
      "In shape: 17, Out shape 63.\n",
      "In shape: 63, Out shape 25.\n",
      "In shape: 25, Out shape 16.\n",
      "In shape: 16, Out shape 64.\n",
      "In shape: 64, Out shape 24.\n",
      "In shape: 24, Out shape 15.\n",
      "In shape: 15, Out shape 63.\n",
      "In shape: 63, Out shape 20.\n",
      "In shape: 20, Out shape 20.\n",
      "In shape: 20, Out shape 64.\n",
      "In shape: 64, Out shape 14.\n",
      "In shape: 14, Out shape 12.\n",
      "In shape: 12, Out shape 62.\n",
      "In shape: 62, Out shape 23.\n",
      "In shape: 23, Out shape 16.\n",
      "In shape: 16, Out shape 61.\n",
      "In shape: 61, Out shape 218.\n",
      "resnet(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(14, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(30, 14, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(14, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(15, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(30, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(15, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(26, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(22, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(10, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(13, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(26, 13, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(13, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(14, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(23, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(10, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(14, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(28, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(14, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(23, 14, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(14, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(14, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(23, 13, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(13, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(23, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(12, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(13, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(18, 7, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(7, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(14, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(23, 9, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(9, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(11, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(22, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(12, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(14, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(25, 13, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(13, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(14, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(23, 9, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(9, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(15, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(20, 11, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(11, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(14, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(19, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(10, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(12, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(40, 27, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(27, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(40, 22, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(22, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(31, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(36, 23, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(23, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(36, 27, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(27, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(31, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(42, 26, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(26, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(40, 23, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(23, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(30, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(38, 26, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(26, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(44, 22, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(22, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(30, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(39, 27, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(27, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(31, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(37, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(24, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(31, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(32, 22, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(22, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(31, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(24, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(43, 25, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(25, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(36, 18, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(18, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(47, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(24, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(31, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(40, 26, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(26, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(30, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(44, 22, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(22, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(31, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(40, 22, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(22, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(31, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(43, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(20, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(63, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(23, 26, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(26, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(63, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(34, 29, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(29, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(28, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(31, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(27, 29, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(29, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(29, 28, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(28, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(28, 26, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(26, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(34, 29, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(29, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(23, 27, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(27, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(24, 23, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(23, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(63, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(29, 19, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(19, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(63, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(38, 27, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(27, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(59, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(27, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(17, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(63, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(25, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(24, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(63, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(20, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(14, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(12, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(62, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(23, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(61, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (select): channel_selection()\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
      "  (fc): Linear(in_features=218, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "Test set: Accuracy: 1839/10000 (18.4%)\n",
      "\n",
      "Train Epoch: 0 [0/50000 (0.0%)]\tLoss: 0.566024\n",
      "Train Epoch: 0 [6400/50000 (12.8%)]\tLoss: 0.630061\n",
      "Train Epoch: 0 [12800/50000 (25.6%)]\tLoss: 0.715779\n",
      "Train Epoch: 0 [19200/50000 (38.4%)]\tLoss: 0.887867\n",
      "Train Epoch: 0 [25600/50000 (51.2%)]\tLoss: 0.560627\n",
      "Train Epoch: 0 [32000/50000 (63.9%)]\tLoss: 0.511311\n",
      "Train Epoch: 0 [38400/50000 (76.7%)]\tLoss: 0.626989\n",
      "Train Epoch: 0 [44800/50000 (89.5%)]\tLoss: 0.351331\n",
      "\n",
      "Test set: Average loss: 0.6472, Accuracy: 7858/10000 (78.6%)\n",
      "\n",
      "Train Epoch: 1 [0/50000 (0.0%)]\tLoss: 0.461007\n",
      "Train Epoch: 1 [6400/50000 (12.8%)]\tLoss: 0.287469\n",
      "Train Epoch: 1 [12800/50000 (25.6%)]\tLoss: 0.593822\n",
      "Train Epoch: 1 [19200/50000 (38.4%)]\tLoss: 0.447958\n",
      "Train Epoch: 1 [25600/50000 (51.2%)]\tLoss: 0.392772\n",
      "Train Epoch: 1 [32000/50000 (63.9%)]\tLoss: 0.565517\n",
      "Train Epoch: 1 [38400/50000 (76.7%)]\tLoss: 0.493645\n",
      "Train Epoch: 1 [44800/50000 (89.5%)]\tLoss: 0.748925\n",
      "\n",
      "Test set: Average loss: 0.7270, Accuracy: 7684/10000 (76.8%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0.0%)]\tLoss: 0.580427\n",
      "Train Epoch: 2 [6400/50000 (12.8%)]\tLoss: 0.497035\n",
      "Train Epoch: 2 [12800/50000 (25.6%)]\tLoss: 0.530495\n",
      "Train Epoch: 2 [19200/50000 (38.4%)]\tLoss: 0.592312\n",
      "Train Epoch: 2 [25600/50000 (51.2%)]\tLoss: 0.424951\n",
      "Train Epoch: 2 [32000/50000 (63.9%)]\tLoss: 0.590584\n",
      "Train Epoch: 2 [38400/50000 (76.7%)]\tLoss: 0.495201\n",
      "Train Epoch: 2 [44800/50000 (89.5%)]\tLoss: 0.566107\n",
      "\n",
      "Test set: Average loss: 0.5533, Accuracy: 8137/10000 (81.4%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0.0%)]\tLoss: 0.494763\n",
      "Train Epoch: 3 [6400/50000 (12.8%)]\tLoss: 0.511247\n",
      "Train Epoch: 3 [12800/50000 (25.6%)]\tLoss: 0.426851\n",
      "Train Epoch: 3 [19200/50000 (38.4%)]\tLoss: 0.524877\n",
      "Train Epoch: 3 [25600/50000 (51.2%)]\tLoss: 0.338002\n",
      "Train Epoch: 3 [32000/50000 (63.9%)]\tLoss: 0.563195\n",
      "Train Epoch: 3 [38400/50000 (76.7%)]\tLoss: 0.565595\n",
      "Train Epoch: 3 [44800/50000 (89.5%)]\tLoss: 0.779467\n",
      "\n",
      "Test set: Average loss: 0.5638, Accuracy: 8119/10000 (81.2%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0.0%)]\tLoss: 0.331030\n",
      "Train Epoch: 4 [6400/50000 (12.8%)]\tLoss: 0.295876\n",
      "Train Epoch: 4 [12800/50000 (25.6%)]\tLoss: 0.622382\n",
      "Train Epoch: 4 [19200/50000 (38.4%)]\tLoss: 0.598541\n",
      "Train Epoch: 4 [25600/50000 (51.2%)]\tLoss: 0.406050\n",
      "Train Epoch: 4 [32000/50000 (63.9%)]\tLoss: 0.442087\n",
      "Train Epoch: 4 [38400/50000 (76.7%)]\tLoss: 0.284041\n",
      "Train Epoch: 4 [44800/50000 (89.5%)]\tLoss: 0.592425\n",
      "\n",
      "Test set: Average loss: 0.6433, Accuracy: 7890/10000 (78.9%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0.0%)]\tLoss: 0.507908\n",
      "Train Epoch: 5 [6400/50000 (12.8%)]\tLoss: 0.583051\n",
      "Train Epoch: 5 [12800/50000 (25.6%)]\tLoss: 0.504980\n",
      "Train Epoch: 5 [19200/50000 (38.4%)]\tLoss: 0.520224\n",
      "Train Epoch: 5 [25600/50000 (51.2%)]\tLoss: 0.466884\n",
      "Train Epoch: 5 [32000/50000 (63.9%)]\tLoss: 0.414520\n",
      "Train Epoch: 5 [38400/50000 (76.7%)]\tLoss: 0.490441\n",
      "Train Epoch: 5 [44800/50000 (89.5%)]\tLoss: 0.413489\n",
      "\n",
      "Test set: Average loss: 0.5598, Accuracy: 8066/10000 (80.7%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0.0%)]\tLoss: 0.336821\n",
      "Train Epoch: 6 [6400/50000 (12.8%)]\tLoss: 0.382732\n",
      "Train Epoch: 6 [12800/50000 (25.6%)]\tLoss: 0.564895\n",
      "Train Epoch: 6 [19200/50000 (38.4%)]\tLoss: 0.468692\n",
      "Train Epoch: 6 [25600/50000 (51.2%)]\tLoss: 0.289048\n",
      "Train Epoch: 6 [32000/50000 (63.9%)]\tLoss: 0.263338\n",
      "Train Epoch: 6 [38400/50000 (76.7%)]\tLoss: 0.533174\n",
      "Train Epoch: 6 [44800/50000 (89.5%)]\tLoss: 0.463326\n",
      "\n",
      "Test set: Average loss: 0.7131, Accuracy: 7650/10000 (76.5%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0.0%)]\tLoss: 0.450830\n",
      "Train Epoch: 7 [6400/50000 (12.8%)]\tLoss: 0.574309\n",
      "Train Epoch: 7 [12800/50000 (25.6%)]\tLoss: 0.429324\n",
      "Train Epoch: 7 [19200/50000 (38.4%)]\tLoss: 0.284477\n",
      "Train Epoch: 7 [25600/50000 (51.2%)]\tLoss: 0.457007\n",
      "Train Epoch: 7 [32000/50000 (63.9%)]\tLoss: 0.416359\n",
      "Train Epoch: 7 [38400/50000 (76.7%)]\tLoss: 0.408063\n",
      "Train Epoch: 7 [44800/50000 (89.5%)]\tLoss: 0.387634\n",
      "\n",
      "Test set: Average loss: 0.5666, Accuracy: 8088/10000 (80.9%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0.0%)]\tLoss: 0.659232\n",
      "Train Epoch: 8 [6400/50000 (12.8%)]\tLoss: 0.369431\n",
      "Train Epoch: 8 [12800/50000 (25.6%)]\tLoss: 0.572396\n",
      "Train Epoch: 8 [19200/50000 (38.4%)]\tLoss: 0.586453\n",
      "Train Epoch: 8 [25600/50000 (51.2%)]\tLoss: 0.595355\n",
      "Train Epoch: 8 [32000/50000 (63.9%)]\tLoss: 0.396919\n",
      "Train Epoch: 8 [38400/50000 (76.7%)]\tLoss: 0.444443\n",
      "Train Epoch: 8 [44800/50000 (89.5%)]\tLoss: 0.356682\n",
      "\n",
      "Test set: Average loss: 0.5603, Accuracy: 8167/10000 (81.7%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0.0%)]\tLoss: 0.482036\n",
      "Train Epoch: 9 [6400/50000 (12.8%)]\tLoss: 0.382377\n",
      "Train Epoch: 9 [12800/50000 (25.6%)]\tLoss: 0.363068\n",
      "Train Epoch: 9 [19200/50000 (38.4%)]\tLoss: 0.356599\n",
      "Train Epoch: 9 [25600/50000 (51.2%)]\tLoss: 0.391702\n",
      "Train Epoch: 9 [32000/50000 (63.9%)]\tLoss: 0.437618\n",
      "Train Epoch: 9 [38400/50000 (76.7%)]\tLoss: 0.563647\n",
      "Train Epoch: 9 [44800/50000 (89.5%)]\tLoss: 0.536647\n",
      "\n",
      "Test set: Average loss: 0.6790, Accuracy: 7855/10000 (78.6%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0.0%)]\tLoss: 0.215639\n",
      "Train Epoch: 10 [6400/50000 (12.8%)]\tLoss: 0.298057\n",
      "Train Epoch: 10 [12800/50000 (25.6%)]\tLoss: 0.296950\n",
      "Train Epoch: 10 [19200/50000 (38.4%)]\tLoss: 0.423657\n",
      "Train Epoch: 10 [25600/50000 (51.2%)]\tLoss: 0.349446\n",
      "Train Epoch: 10 [32000/50000 (63.9%)]\tLoss: 0.240133\n",
      "Train Epoch: 10 [38400/50000 (76.7%)]\tLoss: 0.273200\n",
      "Train Epoch: 10 [44800/50000 (89.5%)]\tLoss: 0.231278\n",
      "\n",
      "Test set: Average loss: 0.2880, Accuracy: 9004/10000 (90.0%)\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0.0%)]\tLoss: 0.191843\n",
      "Train Epoch: 11 [6400/50000 (12.8%)]\tLoss: 0.312558\n",
      "Train Epoch: 11 [12800/50000 (25.6%)]\tLoss: 0.169078\n",
      "Train Epoch: 11 [19200/50000 (38.4%)]\tLoss: 0.328715\n",
      "Train Epoch: 11 [25600/50000 (51.2%)]\tLoss: 0.193049\n",
      "Train Epoch: 11 [32000/50000 (63.9%)]\tLoss: 0.392834\n",
      "Train Epoch: 11 [38400/50000 (76.7%)]\tLoss: 0.284825\n",
      "Train Epoch: 11 [44800/50000 (89.5%)]\tLoss: 0.081960\n",
      "\n",
      "Test set: Average loss: 0.2796, Accuracy: 9046/10000 (90.5%)\n",
      "\n",
      "Train Epoch: 12 [0/50000 (0.0%)]\tLoss: 0.210814\n",
      "Train Epoch: 12 [6400/50000 (12.8%)]\tLoss: 0.236426\n",
      "Train Epoch: 12 [12800/50000 (25.6%)]\tLoss: 0.182366\n",
      "Train Epoch: 12 [19200/50000 (38.4%)]\tLoss: 0.261340\n",
      "Train Epoch: 12 [25600/50000 (51.2%)]\tLoss: 0.089152\n",
      "Train Epoch: 12 [32000/50000 (63.9%)]\tLoss: 0.276335\n",
      "Train Epoch: 12 [38400/50000 (76.7%)]\tLoss: 0.168210\n",
      "Train Epoch: 12 [44800/50000 (89.5%)]\tLoss: 0.206881\n",
      "\n",
      "Test set: Average loss: 0.2887, Accuracy: 9028/10000 (90.3%)\n",
      "\n",
      "Train Epoch: 13 [0/50000 (0.0%)]\tLoss: 0.144345\n",
      "Train Epoch: 13 [6400/50000 (12.8%)]\tLoss: 0.137459\n",
      "Train Epoch: 13 [12800/50000 (25.6%)]\tLoss: 0.241963\n",
      "Train Epoch: 13 [19200/50000 (38.4%)]\tLoss: 0.165436\n",
      "Train Epoch: 13 [25600/50000 (51.2%)]\tLoss: 0.126004\n",
      "Train Epoch: 13 [32000/50000 (63.9%)]\tLoss: 0.218305\n",
      "Train Epoch: 13 [38400/50000 (76.7%)]\tLoss: 0.172602\n",
      "Train Epoch: 13 [44800/50000 (89.5%)]\tLoss: 0.248546\n",
      "\n",
      "Test set: Average loss: 0.2756, Accuracy: 9079/10000 (90.8%)\n",
      "\n",
      "Train Epoch: 14 [0/50000 (0.0%)]\tLoss: 0.253350\n",
      "Train Epoch: 14 [6400/50000 (12.8%)]\tLoss: 0.140716\n",
      "Train Epoch: 14 [12800/50000 (25.6%)]\tLoss: 0.136005\n",
      "Train Epoch: 14 [19200/50000 (38.4%)]\tLoss: 0.140489\n",
      "Train Epoch: 14 [25600/50000 (51.2%)]\tLoss: 0.212557\n",
      "Train Epoch: 14 [32000/50000 (63.9%)]\tLoss: 0.511584\n",
      "Train Epoch: 14 [38400/50000 (76.7%)]\tLoss: 0.130142\n",
      "Train Epoch: 14 [44800/50000 (89.5%)]\tLoss: 0.200674\n",
      "\n",
      "Test set: Average loss: 0.2667, Accuracy: 9074/10000 (90.7%)\n",
      "\n",
      "Train Epoch: 15 [0/50000 (0.0%)]\tLoss: 0.081629\n",
      "Train Epoch: 15 [6400/50000 (12.8%)]\tLoss: 0.101345\n",
      "Train Epoch: 15 [12800/50000 (25.6%)]\tLoss: 0.136412\n",
      "Train Epoch: 15 [19200/50000 (38.4%)]\tLoss: 0.030847\n",
      "Train Epoch: 15 [25600/50000 (51.2%)]\tLoss: 0.210303\n",
      "Train Epoch: 15 [32000/50000 (63.9%)]\tLoss: 0.210065\n",
      "Train Epoch: 15 [38400/50000 (76.7%)]\tLoss: 0.192024\n",
      "Train Epoch: 15 [44800/50000 (89.5%)]\tLoss: 0.148873\n",
      "\n",
      "Test set: Average loss: 0.2562, Accuracy: 9128/10000 (91.3%)\n",
      "\n",
      "Train Epoch: 16 [0/50000 (0.0%)]\tLoss: 0.196362\n",
      "Train Epoch: 16 [6400/50000 (12.8%)]\tLoss: 0.077050\n",
      "Train Epoch: 16 [12800/50000 (25.6%)]\tLoss: 0.283583\n",
      "Train Epoch: 16 [19200/50000 (38.4%)]\tLoss: 0.315179\n",
      "Train Epoch: 16 [25600/50000 (51.2%)]\tLoss: 0.157093\n",
      "Train Epoch: 16 [32000/50000 (63.9%)]\tLoss: 0.113580\n",
      "Train Epoch: 16 [38400/50000 (76.7%)]\tLoss: 0.187115\n",
      "Train Epoch: 16 [44800/50000 (89.5%)]\tLoss: 0.136739\n",
      "\n",
      "Test set: Average loss: 0.2563, Accuracy: 9143/10000 (91.4%)\n",
      "\n",
      "Train Epoch: 17 [0/50000 (0.0%)]\tLoss: 0.150649\n",
      "Train Epoch: 17 [6400/50000 (12.8%)]\tLoss: 0.317169\n",
      "Train Epoch: 17 [12800/50000 (25.6%)]\tLoss: 0.255588\n",
      "Train Epoch: 17 [19200/50000 (38.4%)]\tLoss: 0.113926\n",
      "Train Epoch: 17 [25600/50000 (51.2%)]\tLoss: 0.213996\n",
      "Train Epoch: 17 [32000/50000 (63.9%)]\tLoss: 0.166480\n",
      "Train Epoch: 17 [38400/50000 (76.7%)]\tLoss: 0.125615\n",
      "Train Epoch: 17 [44800/50000 (89.5%)]\tLoss: 0.348820\n",
      "\n",
      "Test set: Average loss: 0.2537, Accuracy: 9145/10000 (91.4%)\n",
      "\n",
      "Train Epoch: 18 [0/50000 (0.0%)]\tLoss: 0.309360\n",
      "Train Epoch: 18 [6400/50000 (12.8%)]\tLoss: 0.177149\n",
      "Train Epoch: 18 [12800/50000 (25.6%)]\tLoss: 0.190668\n",
      "Train Epoch: 18 [19200/50000 (38.4%)]\tLoss: 0.281718\n",
      "Train Epoch: 18 [25600/50000 (51.2%)]\tLoss: 0.194839\n",
      "Train Epoch: 18 [32000/50000 (63.9%)]\tLoss: 0.079625\n",
      "Train Epoch: 18 [38400/50000 (76.7%)]\tLoss: 0.074487\n",
      "Train Epoch: 18 [44800/50000 (89.5%)]\tLoss: 0.198781\n",
      "\n",
      "Test set: Average loss: 0.2565, Accuracy: 9130/10000 (91.3%)\n",
      "\n",
      "Train Epoch: 19 [0/50000 (0.0%)]\tLoss: 0.297308\n",
      "Train Epoch: 19 [6400/50000 (12.8%)]\tLoss: 0.155668\n",
      "Train Epoch: 19 [12800/50000 (25.6%)]\tLoss: 0.188165\n",
      "Train Epoch: 19 [19200/50000 (38.4%)]\tLoss: 0.098258\n",
      "Train Epoch: 19 [25600/50000 (51.2%)]\tLoss: 0.186805\n",
      "Train Epoch: 19 [32000/50000 (63.9%)]\tLoss: 0.157533\n",
      "Train Epoch: 19 [38400/50000 (76.7%)]\tLoss: 0.089705\n",
      "Train Epoch: 19 [44800/50000 (89.5%)]\tLoss: 0.125955\n",
      "\n",
      "Test set: Average loss: 0.2570, Accuracy: 9148/10000 (91.5%)\n",
      "\n",
      "Best accuracy: tensor(0.9148)\n",
      "Number of parameters: 869602\n",
      "Average Time taken: 120.03728036880493\n",
      "Iteration:  8 Percent:  0.7\n",
      "=> loading checkpoint '/kaggle/working/model_best.pth.tar'\n",
      "=> loaded checkpoint '/kaggle/working/model_best.pth.tar' (epoch 19) Prec1: 0.895400\n",
      "layer index: 4 \t total channel: 16 \t remaining channel: 13\n",
      "layer index: 7 \t total channel: 16 \t remaining channel: 15\n",
      "layer index: 9 \t total channel: 16 \t remaining channel: 16\n",
      "layer index: 15 \t total channel: 64 \t remaining channel: 21\n",
      "layer index: 18 \t total channel: 16 \t remaining channel: 12\n",
      "layer index: 20 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 24 \t total channel: 64 \t remaining channel: 21\n",
      "layer index: 27 \t total channel: 16 \t remaining channel: 13\n",
      "layer index: 29 \t total channel: 16 \t remaining channel: 13\n",
      "layer index: 33 \t total channel: 64 \t remaining channel: 19\n",
      "layer index: 36 \t total channel: 16 \t remaining channel: 12\n",
      "layer index: 38 \t total channel: 16 \t remaining channel: 13\n",
      "layer index: 42 \t total channel: 64 \t remaining channel: 11\n",
      "layer index: 45 \t total channel: 16 \t remaining channel: 8\n",
      "layer index: 47 \t total channel: 16 \t remaining channel: 10\n",
      "layer index: 51 \t total channel: 64 \t remaining channel: 18\n",
      "layer index: 54 \t total channel: 16 \t remaining channel: 12\n",
      "layer index: 56 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 60 \t total channel: 64 \t remaining channel: 18\n",
      "layer index: 63 \t total channel: 16 \t remaining channel: 10\n",
      "layer index: 65 \t total channel: 16 \t remaining channel: 9\n",
      "layer index: 69 \t total channel: 64 \t remaining channel: 19\n",
      "layer index: 72 \t total channel: 16 \t remaining channel: 12\n",
      "layer index: 74 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 78 \t total channel: 64 \t remaining channel: 20\n",
      "layer index: 81 \t total channel: 16 \t remaining channel: 12\n",
      "layer index: 83 \t total channel: 16 \t remaining channel: 12\n",
      "layer index: 87 \t total channel: 64 \t remaining channel: 21\n",
      "layer index: 90 \t total channel: 16 \t remaining channel: 12\n",
      "layer index: 92 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 96 \t total channel: 64 \t remaining channel: 18\n",
      "layer index: 99 \t total channel: 16 \t remaining channel: 10\n",
      "layer index: 101 \t total channel: 16 \t remaining channel: 12\n",
      "layer index: 105 \t total channel: 64 \t remaining channel: 14\n",
      "layer index: 108 \t total channel: 16 \t remaining channel: 3\n",
      "layer index: 110 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 114 \t total channel: 64 \t remaining channel: 13\n",
      "layer index: 117 \t total channel: 16 \t remaining channel: 6\n",
      "layer index: 119 \t total channel: 16 \t remaining channel: 10\n",
      "layer index: 123 \t total channel: 64 \t remaining channel: 15\n",
      "layer index: 126 \t total channel: 16 \t remaining channel: 11\n",
      "layer index: 128 \t total channel: 16 \t remaining channel: 12\n",
      "layer index: 132 \t total channel: 64 \t remaining channel: 11\n",
      "layer index: 135 \t total channel: 16 \t remaining channel: 8\n",
      "layer index: 137 \t total channel: 16 \t remaining channel: 12\n",
      "layer index: 141 \t total channel: 64 \t remaining channel: 15\n",
      "layer index: 144 \t total channel: 16 \t remaining channel: 8\n",
      "layer index: 146 \t total channel: 16 \t remaining channel: 11\n",
      "layer index: 150 \t total channel: 64 \t remaining channel: 12\n",
      "layer index: 153 \t total channel: 16 \t remaining channel: 9\n",
      "layer index: 155 \t total channel: 16 \t remaining channel: 14\n",
      "layer index: 159 \t total channel: 64 \t remaining channel: 11\n",
      "layer index: 162 \t total channel: 16 \t remaining channel: 7\n",
      "layer index: 164 \t total channel: 16 \t remaining channel: 8\n",
      "layer index: 169 \t total channel: 64 \t remaining channel: 31\n",
      "layer index: 172 \t total channel: 32 \t remaining channel: 22\n",
      "layer index: 174 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 180 \t total channel: 128 \t remaining channel: 28\n",
      "layer index: 183 \t total channel: 32 \t remaining channel: 17\n",
      "layer index: 185 \t total channel: 32 \t remaining channel: 31\n",
      "layer index: 189 \t total channel: 128 \t remaining channel: 23\n",
      "layer index: 192 \t total channel: 32 \t remaining channel: 21\n",
      "layer index: 194 \t total channel: 32 \t remaining channel: 31\n",
      "layer index: 198 \t total channel: 128 \t remaining channel: 21\n",
      "layer index: 201 \t total channel: 32 \t remaining channel: 19\n",
      "layer index: 203 \t total channel: 32 \t remaining channel: 30\n",
      "layer index: 207 \t total channel: 128 \t remaining channel: 27\n",
      "layer index: 210 \t total channel: 32 \t remaining channel: 21\n",
      "layer index: 212 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 216 \t total channel: 128 \t remaining channel: 23\n",
      "layer index: 219 \t total channel: 32 \t remaining channel: 18\n",
      "layer index: 221 \t total channel: 32 \t remaining channel: 30\n",
      "layer index: 225 \t total channel: 128 \t remaining channel: 24\n",
      "layer index: 228 \t total channel: 32 \t remaining channel: 23\n",
      "layer index: 230 \t total channel: 32 \t remaining channel: 29\n",
      "layer index: 234 \t total channel: 128 \t remaining channel: 26\n",
      "layer index: 237 \t total channel: 32 \t remaining channel: 21\n",
      "layer index: 239 \t total channel: 32 \t remaining channel: 29\n",
      "layer index: 243 \t total channel: 128 \t remaining channel: 26\n",
      "layer index: 246 \t total channel: 32 \t remaining channel: 23\n",
      "layer index: 248 \t total channel: 32 \t remaining channel: 30\n",
      "layer index: 252 \t total channel: 128 \t remaining channel: 14\n",
      "layer index: 255 \t total channel: 32 \t remaining channel: 19\n",
      "layer index: 257 \t total channel: 32 \t remaining channel: 30\n",
      "layer index: 261 \t total channel: 128 \t remaining channel: 17\n",
      "layer index: 264 \t total channel: 32 \t remaining channel: 14\n",
      "layer index: 266 \t total channel: 32 \t remaining channel: 30\n",
      "layer index: 270 \t total channel: 128 \t remaining channel: 14\n",
      "layer index: 273 \t total channel: 32 \t remaining channel: 15\n",
      "layer index: 275 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 279 \t total channel: 128 \t remaining channel: 23\n",
      "layer index: 282 \t total channel: 32 \t remaining channel: 18\n",
      "layer index: 284 \t total channel: 32 \t remaining channel: 32\n",
      "layer index: 288 \t total channel: 128 \t remaining channel: 12\n",
      "layer index: 291 \t total channel: 32 \t remaining channel: 16\n",
      "layer index: 293 \t total channel: 32 \t remaining channel: 30\n",
      "layer index: 297 \t total channel: 128 \t remaining channel: 26\n",
      "layer index: 300 \t total channel: 32 \t remaining channel: 22\n",
      "layer index: 302 \t total channel: 32 \t remaining channel: 30\n",
      "layer index: 306 \t total channel: 128 \t remaining channel: 17\n",
      "layer index: 309 \t total channel: 32 \t remaining channel: 18\n",
      "layer index: 311 \t total channel: 32 \t remaining channel: 28\n",
      "layer index: 315 \t total channel: 128 \t remaining channel: 27\n",
      "layer index: 318 \t total channel: 32 \t remaining channel: 13\n",
      "layer index: 320 \t total channel: 32 \t remaining channel: 30\n",
      "layer index: 324 \t total channel: 128 \t remaining channel: 22\n",
      "layer index: 327 \t total channel: 32 \t remaining channel: 15\n",
      "layer index: 329 \t total channel: 32 \t remaining channel: 31\n",
      "layer index: 334 \t total channel: 128 \t remaining channel: 16\n",
      "layer index: 337 \t total channel: 64 \t remaining channel: 11\n",
      "layer index: 339 \t total channel: 64 \t remaining channel: 62\n",
      "layer index: 345 \t total channel: 256 \t remaining channel: 13\n",
      "layer index: 348 \t total channel: 64 \t remaining channel: 14\n",
      "layer index: 350 \t total channel: 64 \t remaining channel: 62\n",
      "layer index: 354 \t total channel: 256 \t remaining channel: 12\n",
      "layer index: 357 \t total channel: 64 \t remaining channel: 15\n",
      "layer index: 359 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 363 \t total channel: 256 \t remaining channel: 14\n",
      "layer index: 366 \t total channel: 64 \t remaining channel: 15\n",
      "layer index: 368 \t total channel: 64 \t remaining channel: 63\n",
      "layer index: 372 \t total channel: 256 \t remaining channel: 7\n",
      "layer index: 375 \t total channel: 64 \t remaining channel: 14\n",
      "layer index: 377 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 381 \t total channel: 256 \t remaining channel: 13\n",
      "layer index: 384 \t total channel: 64 \t remaining channel: 14\n",
      "layer index: 386 \t total channel: 64 \t remaining channel: 62\n",
      "layer index: 390 \t total channel: 256 \t remaining channel: 7\n",
      "layer index: 393 \t total channel: 64 \t remaining channel: 11\n",
      "layer index: 395 \t total channel: 64 \t remaining channel: 63\n",
      "layer index: 399 \t total channel: 256 \t remaining channel: 8\n",
      "layer index: 402 \t total channel: 64 \t remaining channel: 17\n",
      "layer index: 404 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 408 \t total channel: 256 \t remaining channel: 8\n",
      "layer index: 411 \t total channel: 64 \t remaining channel: 8\n",
      "layer index: 413 \t total channel: 64 \t remaining channel: 63\n",
      "layer index: 417 \t total channel: 256 \t remaining channel: 8\n",
      "layer index: 420 \t total channel: 64 \t remaining channel: 12\n",
      "layer index: 422 \t total channel: 64 \t remaining channel: 59\n",
      "layer index: 426 \t total channel: 256 \t remaining channel: 8\n",
      "layer index: 429 \t total channel: 64 \t remaining channel: 10\n",
      "layer index: 431 \t total channel: 64 \t remaining channel: 61\n",
      "layer index: 435 \t total channel: 256 \t remaining channel: 8\n",
      "layer index: 438 \t total channel: 64 \t remaining channel: 13\n",
      "layer index: 440 \t total channel: 64 \t remaining channel: 56\n",
      "layer index: 444 \t total channel: 256 \t remaining channel: 8\n",
      "layer index: 447 \t total channel: 64 \t remaining channel: 9\n",
      "layer index: 449 \t total channel: 64 \t remaining channel: 60\n",
      "layer index: 453 \t total channel: 256 \t remaining channel: 8\n",
      "layer index: 456 \t total channel: 64 \t remaining channel: 7\n",
      "layer index: 458 \t total channel: 64 \t remaining channel: 61\n",
      "layer index: 462 \t total channel: 256 \t remaining channel: 8\n",
      "layer index: 465 \t total channel: 64 \t remaining channel: 11\n",
      "layer index: 467 \t total channel: 64 \t remaining channel: 59\n",
      "layer index: 471 \t total channel: 256 \t remaining channel: 6\n",
      "layer index: 474 \t total channel: 64 \t remaining channel: 8\n",
      "layer index: 476 \t total channel: 64 \t remaining channel: 60\n",
      "layer index: 480 \t total channel: 256 \t remaining channel: 3\n",
      "layer index: 483 \t total channel: 64 \t remaining channel: 4\n",
      "layer index: 485 \t total channel: 64 \t remaining channel: 55\n",
      "layer index: 489 \t total channel: 256 \t remaining channel: 5\n",
      "layer index: 492 \t total channel: 64 \t remaining channel: 6\n",
      "layer index: 494 \t total channel: 64 \t remaining channel: 55\n",
      "layer index: 497 \t total channel: 256 \t remaining channel: 206\n",
      "Pre-processing Successful!\n",
      "\n",
      "Test set: Accuracy: 1153/10000 (11.5%)\n",
      "\n",
      "Cfg:\n",
      "[13, 15, 16, 21, 12, 14, 21, 13, 13, 19, 12, 13, 11, 8, 10, 18, 12, 14, 18, 10, 9, 19, 12, 14, 20, 12, 12, 21, 12, 14, 18, 10, 12, 14, 3, 14, 13, 6, 10, 15, 11, 12, 11, 8, 12, 15, 8, 11, 12, 9, 14, 11, 7, 8, 31, 22, 32, 28, 17, 31, 23, 21, 31, 21, 19, 30, 27, 21, 32, 23, 18, 30, 24, 23, 29, 26, 21, 29, 26, 23, 30, 14, 19, 30, 17, 14, 30, 14, 15, 32, 23, 18, 32, 12, 16, 30, 26, 22, 30, 17, 18, 28, 27, 13, 30, 22, 15, 31, 16, 11, 62, 13, 14, 62, 12, 15, 64, 14, 15, 63, 7, 14, 64, 13, 14, 62, 7, 11, 63, 8, 17, 64, 8, 8, 63, 8, 12, 59, 8, 10, 61, 8, 13, 56, 8, 9, 60, 8, 7, 61, 8, 11, 59, 6, 8, 60, 3, 4, 55, 5, 6, 55, 206]\n",
      "In shape: 13, Out shape 15.\n",
      "In shape: 15, Out shape 16.\n",
      "In shape: 16, Out shape 21.\n",
      "In shape: 21, Out shape 12.\n",
      "In shape: 12, Out shape 14.\n",
      "In shape: 14, Out shape 21.\n",
      "In shape: 21, Out shape 13.\n",
      "In shape: 13, Out shape 13.\n",
      "In shape: 13, Out shape 19.\n",
      "In shape: 19, Out shape 12.\n",
      "In shape: 12, Out shape 13.\n",
      "In shape: 13, Out shape 11.\n",
      "In shape: 11, Out shape 8.\n",
      "In shape: 8, Out shape 10.\n",
      "In shape: 10, Out shape 18.\n",
      "In shape: 18, Out shape 12.\n",
      "In shape: 12, Out shape 14.\n",
      "In shape: 14, Out shape 18.\n",
      "In shape: 18, Out shape 10.\n",
      "In shape: 10, Out shape 9.\n",
      "In shape: 9, Out shape 19.\n",
      "In shape: 19, Out shape 12.\n",
      "In shape: 12, Out shape 14.\n",
      "In shape: 14, Out shape 20.\n",
      "In shape: 20, Out shape 12.\n",
      "In shape: 12, Out shape 12.\n",
      "In shape: 12, Out shape 21.\n",
      "In shape: 21, Out shape 12.\n",
      "In shape: 12, Out shape 14.\n",
      "In shape: 14, Out shape 18.\n",
      "In shape: 18, Out shape 10.\n",
      "In shape: 10, Out shape 12.\n",
      "In shape: 12, Out shape 14.\n",
      "In shape: 14, Out shape 3.\n",
      "In shape: 3, Out shape 14.\n",
      "In shape: 14, Out shape 13.\n",
      "In shape: 13, Out shape 6.\n",
      "In shape: 6, Out shape 10.\n",
      "In shape: 10, Out shape 15.\n",
      "In shape: 15, Out shape 11.\n",
      "In shape: 11, Out shape 12.\n",
      "In shape: 12, Out shape 11.\n",
      "In shape: 11, Out shape 8.\n",
      "In shape: 8, Out shape 12.\n",
      "In shape: 12, Out shape 15.\n",
      "In shape: 15, Out shape 8.\n",
      "In shape: 8, Out shape 11.\n",
      "In shape: 11, Out shape 12.\n",
      "In shape: 12, Out shape 9.\n",
      "In shape: 9, Out shape 14.\n",
      "In shape: 14, Out shape 11.\n",
      "In shape: 11, Out shape 7.\n",
      "In shape: 7, Out shape 8.\n",
      "In shape: 8, Out shape 31.\n",
      "In shape: 31, Out shape 22.\n",
      "In shape: 22, Out shape 32.\n",
      "In shape: 32, Out shape 28.\n",
      "In shape: 28, Out shape 17.\n",
      "In shape: 17, Out shape 31.\n",
      "In shape: 31, Out shape 23.\n",
      "In shape: 23, Out shape 21.\n",
      "In shape: 21, Out shape 31.\n",
      "In shape: 31, Out shape 21.\n",
      "In shape: 21, Out shape 19.\n",
      "In shape: 19, Out shape 30.\n",
      "In shape: 30, Out shape 27.\n",
      "In shape: 27, Out shape 21.\n",
      "In shape: 21, Out shape 32.\n",
      "In shape: 32, Out shape 23.\n",
      "In shape: 23, Out shape 18.\n",
      "In shape: 18, Out shape 30.\n",
      "In shape: 30, Out shape 24.\n",
      "In shape: 24, Out shape 23.\n",
      "In shape: 23, Out shape 29.\n",
      "In shape: 29, Out shape 26.\n",
      "In shape: 26, Out shape 21.\n",
      "In shape: 21, Out shape 29.\n",
      "In shape: 29, Out shape 26.\n",
      "In shape: 26, Out shape 23.\n",
      "In shape: 23, Out shape 30.\n",
      "In shape: 30, Out shape 14.\n",
      "In shape: 14, Out shape 19.\n",
      "In shape: 19, Out shape 30.\n",
      "In shape: 30, Out shape 17.\n",
      "In shape: 17, Out shape 14.\n",
      "In shape: 14, Out shape 30.\n",
      "In shape: 30, Out shape 14.\n",
      "In shape: 14, Out shape 15.\n",
      "In shape: 15, Out shape 32.\n",
      "In shape: 32, Out shape 23.\n",
      "In shape: 23, Out shape 18.\n",
      "In shape: 18, Out shape 32.\n",
      "In shape: 32, Out shape 12.\n",
      "In shape: 12, Out shape 16.\n",
      "In shape: 16, Out shape 30.\n",
      "In shape: 30, Out shape 26.\n",
      "In shape: 26, Out shape 22.\n",
      "In shape: 22, Out shape 30.\n",
      "In shape: 30, Out shape 17.\n",
      "In shape: 17, Out shape 18.\n",
      "In shape: 18, Out shape 28.\n",
      "In shape: 28, Out shape 27.\n",
      "In shape: 27, Out shape 13.\n",
      "In shape: 13, Out shape 30.\n",
      "In shape: 30, Out shape 22.\n",
      "In shape: 22, Out shape 15.\n",
      "In shape: 15, Out shape 31.\n",
      "In shape: 31, Out shape 16.\n",
      "In shape: 16, Out shape 11.\n",
      "In shape: 11, Out shape 62.\n",
      "In shape: 62, Out shape 13.\n",
      "In shape: 13, Out shape 14.\n",
      "In shape: 14, Out shape 62.\n",
      "In shape: 62, Out shape 12.\n",
      "In shape: 12, Out shape 15.\n",
      "In shape: 15, Out shape 64.\n",
      "In shape: 64, Out shape 14.\n",
      "In shape: 14, Out shape 15.\n",
      "In shape: 15, Out shape 63.\n",
      "In shape: 63, Out shape 7.\n",
      "In shape: 7, Out shape 14.\n",
      "In shape: 14, Out shape 64.\n",
      "In shape: 64, Out shape 13.\n",
      "In shape: 13, Out shape 14.\n",
      "In shape: 14, Out shape 62.\n",
      "In shape: 62, Out shape 7.\n",
      "In shape: 7, Out shape 11.\n",
      "In shape: 11, Out shape 63.\n",
      "In shape: 63, Out shape 8.\n",
      "In shape: 8, Out shape 17.\n",
      "In shape: 17, Out shape 64.\n",
      "In shape: 64, Out shape 8.\n",
      "In shape: 8, Out shape 8.\n",
      "In shape: 8, Out shape 63.\n",
      "In shape: 63, Out shape 8.\n",
      "In shape: 8, Out shape 12.\n",
      "In shape: 12, Out shape 59.\n",
      "In shape: 59, Out shape 8.\n",
      "In shape: 8, Out shape 10.\n",
      "In shape: 10, Out shape 61.\n",
      "In shape: 61, Out shape 8.\n",
      "In shape: 8, Out shape 13.\n",
      "In shape: 13, Out shape 56.\n",
      "In shape: 56, Out shape 8.\n",
      "In shape: 8, Out shape 9.\n",
      "In shape: 9, Out shape 60.\n",
      "In shape: 60, Out shape 8.\n",
      "In shape: 8, Out shape 7.\n",
      "In shape: 7, Out shape 61.\n",
      "In shape: 61, Out shape 8.\n",
      "In shape: 8, Out shape 11.\n",
      "In shape: 11, Out shape 59.\n",
      "In shape: 59, Out shape 6.\n",
      "In shape: 6, Out shape 8.\n",
      "In shape: 8, Out shape 60.\n",
      "In shape: 60, Out shape 3.\n",
      "In shape: 3, Out shape 4.\n",
      "In shape: 4, Out shape 55.\n",
      "In shape: 55, Out shape 5.\n",
      "In shape: 5, Out shape 6.\n",
      "In shape: 6, Out shape 55.\n",
      "In shape: 55, Out shape 206.\n",
      "resnet(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(13, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(21, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(12, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(14, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(21, 13, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(13, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(13, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(19, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(12, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(13, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(11, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(8, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(10, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(18, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(12, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(14, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(18, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(10, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(9, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(19, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(12, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(14, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(20, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(12, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(21, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(12, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(14, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(18, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(10, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(12, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(14, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(3, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(14, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(13, 6, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(10, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(15, 11, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(11, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(12, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(11, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(8, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(12, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(15, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(8, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(11, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(12, 9, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(9, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(14, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(11, 7, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(7, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(31, 22, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(22, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(28, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(17, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(31, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(23, 21, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(21, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(31, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(21, 19, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(19, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(30, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(27, 21, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(21, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(23, 18, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(18, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(30, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(24, 23, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(23, 29, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(29, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(26, 21, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(21, 29, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(29, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(26, 23, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(23, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(30, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(14, 19, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(19, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(30, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(17, 14, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(14, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(30, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(14, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(23, 18, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(18, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(12, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(30, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(26, 22, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(22, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(30, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(17, 18, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(18, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(28, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(27, 13, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(13, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(30, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(22, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(31, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(16, 11, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(11, 62, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(62, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(13, 14, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(14, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(62, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(12, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(14, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(15, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(63, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(7, 14, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(14, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(13, 14, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(14, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(62, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(7, 11, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(11, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(63, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(8, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(17, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(8, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(63, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(8, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(12, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(59, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(8, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(10, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(61, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(8, 13, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(13, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(56, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(8, 9, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(9, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(60, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(8, 7, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(7, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(61, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(8, 11, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(11, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(59, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(6, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(8, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(60, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(3, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(4, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(55, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (select): channel_selection()\n",
      "      (conv1): Conv2d(5, 6, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(6, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(55, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (select): channel_selection()\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
      "  (fc): Linear(in_features=206, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "Test set: Accuracy: 1153/10000 (11.5%)\n",
      "\n",
      "Train Epoch: 0 [0/50000 (0.0%)]\tLoss: 1.477410\n",
      "Train Epoch: 0 [6400/50000 (12.8%)]\tLoss: 1.018968\n",
      "Train Epoch: 0 [12800/50000 (25.6%)]\tLoss: 0.914615\n",
      "Train Epoch: 0 [19200/50000 (38.4%)]\tLoss: 0.659867\n",
      "Train Epoch: 0 [25600/50000 (51.2%)]\tLoss: 0.871879\n",
      "Train Epoch: 0 [32000/50000 (63.9%)]\tLoss: 0.517678\n",
      "Train Epoch: 0 [38400/50000 (76.7%)]\tLoss: 0.782508\n",
      "Train Epoch: 0 [44800/50000 (89.5%)]\tLoss: 0.270199\n",
      "\n",
      "Test set: Average loss: 0.7397, Accuracy: 7574/10000 (75.7%)\n",
      "\n",
      "Train Epoch: 1 [0/50000 (0.0%)]\tLoss: 0.596703\n",
      "Train Epoch: 1 [6400/50000 (12.8%)]\tLoss: 0.773429\n",
      "Train Epoch: 1 [12800/50000 (25.6%)]\tLoss: 0.733481\n",
      "Train Epoch: 1 [19200/50000 (38.4%)]\tLoss: 0.630519\n",
      "Train Epoch: 1 [25600/50000 (51.2%)]\tLoss: 0.563140\n",
      "Train Epoch: 1 [32000/50000 (63.9%)]\tLoss: 0.426911\n",
      "Train Epoch: 1 [38400/50000 (76.7%)]\tLoss: 0.502984\n",
      "Train Epoch: 1 [44800/50000 (89.5%)]\tLoss: 0.551437\n",
      "\n",
      "Test set: Average loss: 0.7897, Accuracy: 7393/10000 (73.9%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0.0%)]\tLoss: 0.525033\n",
      "Train Epoch: 2 [6400/50000 (12.8%)]\tLoss: 0.537664\n",
      "Train Epoch: 2 [12800/50000 (25.6%)]\tLoss: 0.545715\n",
      "Train Epoch: 2 [19200/50000 (38.4%)]\tLoss: 0.392317\n",
      "Train Epoch: 2 [25600/50000 (51.2%)]\tLoss: 0.558142\n",
      "Train Epoch: 2 [32000/50000 (63.9%)]\tLoss: 0.383393\n",
      "Train Epoch: 2 [38400/50000 (76.7%)]\tLoss: 0.709343\n",
      "Train Epoch: 2 [44800/50000 (89.5%)]\tLoss: 0.676718\n",
      "\n",
      "Test set: Average loss: 0.6653, Accuracy: 7746/10000 (77.5%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0.0%)]\tLoss: 0.566263\n",
      "Train Epoch: 3 [6400/50000 (12.8%)]\tLoss: 0.468314\n",
      "Train Epoch: 3 [12800/50000 (25.6%)]\tLoss: 0.445211\n",
      "Train Epoch: 3 [19200/50000 (38.4%)]\tLoss: 0.570514\n",
      "Train Epoch: 3 [25600/50000 (51.2%)]\tLoss: 0.483216\n",
      "Train Epoch: 3 [32000/50000 (63.9%)]\tLoss: 0.518998\n",
      "Train Epoch: 3 [38400/50000 (76.7%)]\tLoss: 0.391286\n",
      "Train Epoch: 3 [44800/50000 (89.5%)]\tLoss: 0.387754\n",
      "\n",
      "Test set: Average loss: 0.6252, Accuracy: 7849/10000 (78.5%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0.0%)]\tLoss: 0.525040\n",
      "Train Epoch: 4 [6400/50000 (12.8%)]\tLoss: 0.350690\n",
      "Train Epoch: 4 [12800/50000 (25.6%)]\tLoss: 0.522237\n",
      "Train Epoch: 4 [19200/50000 (38.4%)]\tLoss: 0.458508\n",
      "Train Epoch: 4 [25600/50000 (51.2%)]\tLoss: 0.473776\n",
      "Train Epoch: 4 [32000/50000 (63.9%)]\tLoss: 0.877530\n",
      "Train Epoch: 4 [38400/50000 (76.7%)]\tLoss: 0.459282\n",
      "Train Epoch: 4 [44800/50000 (89.5%)]\tLoss: 0.493374\n",
      "\n",
      "Test set: Average loss: 0.5967, Accuracy: 7984/10000 (79.8%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0.0%)]\tLoss: 0.557502\n",
      "Train Epoch: 5 [6400/50000 (12.8%)]\tLoss: 0.569671\n",
      "Train Epoch: 5 [12800/50000 (25.6%)]\tLoss: 0.541783\n",
      "Train Epoch: 5 [19200/50000 (38.4%)]\tLoss: 0.429503\n",
      "Train Epoch: 5 [25600/50000 (51.2%)]\tLoss: 0.670469\n",
      "Train Epoch: 5 [32000/50000 (63.9%)]\tLoss: 0.448079\n",
      "Train Epoch: 5 [38400/50000 (76.7%)]\tLoss: 0.555517\n",
      "Train Epoch: 5 [44800/50000 (89.5%)]\tLoss: 0.392424\n",
      "\n",
      "Test set: Average loss: 0.6538, Accuracy: 7818/10000 (78.2%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0.0%)]\tLoss: 0.620813\n",
      "Train Epoch: 6 [6400/50000 (12.8%)]\tLoss: 0.606149\n",
      "Train Epoch: 6 [12800/50000 (25.6%)]\tLoss: 0.395784\n",
      "Train Epoch: 6 [19200/50000 (38.4%)]\tLoss: 0.566759\n",
      "Train Epoch: 6 [25600/50000 (51.2%)]\tLoss: 0.623691\n",
      "Train Epoch: 6 [32000/50000 (63.9%)]\tLoss: 0.556601\n",
      "Train Epoch: 6 [38400/50000 (76.7%)]\tLoss: 0.452755\n",
      "Train Epoch: 6 [44800/50000 (89.5%)]\tLoss: 0.646634\n",
      "\n",
      "Test set: Average loss: 0.6117, Accuracy: 7988/10000 (79.9%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0.0%)]\tLoss: 0.601821\n",
      "Train Epoch: 7 [6400/50000 (12.8%)]\tLoss: 0.433782\n",
      "Train Epoch: 7 [12800/50000 (25.6%)]\tLoss: 0.358763\n",
      "Train Epoch: 7 [19200/50000 (38.4%)]\tLoss: 0.622254\n",
      "Train Epoch: 7 [25600/50000 (51.2%)]\tLoss: 0.565909\n",
      "Train Epoch: 7 [32000/50000 (63.9%)]\tLoss: 0.379893\n",
      "Train Epoch: 7 [38400/50000 (76.7%)]\tLoss: 0.549176\n",
      "Train Epoch: 7 [44800/50000 (89.5%)]\tLoss: 0.472415\n",
      "\n",
      "Test set: Average loss: 0.5275, Accuracy: 8242/10000 (82.4%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0.0%)]\tLoss: 0.438345\n",
      "Train Epoch: 8 [6400/50000 (12.8%)]\tLoss: 0.342075\n",
      "Train Epoch: 8 [12800/50000 (25.6%)]\tLoss: 0.315409\n",
      "Train Epoch: 8 [19200/50000 (38.4%)]\tLoss: 0.391801\n",
      "Train Epoch: 8 [25600/50000 (51.2%)]\tLoss: 0.478973\n",
      "Train Epoch: 8 [32000/50000 (63.9%)]\tLoss: 0.314270\n",
      "Train Epoch: 8 [38400/50000 (76.7%)]\tLoss: 0.369651\n",
      "Train Epoch: 8 [44800/50000 (89.5%)]\tLoss: 0.492359\n",
      "\n",
      "Test set: Average loss: 0.5373, Accuracy: 8216/10000 (82.2%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0.0%)]\tLoss: 0.480335\n",
      "Train Epoch: 9 [6400/50000 (12.8%)]\tLoss: 0.391604\n",
      "Train Epoch: 9 [12800/50000 (25.6%)]\tLoss: 0.348717\n",
      "Train Epoch: 9 [19200/50000 (38.4%)]\tLoss: 0.517445\n",
      "Train Epoch: 9 [25600/50000 (51.2%)]\tLoss: 0.376037\n",
      "Train Epoch: 9 [32000/50000 (63.9%)]\tLoss: 0.478044\n",
      "Train Epoch: 9 [38400/50000 (76.7%)]\tLoss: 0.335912\n",
      "Train Epoch: 9 [44800/50000 (89.5%)]\tLoss: 0.322575\n",
      "\n",
      "Test set: Average loss: 0.6291, Accuracy: 7895/10000 (78.9%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0.0%)]\tLoss: 0.780557\n",
      "Train Epoch: 10 [6400/50000 (12.8%)]\tLoss: 0.364839\n",
      "Train Epoch: 10 [12800/50000 (25.6%)]\tLoss: 0.287351\n",
      "Train Epoch: 10 [19200/50000 (38.4%)]\tLoss: 0.135574\n",
      "Train Epoch: 10 [25600/50000 (51.2%)]\tLoss: 0.340650\n",
      "Train Epoch: 10 [32000/50000 (63.9%)]\tLoss: 0.281263\n",
      "Train Epoch: 10 [38400/50000 (76.7%)]\tLoss: 0.276142\n",
      "Train Epoch: 10 [44800/50000 (89.5%)]\tLoss: 0.247094\n",
      "\n",
      "Test set: Average loss: 0.3326, Accuracy: 8860/10000 (88.6%)\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0.0%)]\tLoss: 0.256713\n",
      "Train Epoch: 11 [6400/50000 (12.8%)]\tLoss: 0.293882\n",
      "Train Epoch: 11 [12800/50000 (25.6%)]\tLoss: 0.218673\n",
      "Train Epoch: 11 [19200/50000 (38.4%)]\tLoss: 0.159433\n",
      "Train Epoch: 11 [25600/50000 (51.2%)]\tLoss: 0.286972\n",
      "Train Epoch: 11 [32000/50000 (63.9%)]\tLoss: 0.361729\n",
      "Train Epoch: 11 [38400/50000 (76.7%)]\tLoss: 0.365691\n",
      "Train Epoch: 11 [44800/50000 (89.5%)]\tLoss: 0.323439\n",
      "\n",
      "Test set: Average loss: 0.3183, Accuracy: 8933/10000 (89.3%)\n",
      "\n",
      "Train Epoch: 12 [0/50000 (0.0%)]\tLoss: 0.285550\n",
      "Train Epoch: 12 [6400/50000 (12.8%)]\tLoss: 0.178804\n",
      "Train Epoch: 12 [12800/50000 (25.6%)]\tLoss: 0.239161\n",
      "Train Epoch: 12 [19200/50000 (38.4%)]\tLoss: 0.211057\n",
      "Train Epoch: 12 [25600/50000 (51.2%)]\tLoss: 0.191336\n",
      "Train Epoch: 12 [32000/50000 (63.9%)]\tLoss: 0.209166\n",
      "Train Epoch: 12 [38400/50000 (76.7%)]\tLoss: 0.228537\n",
      "Train Epoch: 12 [44800/50000 (89.5%)]\tLoss: 0.268753\n",
      "\n",
      "Test set: Average loss: 0.3105, Accuracy: 8949/10000 (89.5%)\n",
      "\n",
      "Train Epoch: 13 [0/50000 (0.0%)]\tLoss: 0.251447\n",
      "Train Epoch: 13 [6400/50000 (12.8%)]\tLoss: 0.384810\n",
      "Train Epoch: 13 [12800/50000 (25.6%)]\tLoss: 0.234471\n",
      "Train Epoch: 13 [19200/50000 (38.4%)]\tLoss: 0.284644\n",
      "Train Epoch: 13 [25600/50000 (51.2%)]\tLoss: 0.253208\n",
      "Train Epoch: 13 [32000/50000 (63.9%)]\tLoss: 0.376484\n",
      "Train Epoch: 13 [38400/50000 (76.7%)]\tLoss: 0.139016\n",
      "Train Epoch: 13 [44800/50000 (89.5%)]\tLoss: 0.157224\n",
      "\n",
      "Test set: Average loss: 0.3083, Accuracy: 8965/10000 (89.7%)\n",
      "\n",
      "Train Epoch: 14 [0/50000 (0.0%)]\tLoss: 0.211394\n",
      "Train Epoch: 14 [6400/50000 (12.8%)]\tLoss: 0.416209\n",
      "Train Epoch: 14 [12800/50000 (25.6%)]\tLoss: 0.288246\n",
      "Train Epoch: 14 [19200/50000 (38.4%)]\tLoss: 0.320208\n",
      "Train Epoch: 14 [25600/50000 (51.2%)]\tLoss: 0.325210\n",
      "Train Epoch: 14 [32000/50000 (63.9%)]\tLoss: 0.359122\n",
      "Train Epoch: 14 [38400/50000 (76.7%)]\tLoss: 0.353794\n",
      "Train Epoch: 14 [44800/50000 (89.5%)]\tLoss: 0.320376\n",
      "\n",
      "Test set: Average loss: 0.3156, Accuracy: 8957/10000 (89.6%)\n",
      "\n",
      "Train Epoch: 15 [0/50000 (0.0%)]\tLoss: 0.229546\n",
      "Train Epoch: 15 [6400/50000 (12.8%)]\tLoss: 0.119038\n",
      "Train Epoch: 15 [12800/50000 (25.6%)]\tLoss: 0.208354\n",
      "Train Epoch: 15 [19200/50000 (38.4%)]\tLoss: 0.155958\n",
      "Train Epoch: 15 [25600/50000 (51.2%)]\tLoss: 0.233659\n",
      "Train Epoch: 15 [32000/50000 (63.9%)]\tLoss: 0.477895\n",
      "Train Epoch: 15 [38400/50000 (76.7%)]\tLoss: 0.143252\n",
      "Train Epoch: 15 [44800/50000 (89.5%)]\tLoss: 0.275975\n",
      "\n",
      "Test set: Average loss: 0.2978, Accuracy: 9011/10000 (90.1%)\n",
      "\n",
      "Train Epoch: 16 [0/50000 (0.0%)]\tLoss: 0.218118\n",
      "Train Epoch: 16 [6400/50000 (12.8%)]\tLoss: 0.127037\n",
      "Train Epoch: 16 [12800/50000 (25.6%)]\tLoss: 0.230613\n",
      "Train Epoch: 16 [19200/50000 (38.4%)]\tLoss: 0.296643\n",
      "Train Epoch: 16 [25600/50000 (51.2%)]\tLoss: 0.104069\n",
      "Train Epoch: 16 [32000/50000 (63.9%)]\tLoss: 0.216797\n",
      "Train Epoch: 16 [38400/50000 (76.7%)]\tLoss: 0.276396\n",
      "Train Epoch: 16 [44800/50000 (89.5%)]\tLoss: 0.142723\n",
      "\n",
      "Test set: Average loss: 0.2933, Accuracy: 9017/10000 (90.2%)\n",
      "\n",
      "Train Epoch: 17 [0/50000 (0.0%)]\tLoss: 0.239336\n",
      "Train Epoch: 17 [6400/50000 (12.8%)]\tLoss: 0.110756\n",
      "Train Epoch: 17 [12800/50000 (25.6%)]\tLoss: 0.104012\n",
      "Train Epoch: 17 [19200/50000 (38.4%)]\tLoss: 0.327090\n",
      "Train Epoch: 17 [25600/50000 (51.2%)]\tLoss: 0.157950\n",
      "Train Epoch: 17 [32000/50000 (63.9%)]\tLoss: 0.156326\n",
      "Train Epoch: 17 [38400/50000 (76.7%)]\tLoss: 0.215951\n",
      "Train Epoch: 17 [44800/50000 (89.5%)]\tLoss: 0.199387\n",
      "\n",
      "Test set: Average loss: 0.2940, Accuracy: 9026/10000 (90.3%)\n",
      "\n",
      "Train Epoch: 18 [0/50000 (0.0%)]\tLoss: 0.180867\n",
      "Train Epoch: 18 [6400/50000 (12.8%)]\tLoss: 0.246153\n",
      "Train Epoch: 18 [12800/50000 (25.6%)]\tLoss: 0.225963\n",
      "Train Epoch: 18 [19200/50000 (38.4%)]\tLoss: 0.258628\n",
      "Train Epoch: 18 [25600/50000 (51.2%)]\tLoss: 0.270532\n",
      "Train Epoch: 18 [32000/50000 (63.9%)]\tLoss: 0.269480\n",
      "Train Epoch: 18 [38400/50000 (76.7%)]\tLoss: 0.227164\n",
      "Train Epoch: 18 [44800/50000 (89.5%)]\tLoss: 0.170213\n",
      "\n",
      "Test set: Average loss: 0.2902, Accuracy: 9034/10000 (90.3%)\n",
      "\n",
      "Train Epoch: 19 [0/50000 (0.0%)]\tLoss: 0.188195\n",
      "Train Epoch: 19 [6400/50000 (12.8%)]\tLoss: 0.157050\n",
      "Train Epoch: 19 [12800/50000 (25.6%)]\tLoss: 0.309204\n",
      "Train Epoch: 19 [19200/50000 (38.4%)]\tLoss: 0.283684\n",
      "Train Epoch: 19 [25600/50000 (51.2%)]\tLoss: 0.170018\n",
      "Train Epoch: 19 [32000/50000 (63.9%)]\tLoss: 0.294499\n",
      "Train Epoch: 19 [38400/50000 (76.7%)]\tLoss: 0.261021\n",
      "Train Epoch: 19 [44800/50000 (89.5%)]\tLoss: 0.166261\n",
      "\n",
      "Test set: Average loss: 0.2920, Accuracy: 9042/10000 (90.4%)\n",
      "\n",
      "Best accuracy: tensor(0.9042)\n",
      "Number of parameters: 672185\n",
      "Average Time taken: 114.91973477602005\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkgAAAHHCAYAAABEEKc/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABf7ElEQVR4nO3deVhUZf8G8HtmYBhkV3ZEEERxBUXFPS0K03AJt8xwKc2FXsvK5dXStDfLX5mlVlYu5b6huZSF5JIbKAIuCAmi7JvKvs+c3x/EJJsCMhyW+3Ndc10vz5zl+xxN7vec5zyPRBAEAURERESkJhW7ACIiIqLGhgGJiIiIqAIGJCIiIqIKGJCIiIiIKmBAIiIiIqqAAYmIiIioAgYkIiIiogoYkIiIiIgqYEAiIiIiqoABiYiohZJIJPD19RW7DKJGiQGJiB7rm2++gUQigbu7u9ilNEmpqalYvHgxunfvDn19fSgUCnTo0AHTp0/HuXPnxC6PiKqhJXYBRNS47dy5E/b29ggKCkJUVBQ6dOggdklNRlBQEEaOHIns7GxMmjQJs2fPho6ODmJiYnD48GFs27YNZ86cwZAhQ8QulYgqYEAiomrFxMTgwoUL8PPzw5tvvomdO3di+fLlYpdVpdzcXOjp6YldhtrDhw8xZswYaGlpITQ0FM7OzuW+//jjj7Fnzx7o6uo+9jiNrV9ELQUfsRFRtXbu3AkTExOMHDkS48aNw86dO6vcLiMjA++88w7s7e2ho6ODtm3bwsfHB+np6eptCgoKsGLFCnTs2BEKhQJWVlZ4+eWXER0dDQA4ffo0JBIJTp8+Xe7Yd+/ehUQiwbZt29Rt06ZNg76+PqKjozFixAgYGBjg1VdfBQD89ddfGD9+PNq1awcdHR3Y2trinXfeQX5+fqW6IyIiMGHCBJiZmUFXVxedOnXC0qVLAQCnTp2CRCLBoUOHKu23a9cuSCQSXLx4sdpr99133yEpKQnr1q2rFI6A0vE/r7zyCvr06aNuW7FiBSQSCcLDwzF58mSYmJhg0KBBAIBr165h2rRpcHBwgEKhgKWlJWbMmIH79++XO27ZMcr6ZmhoiDZt2mD+/PkoKCiostbDhw+jW7du0NHRQdeuXXHixIlq+0XUUvAOEhFVa+fOnXj55Zchl8vxyiuv4Ntvv8Xly5fL/VLPycnB4MGDcevWLcyYMQO9evVCeno6jhw5gvj4eJiamkKpVOKll15CQEAAJk2ahPnz5yM7Oxv+/v64ceMGHB0da11bSUkJPD09MWjQIHz++edo1aoVAGD//v3Iy8vDnDlz0KZNGwQFBWH9+vWIj4/H/v371ftfu3YNgwcPhra2NmbNmgV7e3tER0fj6NGj+N///oehQ4fC1tYWO3fuxNixYytdF0dHR/Tv37/a+o4ePQpdXV28/PLLte7b+PHj4eTkhE8++QSCIAAA/P39cefOHUyfPh2Wlpa4efMmvv/+e9y8eROXLl2CRCIpd4wJEybA3t4eq1evxqVLl/D111/j4cOH+Pnnn8ttd+7cOfj5+WHu3LkwMDDA119/DW9vb8TGxqJNmza1rp2o2RCIiKpw5coVAYDg7+8vCIIgqFQqoW3btsL8+fPLbffhhx8KAAQ/P79Kx1CpVIIgCMKWLVsEAMLatWur3ebUqVMCAOHUqVPlvo+JiREACFu3blW3TZ06VQAgLF68uNLx8vLyKrWtXr1akEgkwr1799RtQ4YMEQwMDMq1PVqPIAjCkiVLBB0dHSEjI0PdlpqaKmhpaQnLly+vdJ5HmZiYCK6urpXas7KyhLS0NPUnJydH/d3y5csFAMIrr7xSo37t3r1bACCcPXu20jFGjRpVbtu5c+cKAISwsDB1GwBBLpcLUVFR6rawsDABgLB+/frH9o+oueMjNiKq0s6dO2FhYYFhw4YBKH0kNHHiROzZswdKpVK93cGDB+Hi4lLpLkvZPmXbmJqa4q233qp2m7qYM2dOpbZHx/Tk5uYiPT0dAwYMgCAICAkJAQCkpaXh7NmzmDFjBtq1a1dtPT4+PigsLMSBAwfUbXv37kVJSQmmTJny2NqysrKgr69fqf21116DmZmZ+rNo0aJK28yePfux/SooKEB6ejr69esHALh69Wql7efNm1fu57Jr/+uvv5Zr9/DwKHcHr0ePHjA0NMSdO3ce1z2iZo8BiYgqUSqV2LNnD4YNG4aYmBhERUUhKioK7u7uSElJQUBAgHrb6OhodOvW7bHHi46ORqdOnaClVX9P9bW0tNC2bdtK7bGxsZg2bRpat24NfX19mJmZ4ZlnngEAZGZmAoD6l/+T6nZ2dkafPn3Kjb3auXMn+vXr98S3+QwMDJCTk1OpfeXKlfD394e/v3+1+7Zv375S24MHDzB//nxYWFhAV1cXZmZm6u3K+vUoJyencj87OjpCKpXi7t275dorBkQAMDExwcOHD6utj6gl4BgkIqrkzz//RFJSEvbs2YM9e/ZU+n7nzp144YUX6vWc1d1JevRu1aN0dHQglUorbfv888/jwYMHWLRoEZydnaGnp4eEhARMmzYNKpWq1nX5+Phg/vz5iI+PR2FhIS5duoQNGzY8cT9nZ2eEhYWhuLgY2tra6vYePXo8cd+q3mybMGECLly4gPfffx+urq7Q19eHSqXC8OHDa9Sv6q6vTCarsl34Z+wTUUvFgERElezcuRPm5ubYuHFjpe/8/Pxw6NAhfPfdd9DV1YWjoyNu3Ljx2OM5OjoiMDCwUlh4lImJCYDSN+Iede/evRrXff36dfz999/46aef4OPjo26veLfGwcEBAJ5YNwBMmjQJCxYswO7du5Gfnw9tbW1MnDjxifu99NJLuHTpEg4dOoQJEybUuA9VefjwIQICAvDRRx/hww8/VLffvn272n1u375d7k5UVFQUVCoV7O3tn6oWopaCj9iIqJz8/Hz4+fnhpZdewrhx4yp9fH19kZ2djSNHjgAAvL29ERYWVuXr8GV3Iby9vZGenl7lnZeybezs7CCTyXD27Nly33/zzTc1rr3sbsijdz8EQcBXX31VbjszMzMMGTIEW7ZsQWxsbJX1lDE1NcWLL76IHTt2YOfOnRg+fDhMTU2fWMucOXNgYWGBd955B3///Xel72tzh6aqfgHAunXrqt2nYrhdv349AODFF1+s8XmJWjLeQSKico4cOYLs7GyMGjWqyu/79esHMzMz7Ny5ExMnTsT777+PAwcOYPz48ZgxYwbc3Nzw4MEDHDlyBN999x1cXFzg4+ODn3/+GQsWLEBQUBAGDx6M3NxcnDx5EnPnzsXo0aNhZGSE8ePHY/369ZBIJHB0dMSxY8eQmppa49qdnZ3h6OiI9957DwkJCTA0NMTBgwerHE/z9ddfY9CgQejVqxdmzZqF9u3b4+7duzh+/DhCQ0PLbevj44Nx48YBAFatWlWjWlq3bo1Dhw7By8sLLi4umDRpEvr06QNtbW3ExcWppxyoagxQRYaGhhgyZAjWrFmD4uJi2NjY4I8//kBMTEy1+8TExGDUqFEYPnw4Ll68iB07dmDy5MlwcXGpUf1ELZ5o788RUaPk5eUlKBQKITc3t9ptpk2bJmhrawvp6emCIAjC/fv3BV9fX8HGxkaQy+VC27ZthalTp6q/F4TS19SXLl0qtG/fXtDW1hYsLS2FcePGCdHR0ept0tLSBG9vb6FVq1aCiYmJ8Oabbwo3btyo8jV/PT29KmsLDw8XPDw8BH19fcHU1FSYOXOm+tX1R48hCIJw48YNYezYsYKxsbGgUCiETp06CR988EGlYxYWFgomJiaCkZGRkJ+fX5PLqJaUlCS8//77QpcuXQRdXV1BR0dHcHBwEHx8fMq9ni8I/76in5aWVuk48fHx6lqNjIyE8ePHC4mJiQKAclMOlB0jPDxcGDdunGBgYCCYmJgIvr6+lWoHIMybN6/Suezs7ISpU6fWqp9EzY1EEDgSj4jocUpKSmBtbQ0vLy9s3rxZ7HIea8WKFfjoo4+QlpZWo0eBRFQ1jkEiInqCw4cPIy0trdzAbyJq3jgGiYioGoGBgbh27RpWrVqFnj17qudTIqLmj3eQiIiq8e2332LOnDkwNzevtIYZETVvHINEREREVAHvIBERERFVwIBEREREVAEHadeRSqVCYmIiDAwMnmo1ciIiImo4giAgOzsb1tbWldZzfBQDUh0lJibC1tZW7DKIiIioDuLi4tC2bdtqv2dAqiMDAwMApRfY0NBQ5GqIiIioJrKysmBra6v+PV4dBqQ6KnusZmhoyIBERETUxDxpeAwHaRMRERFVwIBEREREVAEDEhEREVEFDEhEREREFTAgEREREVXAgERERERUAQMSERERUQUMSEREREQVMCARERERVcCARERERFQBAxIRERFRBQxIRERERBUwIFGjU1CshFIliF0GERG1YAxI1GiUKFX48a876LnSHy98eQa3U7LFLomIiFooBiRqFG4mZmLsNxfw8fFbyC9WIjotF6M3nsfxa0lil0ZERC0QAxKJqqBYiU9/i8CoDedxPSETBgotfDSqKwY4tkFekRLzdl3FJ7/eQolSJXapRETUgjSKgLRx40bY29tDoVDA3d0dQUFB1W5bXFyMlStXwtHREQqFAi4uLjhx4kS5bVavXo0+ffrAwMAA5ubmGDNmDCIjI8ttM3ToUEgkknKf2bNna6R/VLUL0ekYvu4svjsTDaVKwIjulghY8AymDrDHzzP64s0hDgCA78/ewWubg3A/p1DkiomIqKUQPSDt3bsXCxYswPLly3H16lW4uLjA09MTqampVW6/bNkybNq0CevXr0d4eDhmz56NsWPHIiQkRL3NmTNnMG/ePFy6dAn+/v4oLi7GCy+8gNzc3HLHmjlzJpKSktSfNWvWaLSvVCozrxiLDlzD5B8Ccfd+HiwMdbDpNTd886obzA0VAAAtmRRLRnTGxsm90Eouw8U79+G1/hzC4jLELZ6IiFoEiSAIor4u5O7ujj59+mDDhg0AAJVKBVtbW7z11ltYvHhxpe2tra2xdOlSzJs3T93m7e0NXV1d7Nixo8pzpKWlwdzcHGfOnMGQIUMAlN5BcnV1xbp16+pUd1ZWFoyMjJCZmQlDQ8M6HaOlEQQBv91Ixoe/3ET6P3eDpvRrh4XDnWGo0K52v9sp2XhzezDupOdCLpNi5eiumNS3XUOVTUREzUhNf3+LegepqKgIwcHB8PDwULdJpVJ4eHjg4sWLVe5TWFgIhUJRrk1XVxfnzp2r9jyZmZkAgNatW5dr37lzJ0xNTdGtWzcsWbIEeXl51R6jsLAQWVlZ5T5Uc0mZ+Zj5czDm7ryK9JxCOJrpYf/s/vh4TPfHhiMAcLIwwGHfgXihiwWKlCos9ruOJX7XUFiibKDqiYiopdES8+Tp6elQKpWwsLAo125hYYGIiIgq9/H09MTatWsxZMgQODo6IiAgAH5+flAqq/5lqVKp8Pbbb2PgwIHo1q2bun3y5Mmws7ODtbU1rl27hkWLFiEyMhJ+fn5VHmf16tX46KOP6tjTlkulErAzKBaf/RaBnMISaMskmPOMI+YO6wCFtqzGxzFUaOO7KW749kw0Pv8jEruD4hCemIVvp7jB2lhXgz0gIqKWSNRHbImJibCxscGFCxfQv39/dfvChQtx5swZBAYGVtonLS0NM2fOxNGjRyGRSODo6AgPDw9s2bIF+fn5lbafM2cOfvvtN5w7dw5t27attpY///wTzz33HKKiouDo6Fjp+8LCQhQW/jtIOCsrC7a2tnzE9hhRqdlYfPA6rtx7CABwtTXGZ9490MnS4KmOe/bvNPxnTwgy8orRRk+O9a/0xIAOpvVRMhERNXNN4hGbqakpZDIZUlJSyrWnpKTA0tKyyn3MzMxw+PBh5Obm4t69e4iIiIC+vj4cHBwqbevr64tjx47h1KlTjw1HQOlYKACIioqq8nsdHR0YGhqW+1DVikpU+OrkbYz46hyu3HuIVnIZVnh1wcE5A546HAHAkI5mOOo7CF2tDXE/twhTNgfi+7PREHk4HRERNSOiBiS5XA43NzcEBASo21QqFQICAsrdUaqKQqGAjY0NSkpKcPDgQYwePVr9nSAI8PX1xaFDh/Dnn3+iffv2T6wlNDQUAGBlZVW3zhAAIPjeQ7y0/i98efJvFClVGNbJDP4LnsG0ge0hk0rq7Ty2rVvh4JwB8O7VFioB+OTXCPjuCkFOYUm9nYOIiFouUccgAcCCBQswdepU9O7dG3379sW6deuQm5uL6dOnAwB8fHxgY2OD1atXAwACAwORkJAAV1dXJCQkYMWKFVCpVFi4cKH6mPPmzcOuXbvwyy+/wMDAAMnJyQAAIyMj6OrqIjo6Grt27cKIESPQpk0bXLt2De+88w6GDBmCHj16NPxFaAZyCkvw+e+R+OniXQgC0EZPjuWjusKrhxUkkvoLRo9SaMvw+fgecG1njJVHb+L49ST8nZKN715zg6OZvkbOSURELYPoAWnixIlIS0vDhx9+iOTkZLi6uuLEiRPqgduxsbGQSv+90VVQUIBly5bhzp070NfXx4gRI7B9+3YYGxurt/n2228BlL7K/6itW7di2rRpkMvlOHnypDqM2drawtvbG8uWLdN4f5ujPyNSsOzQDSRmFgAAvHu1xbKRnWGiJ9f4uSUSCV7rZ4cuVoaYuzMYt1NzMHrDeXwxwQWeXat+TEtERPQkos+D1FRxHiQgPacQHx0Nx9GwRACAbWtdfDK2OwY7mYlST2p2AXx3hSAo5gEAwHdYB7zzfMd6fbRHRERNW01/fzMg1VFLDkiCIODg1QR8fDwcGXnFkEqANwY74G0PJ7SSi3tTslipwupfI7DlfAyA0gHdX010bZC7WURE1PgxIGlYSw1Isffz8N9D13EuKh0A0MXKEJ9590D3tkYiV1beL6EJWHTwGgqKVWhroovvprihm03jqpGIiBoeA5KGtbSAVKJUYcv5GKz1/xsFxSroaEnxzvMd8fqg9tCWib6kX5VuJWVh9o5g3LufBx0tKf43tjvGuT1+ugciImreGJA0rCUFpBsJmVjsdw03EkqXV+nv0AarX+4Oe1M9kSt7ssy8Yry9NwSnItMAAK/1s8MHL3WBXKtxhjoiItIsBiQNawkBKb9IiXUBf+PHv2KgVAkwVGhh2cguGN+7rcZe3dcElUrA13/exrqTtwEAvdoZ49spbrAwVDxhTyIiam4YkDSsuQekC1HpWHLoOu7dL13Ad2QPKyz36gJzg6YbKv6MSMHbe0KRVVACU30dfPNqL/Rt3/rJOxIRUbPBgKRhzTUgZeQV4ZNfb2HflXgAgJWRAqtGd4NHF4sn7Nk03Lufize3ByMiORtaUgn+O6Izpg+0b1J3xIiIqO4YkDSsuQUkQRBw/HoSVhy5ifScIkgkpeN13vfsBAOFttjl1au8ohIs8buOX0JL528a7WqN1S93F32KAiIi0rya/v7mbwRCUmY+Pjh8AydvpQIAOpjr49OXu6O3ffN8/NRKroV1E13h0tYY//v1Fn4JTURkcjY2veYGuzaNf+A5ERFpHu8g1VFzuIOkUgnYEXgPa05EIqewBNoyCeYO7YC5wxyhoyUTu7wGEXjnPubtCkF6TiEMFVr4alJPDHM2F7ssIiLSED5i07CmHpBup2Rjsd91BN97CKD0za5PvXugo4WByJU1vOTMAszZGYyQ2AxIJMD855zwn2edIOUSJUREzQ4DkoY11YBUWKLEt6ejsfFUFIqVAvTkMix60RlT3O1adCAoKlFh1bFwbL90DwDwnLM51k50hZFu8xp/RUTU0jEgaVhTDEjB9x5g8cHruJ2aA6A0BKwa0w3WxroiV9Z4HAiOx9JD11FYooJdm1b4boobOls1jT9fIiJ6MgYkDWtKASm7oBj/93sktl+6B0EATPXlWDGqK0Z2t+Lr7VW4kZCJ2TuCEf8wHwptKT7z7oHRrjZil0VERPWAAUnDmkpACriVgmWHbyApswAAMN6tLZaO7AzjVlzd/nEe5hbhP3tC8Nft0kV5ZwxsjyUjnBvtunNERFQzDEga1tgDUlp2IT46ehPHriUBANq1boXVL3fHwA6mIlfWdChVAtb6R2LjqWgAQN/2rbFhcs8mPZs4EVFLx4CkYY01IAmCgP3B8fjf8VvIzC+GTCrBG4Pb4+3nOkJX3jJe3a9vv99Mxrv7wpBTWAILQx1886ob3OxMxC6LiIjqgAFJwxpjQLp3PxdL/K7jQvR9AEA3G0N8+nIPdLMxErmypi86LQeztwfjdmoOtGUSfOjVFVPc23EMFxFRE8OApGGNKSCVKFX48VwMvvT/G4UlKii0pVjwfEfMGNgeWhwzU29yCkuw8EAYfr2eDAAY59YWH4/pBoU278wRETUVDEga1lgC0o2ETCw6eA03E7MAAAM7tMEnY7tzyQwNEQQBP/x1B5/+FgGVUHqX7ttX3WDbupXYpRERUQ0wIGmY2AEpv0iJdSf/xo/nYqBUCTDS1caykZ0xzq0tH/s0gAtR6fDdHYIHuUUwbqWNryf1xJCOZmKXRURET8CApGFiBqTzUelY4ncdsQ/yAABeLtb48KUuMDPQadA6WrqEjHzM3RGMsPhMSCTAey90wtyhjgyoRESNGAOShokRkDLyivDx8Vs4EBwPALAyUuDjMd3wXGeLBjk/VVZQrMSKIzex53IcAOCFLhb4YoILDBRcooSIqDFiQNKwhgxIgiDg2LUkfHT0JtJziiCRAFP72+M9z07Q19HS6LmpZnYHxWL5LzdRpFTBwUwPm6a4wakFLvxLRNTYMSBpWEMFpISMfHxw+Ab+jEgFADiZ6+NT7x6ch6cRCo3LwJwdwUjKLICeXIbPx7vgxe5WYpdFRESPYEDSME0HJKVKwI5L97DmRARyi5SQy6SYN6wD5gx1hFyLr+43Vuk5hXhrVwgu3imdi+rNIQ5437MTp1sgImokGJA0TJMB6e+UbCw+eA1XYzMAAL3tTPCpd3d0MOcjm6agRKnC//0eiU1n7wAABji2wfpXeqKNPgfRExGJjQFJwzQVkPzDUzB3ZzCKlQL0dbSw6EVnvNq3HaRSvhnV1By/loT3D4Qhr0gJayMFvp3iBhdbY7HLIiJq0Wr6+5v3/RuZU5GpKFYK6GNvAv8FQ/BaPzuGoyZqZA8rHJ43EA6mekjMLMD47y5i7+VYscsiIqIaYEBqpAY7mcHKSFfsMugpdbQwwGHfgXi+iwWKlCosOngdS/yuo7BEKXZpRET0GAxIRBpmqNDGpilueN+zEySS0ikBJmy6hMSMfLFLIyKiajAgETUAqVSCecM6YNv0vjBupY2wuAx4rT+HC9HpYpdGRERV4CDtOtLUIO2wuAzce5AHZ0sDdOREg81S3IM8vLk9GOFJWZBKgMUvOmPmYAcuUUJE1AD4FpuGib1YLTVtBcVK/PfQdfhdTQAAjOxuhTXjekCPM6MTEWkU32IjasQU2jJ8Md4Fq0Z3hZZUguPXkzBm43ncScsRuzQiIgIDEpFoJBIJXutvj71v9oO5gQ5up+Zg9Ibz+ONmstilERG1eHzEVkd8xEb1KTW7AL47QxB09wEAYNoAezhZ6ItclXgkkKBHWyN0tTbk2Cwiqlccg6RhDEhU34qVKnzy6y1sPX9X7FIaDQczPXj1sIaXizU6mLfcwEhE9YcBScMYkEhTfruehKPXEqFUtdz/NPOKlAiMeYCiEpW6rbOVIUa5WOOlHlawbd1KxOqIqCljQNIwBiQizcouKMbJWyk4GpaEs3+noeSRwNiznTG8elhjZA8rWBgqRKySiJoaBiQNY0AiajgPc4tw4mYyjoYl4uKd+yj7V0siAfq1bwMvF2u82M0SJnpycQslokaPAUnDGJCIxJGaVYDj15NwNCwRV2Mz1O1aUgkGOZnCq4c1XuhqAQOFtnhFElGjxYCkYQxIROKLe5CnDks3E7PU7XItKZ7tZA4vF2s862wOXblMxCqJqDFhQNIwBiSixiUqNQfHriXiSFgi7qTlqttbyWV4vosFRrlYY7CTGeRanP6NqCVjQNIwBiSixkkQBNxKysbRa4k4GpaI+If56u8MFVp4sZsVvFys0c+hNbRkDEtELQ0DkoYxIBE1foIgICQuA0fDEnH8WhJSswvV35nqyzGye2lY6tXOBFIpJ6QkagkYkDSMAYmoaVGqBATFPMCRsET8diMJGXnF6u+sjRR4ycUaXj2s0c2Gs3cTNWcMSBrGgETUdBUrVTgXlY6jYYn442YKcgpL1N+1N9WDV4/SO0tOFgYiVklEmsCApGEMSETNQ0GxEqcjU3E0LAknb6Wg8JHZu50tDeD1z52ldm04ezdRc8CApGEMSETNT05hCQJupeBoWCLO/J2GYuW//zy62BrDq4cVXuphDUsjzt5N1FQxIGkYAxJR85aZV4zfbybjSFgiLkSnQ/XI7N197FvDy8UaI7pZoo2+jriFElGtMCBpGAMSUcuRll2I326UTkh5+e5DdbtMKsHADqbw6mGFF7pawkiXs3cTNXYMSBrGgETUMiVk5OP4tUQcDUvC9YRMdbtcJsUzncwwysUaz3U2Ryu5lohVElF1GJA0jAGJiGLSc3EsrHT27tupOep2XW0ZPLpYwKuHFZ7pZAYdLS51QtRYMCBpGAMSEZURBAGRKdk4GlZ6Zyn2QZ76OwOFFoZ3tYSXizUGOLbh7N1EImNA0jAGJCKqiiAIuBafiSNhiTh2LREpWf/O3t1GT44Xu1vCq4c1+ti35uzdRCJgQNIwBiQiehKVSsDluw9w9Foifr2ejAe5RervLA0VeOmfCSl7tDXi7N1EDYQBScMYkIioNkqUKpyPvo+jYYn4/UYysh+Zvbtd61bwcrHCKBcbdLLk7N1EmsSApGEMSERUVwXFSpz9Ow1HryXhZHgK8ouV6u86WujDq4c1Rrlaw66NnohVEjVPDEgaxoBERPUhr6gEJ2+lls7eHZmGImXpUicSCfCcszlmDGqP/g5t+AiOqJ4wIGkYAxIR1bfM/GL88c/s3X/dTle3d7EyxOuD2sPLxRpyLb4FR/Q0GJA0jAGJiDQpOi0HW8/H4EBwPAqKS+8qmRnoYGp/O0x2t0NrPbnIFRI1TQxIGsaAREQNISOvCLuCYvHThbvqKQN0tKR4uVdbvD7IHh3MOaibqDYYkDSMAYmIGlJRiQq/Xk/Cj+fu4EZClrp9aCczvD6oPQZ1MOU4JaIaYEDSMAYkIhKDIAgIinmAzedi4H8rBWX/gjtbGmDGwPYY5WoNhTaXNiGqDgOShjEgEZHY7qbnYtuFu9h3JQ55RaVTBZjqyzGlnx2m9LODqb6OyBUSNT4MSBrGgEREjUVmfjH2/DNOKTGzAAAg15JijKs1Xh/kwMkniR7BgKRhDEhE1NgUK1X47UYyNp+LQVhchrp9sJMpZgxqj2eczLj+G7V4Nf393Sgm1Ni4cSPs7e2hUCjg7u6OoKCgarctLi7GypUr4ejoCIVCARcXF5w4caLcNqtXr0afPn1gYGAAc3NzjBkzBpGRkeW2KSgowLx589CmTRvo6+vD29sbKSkpGukfEVFD0JZJMcrFGofnDsDBOf3xYjdLSCXAX7fTMX3rZbyw7ix2Bcai4JGZu4moaqIHpL1792LBggVYvnw5rl69ChcXF3h6eiI1NbXK7ZctW4ZNmzZh/fr1CA8Px+zZszF27FiEhISotzlz5gzmzZuHS5cuwd/fH8XFxXjhhReQm5ur3uadd97B0aNHsX//fpw5cwaJiYl4+eWXNd5fIiJNk0gkcLNrjW+nuOHM+8Pw+qD20NfRQlRqDv576DoGfPonvvgjEqnZBWKXStRoif6Izd3dHX369MGGDRsAACqVCra2tnjrrbewePHiSttbW1tj6dKlmDdvnrrN29sburq62LFjR5XnSEtLg7m5Oc6cOYMhQ4YgMzMTZmZm2LVrF8aNGwcAiIiIQOfOnXHx4kX069fviXXzERsRNSXZBcXYezkOW8/fRUJGPgBAWybBKBcbvD6oPbpY898xahmaxCO2oqIiBAcHw8PDQ90mlUrh4eGBixcvVrlPYWEhFApFuTZdXV2cO3eu2vNkZmYCAFq3bg0ACA4ORnFxcbnzOjs7o127dtWel4ioKTNQaOONwQ448/5QfPNqL7jZmaBYKeDg1XiM+PovTP7hEgJupUCl4rBUIgDQEvPk6enpUCqVsLCwKNduYWGBiIiIKvfx9PTE2rVrMWTIEDg6OiIgIAB+fn5QKqt+pq5SqfD2229j4MCB6NatGwAgOTkZcrkcxsbGlc6bnJxc5XEKCwtRWFio/jkrK6vK7YiIGjMtmRQjulthRHcrhMQ+xOZzMfjtRjIuRN/Hhej7cDDVw/RB7eHdywat5KL+iiASlehjkGrrq6++gpOTE5ydnSGXy+Hr64vp06dDKq26K/PmzcONGzewZ8+epzrv6tWrYWRkpP7Y2to+1fGIiMTWs50JNkzuhbMLh2HWEAcYKLRwJz0XHxy+gf6r/8RnJyKQnMlxStQyiRqQTE1NIZPJKr09lpKSAktLyyr3MTMzw+HDh5Gbm4t79+4hIiIC+vr6cHBwqLStr68vjh07hlOnTqFt27bqdktLSxQVFSEjI6PG512yZAkyMzPVn7i4uFr2loiocbIx1sV/R3TGxSXPYYVXF7Rr3QqZ+cX49nQ0Bn32J97eE4Lr8Zlil0nUoEQNSHK5HG5ubggICFC3qVQqBAQEoH///o/dV6FQwMbGBiUlJTh48CBGjx6t/k4QBPj6+uLQoUP4888/0b59+3L7urm5QVtbu9x5IyMjERsbW+15dXR0YGhoWO5DRNSc6OtoYdrA9jj13lBses0Nfdu3RolKwOHQRHhtOIcJmy7i95vJUHKcErUAor/FtnfvXkydOhWbNm1C3759sW7dOuzbtw8RERGwsLCAj48PbGxssHr1agBAYGAgEhIS4OrqioSEBKxYsQIxMTG4evWqekzR3LlzsWvXLvzyyy/o1KmT+lxGRkbQ1dUFAMyZMwe//vortm3bBkNDQ7z11lsAgAsXLtSobr7FRkQtwfX4TGw+dwfHriWh5J9gZNemFaYPsMf43rbQ0+E4JWpamtRM2hs2bMD//d//ITk5Ga6urvj666/h7u4OABg6dCjs7e2xbds2AKVzHM2ZMwd37tyBvr4+RowYgU8//RTW1tbq41W3ovXWrVsxbdo0AKUTRb777rvYvXs3CgsL4enpiW+++abaR2wVMSARUUuSnFmAny7exa7AWGTmFwMADBRaeKVvO0wdYA8bY12RKySqmSYVkJoiBiQiaonyikpwMDgeW87fRUx66eS7MqkEL3azxBuDHeBqayxugURPwICkYQxIRNSSqVQCTkWm4se/YnDxzn11u5udCV4f1B4vdLGAlqzJvShNLQADkoYxIBERlbqZmInN52JwNCwRxcrSXyltTXQxbYA9JvaxhYFCW+QKif7FgKRhDEhEROWlZhVg+6V72HHpHh7mlY5T0tfRwsQ+tpg2wB62rVuJXCERA5LGMSAREVUtv0iJQyEJ2HzuDqLTSscpSSXA8G6WeH1Qe/RqZ1LtyzREmsaApGEMSEREj6dSCThzOw1bzsXgr9vp6nYXW2O8Pqg9XuxmCW2OU6IGxoCkYQxIREQ1F5GchS3nYnA4JBFFShUAwNpIgakD7DGpbzsY6XKcEjUMBiQNY0AiIqq9tOxC7PhnnNL93CIAQCu5DBN622L6QHvYtdETuUJq7hiQNIwBiYio7gqKlfglNAGbz8Xg75QcAIBEAjzf2QKvD2qPvu1bc5wSaQQDkoYxIBERPT1BEHAuKh0//hWDM3+nqdu72xhh9cvd0c3GSMTqqDliQNIwBiQiovp1OyUbW87fhd/VeBSWqGCkq43dM/uhizX/jaX6U9Pf33x9gIiIGgUnCwOsfrk7Lix+Fr3aGSMzvxhTNgfidkq22KVRC8SAREREjUobfR1sm9EXPdoa4UFuESb/GIg7aTlil0UtDAMSERE1OoYKbfw8oy+cLQ2Qll2IV38MRNyDPLHLohaEAYmIiBol41Zy7HzDHR3M9ZGUWYBXfriExIx8scuiFoIBiYiIGq02+jrY9YY77Nu0QvzDfEz+4RJSswrELotaAAYkIiJq1MwNFdg1sx/amuji7v08TP4xEOk5hWKXRc0cAxIRETV61sa62D2zH6yMFIhKzcGUHwORkVckdlnUjDEgERFRk2DbuhV2vuEOMwMdRCRn47XNQcgqKBa7LGqmGJCIiKjJcDDTx6433NFaT47rCZmYtiUIOYUlYpdFzRADEhERNSlOFgbY8bo7jHS1cTU2AzO2XUZ+kVLssqiZYUAiIqImp4u1Iba/3hcGOloIinmAmT9fQUExQxLVHwYkIiJqknq0Nca2GX3QSi7Duah0zN15FUUlKrHLomaCAYmIiJosN7vW2DKtDxTaUvwZkYq3dl9FsZIhiZ4eAxIRETVp/Rza4Aef3pBrSfH7zRQs2BcGpUoQuyxq4hiQiIioyRvsZIZvX+0FLakER8MSsfDANagYkugpMCAREVGz8FxnC6x/pSdkUgkOXo3Hsl9uQBAYkqhuGJCIiKjZeLG7FdZOcIFEAuwKjMXKY+EMSVQnDEhERNSsjHa1wRrvHgCArefv4rMTkQxJVGsMSERE1OyM722Lj8d0AwB8dyYaXwXcFrkiamoYkIiIqFma0s8OH7zUBQCw7uRtfHM6SuSKqClhQCIiombr9UHtsWi4MwBgzYlIbD4XI3JF1FQwIBERUbM2Z6gj5j/nBABYdSwcOy7dE7kiagoYkIiIqNl728MJs59xBAAsO3wD+67EiVwRNXYMSERE1OxJJBIsGt4J0wfaAwAWHbyGX0ITxC2KGjUGJCIiahEkEgk+fKkLXnVvB0EAFuwLw2/Xk8QuixopBiQiImoxJBIJVo3uhnFubaFUCXhrdwgCbqWIXRY1QgxIRETUokilEnzm3QNeLtYoUQmYs+Mqzv6dJnZZ1MgwIBERUYsjk0qwdoILhne1RJFShVnbr+Bi9H2xy6JGhAGJiIhaJG2ZFF+/0hPPOpujoFiF13+6jOB7D8QuixoJBiQiImqx5FpSfPNqLwx2MkVekRLTtlzGtfgMscuiRoABiYiIWjSFtgzfv9Ybfdu3RnZhCV7bHITwxCyxyyKRMSAREVGLpyuXYcu0PujVzhiZ+cWYsjkQt1OyxS6LRMSAREREBEBfRwvbZvRFdxsjPMgtwuQfA3EnLUfsskgkDEhERET/MFRo4+cZfeFsaYC07EK8+mMg4h7kiV0WiYABiYiI6BEmenLseMMdHcz1kZRZgFd+uITEjHyxy6IGxoBERERUgam+Dna94Q77Nq0Q/zAfk3+4hNSsArHLogbEgERERFQFc0MFds3sh7Ymurh7Pw+TfwxEek6h2GVRA6lTQDp16lR910FERNToWBvrYvfMfrAyUiAqNQdTfgxERl6R2GVRA6hTQBo+fDgcHR3x8ccfIy4urr5rIiIiajRsW7fCzjfcYWagg4jkbLy2OQhZBcVil0UaVqeAlJCQAF9fXxw4cAAODg7w9PTEvn37UFTEVE1ERM2Pg5k+dr3hjtZ6clxPyMS0LUHIKSwRuyzSoDoFJFNTU7zzzjsIDQ1FYGAgOnbsiLlz58La2hr/+c9/EBYWVt91EhERicrJwgA7XneHka42rsZmYMa2y8gvUopdFmnIUw/S7tWrF5YsWQJfX1/k5ORgy5YtcHNzw+DBg3Hz5s36qJGIiKhR6GJtiJ9n9IWBjhaCYh5g1vYrKChmSGqO6hyQiouLceDAAYwYMQJ2dnb4/fffsWHDBqSkpCAqKgp2dnYYP358fdZKREQkOhdbY2yb0Qet5DL8dTsdc3deRVGJSuyyqJ5JBEEQarvTW2+9hd27d0MQBLz22mt444030K1bt3LbJCcnw9raGipV8/xLk5WVBSMjI2RmZsLQ0FDscoiIqIFdunMf07YGoaBYBc+uFtgwuRe0ZZw9p7Gr6e/vOv1JhoeHY/369UhMTMS6desqhSOgdJwSpwMgIqLmqp9DG3z/Wm/IZVL8fjMFC/aFQamq9T0HaqTqdAeJeAeJiIhKBdxKwZvbg1GiEjDOrS3WePeAVCoRuyyqhkbvIK1evRpbtmyp1L5lyxZ89tlndTkkERFRk/RcZwusf6UnZFIJDgTHY9kvN8B7D01fnQLSpk2b4OzsXKm9a9eu+O677566KCIioqbkxe5WWDvBBRIJsCswFiuPhTMkNXF1CkjJycmwsrKq1G5mZoakpKSnLoqIiKipGe1qg8+8ewAAtp6/i89ORDIkNWF1Cki2trY4f/58pfbz58/D2tr6qYsiIiJqiib0tsXHY0pfXPruTDS+CrgtckVUV1p12WnmzJl4++23UVxcjGeffRYAEBAQgIULF+Ldd9+t1wKJiIiakin97FBYosKqY+FYd/I25FpSzB3aQeyyqJbqFJDef/993L9/H3PnzlWvv6ZQKLBo0SIsWbKkXgskIiJqal4f1B6FJUqsORGJNScioaMlw+uD2otdFtXCU73mn5OTg1u3bkFXVxdOTk7Q0dGpz9oaNb7mT0RET/Kl/9/qx2wfj+mGKf3sRK6Iavr7u053kMro6+ujT58+T3MIIiKiZuttDycUlqjw3ZloLDt8A3ItKSb0thW7LKqBOgekK1euYN++fYiNjVU/Zivj5+f31IURERE1dRKJBIuGd0JhiRJbz9/FooPXoKMlxWhXG7FLoyeo01tse/bswYABA3Dr1i0cOnQIxcXFuHnzJv78808YGRnVd41ERERNlkQiwYcvdcFk93YQBGDBvjD8dp1T4jR2dQpIn3zyCb788kscPXoUcrkcX331FSIiIjBhwgS0a9euvmskIiJq0iQSCT4e3Q3j3NpCqRLw1u4QBNxKEbsseow6BaTo6GiMHDkSACCXy5GbmwuJRIJ33nkH33//fb0WSERE1BxIpRJ85t0DXi7WKFEJmLPjKs7+nSZ2WVSNOgUkExMTZGdnAwBsbGxw48YNAEBGRgby8vJqdayNGzfC3t4eCoUC7u7uCAoKqnbb4uJirFy5Eo6OjlAoFHBxccGJEyfKbXP27Fl4eXnB2toaEokEhw8frnScadOmQSKRlPsMHz68VnUTERHVlkwqwdoJLvDsaoEipQqztl/Bxej7YpdFVahTQBoyZAj8/f0BAOPHj8f8+fMxc+ZMvPLKK3juuedqfJy9e/diwYIFWL58Oa5evQoXFxd4enoiNTW1yu2XLVuGTZs2Yf369QgPD8fs2bMxduxYhISEqLfJzc2Fi4sLNm7c+NhzDx8+HElJSerP7t27a1w3ERFRXWnLpFj/Si8862yOgmIVXv/pMoLvPRC7LKqgTvMgPXjwAAUFBbC2toZKpcKaNWtw4cIFODk5YdmyZTAxManRcdzd3dGnTx9s2LABAKBSqWBra4u33noLixcvrrS9tbU1li5dinnz5qnbvL29oaurix07dlTunESCQ4cOYcyYMeXap02bhoyMjCrvLtUU50EiIqKnUVCsxBs/XcG5qHQY6Ghh50x39GhrLHZZzV5Nf3/X+g5SSUkJjh07BplMVnoAqRSLFy/GkSNH8MUXX9Q4HBUVFSE4OBgeHh7/FiOVwsPDAxcvXqxyn8LCQigUinJturq6OHfuXG27gdOnT8Pc3BydOnXCnDlzcP8+b3ESEVHDUWjL8INPb/Rt3xrZhSV4bXMQwhOzxC6L/lHrgKSlpYXZs2ejoKDgqU6cnp4OpVIJCwuLcu0WFhZITk6uch9PT0+sXbsWt2/fhkqlgr+/P/z8/JCUVLvXJYcPH46ff/4ZAQEB+Oyzz3DmzBm8+OKLUCqV1e5TWFiIrKysch8iIqKnoSuXYcu0PujVzhiZ+cWYsjkQt1OyxS6LUMcxSH379kVoaGg9l/JkX331FZycnODs7Ay5XA5fX19Mnz4dUmntujFp0iSMGjUK3bt3x5gxY3Ds2DFcvnwZp0+frnaf1atXw8jISP2xteVMqERE9PT0dbSwdXpfdLcxwoPcIkz+MRAx6blil9Xi1SkgzZ07FwsWLMCGDRtw8eJFXLt2rdynJkxNTSGTyZCSUn4eiJSUFFhaWla5j5mZGQ4fPozc3Fzcu3cPERER0NfXh4ODQ126oebg4ABTU1NERUVVu82SJUuQmZmp/sTFxT3VOYmIiMoY6Wrj5xl94WxpgLTsQkz+4RLiHtTurXCqX3VaamTSpEkAgP/85z/qNolEAkEQIJFIHvuoqoxcLoebmxsCAgLUg6hVKhUCAgLg6+v72H0VCgVsbGxQXFyMgwcPYsKECXXphlp8fDzu378PKyurarfR0dFpUYvxEhFRwzLRk2PHG+6Y9P0lRKXmYOrWIPi/8wxkUonYpbVIdQpIMTEx9XLyBQsWYOrUqejduzf69u2LdevWITc3F9OnTwcA+Pj4wMbGBqtXrwYABAYGIiEhAa6urkhISMCKFSugUqmwcOFC9TFzcnLK3QmKiYlBaGgoWrdujXbt2iEnJwcfffQRvL29YWlpiejoaCxcuBAdOnSAp6dnvfSLiIioLkz1dbDrDXc8/+VZ3EnLxbmodDzT0UzsslqkOgUkOzu7ejn5xIkTkZaWhg8//BDJyclwdXXFiRMn1AO3Y2Njy40vKigowLJly3Dnzh3o6+tjxIgR2L59O4yNjdXbXLlyBcOGDVP/vGDBAgDA1KlTsW3bNshkMly7dg0//fQTMjIyYG1tjRdeeAGrVq3iHSIiIhKduaECY3vaYNuFu9h3JY4BSSR1mgfp559/fuz3Pj4+dS6oqeA8SEREpCk3EzMx8utzkMukCPzvczDRk4tdUrNR09/fdbqDNH/+/HI/FxcXIy8vD3K5HK1atWoRAYmIiEhTuloboau1IW4mZuGX0ARMG9he7JJanDq9xfbw4cNyn5ycHERGRmLQoEFcsoOIiKgeTOhdOp3MvivxIlfSMtUpIFXFyckJn376aaW7S0RERFR7o12tIdeSIjwpCzcSMsUup8Wpt4AElM6ynZiYWJ+HJCIiapGMW8nh2bV0XsB9Vzj3XkOr0xikI0eOlPtZEAQkJSVhw4YNGDhwYL0URkRE1NJN6N0WR8MScTgkAf8d0RkKbZnYJbUYdQpIZRM7lpFIJDAzM8Ozzz6LL774oj7qIiIiavEGOJrCxlgXCRn5+CM8BaNcrMUuqcWoU0BSqVT1XQcRERFVIJNK4O3WFl8H3Mb+K3EMSA2oXscgERERUf0a79YWAHAuKh3xD7k+W0OpU0Dy9vbGZ599Vql9zZo1GD9+/FMXRURERKVsW7fCwA5tIAjAweAEsctpMeoUkM6ePYsRI0ZUan/xxRdx9uzZpy6KiIiI/lU2J9L+4DioVLVeAIPqoE4BKScnB3J55WnPtbW1kZWV9dRFERER0b88u1rCQKGF+If5uHjnvtjltAh1Ckjdu3fH3r17K7Xv2bMHXbp0eeqiiIiI6F8KbRlGu5YO0OacSA2jTm+xffDBB3j55ZcRHR2NZ599FgAQEBCA3bt3Y//+/fVaIBEREZU+ZttxKRa/3UjGyrxiGLXSFrukZq1Od5C8vLxw+PBhREVFYe7cuXj33XcRHx+PkydPVpojiYiIiJ5edxsjOFsaoKhEhSPXuGqFpkkEQeBorzrIysqCkZERMjMzYWhoKHY5RETUAmw+F4NVx8LRo60RjvgOErucJqmmv7/rdAfp8uXLCAwMrNQeGBiIK1eu1OWQRERE9ARje9pAWybBtfhM3EriS1GaVKeANG/ePMTFVR4klpCQgHnz5j11UURERFRZaz05nu9iAYCDtTWtTgEpPDwcvXr1qtTes2dPhIeHP3VRREREVLXx/8yJdDgkAYUlSpGrab7qFJB0dHSQkpJSqT0pKQlaWnV6MY6IiIhqYIiTGSwNFXiYV4yAW6lil9Ns1SkgvfDCC1iyZAkyMzPVbRkZGfjvf/+L559/vt6KIyIiovJKF7C1AcDHbJpUp4D0+eefIy4uDnZ2dhg2bBiGDRuG9u3bIzk5GV988UV910hERESPGO9W+pjt7N9pSMrMF7ma5qlOAcnGxgbXrl3DmjVr0KVLF7i5ueGrr77C9evXYWtrW981EhER0SPsTfXg3r41VAJwMDhe7HKapToPGNLT08OgQYPQrl07FBUVAQB+++03AMCoUaPqpzoiIiKq0oTetgiMeYB9V+Ixd2gHSKUSsUtqVuoUkO7cuYOxY8fi+vXrkEgkEAQBEsm/fzBKJUfVExERadKL3S2x/MhNxD7IQ9DdB+jn0EbskpqVOj1imz9/Ptq3b4/U1FS0atUKN27cwJkzZ9C7d2+cPn26nkskIiKiilrJteDlYgWAg7U1oU4B6eLFi1i5ciVMTU0hlUohk8kwaNAgrF69Gv/5z3/qu0YiIiKqQtmcSL9eT0J2QbHI1TQvdQpISqUSBgYGAABTU1MkJpYummdnZ4fIyMj6q46IiIiq1dPWGB3M9VFQrMKxa0lil9Os1CkgdevWDWFhYQAAd3d3rFmzBufPn8fKlSvh4OBQrwUSERFR1SQSCSb0bguAj9nqW50C0rJly6BSqQAAK1euRExMDAYPHoxff/0VX3/9db0WSERERNUb27MttKQShMRm4HZKttjlNBt1eovN09NT/b87dOiAiIgIPHjwACYmJuXeZiMiIiLNMjPQwbPO5vgjPAX7rsRh6cguYpfULNTpDlJVWrduzXBEREQkggn/DNb2u5qAYqVK5Gqah3oLSERERCSOoZ3MYGagg/u5RfgzggvY1gcGJCIioiZOSybFy71KF7Ddz8Ha9YIBiYiIqBkoW8D2VGQaUrMKRK6m6WNAIiIiagY6mOujt50JlCoBB68miF1Ok8eARERE1EyUDdbefyUOgiCIXE3TxoBERETUTIzoYYVWchnupOci+N5Dsctp0hiQiIiImgl9HS2M7M4FbOsDAxIREVEzMqFP6WO2Y9eSkFtYInI1TRcDEhERUTPS284E7U31kFekxPHrXMC2rhiQiIiImhGJRILxZQvYXuZjtrpiQCIiImpmxvVqC5lUgiv3HiI6LUfscpokBiQiIqJmxtxQgaEdzQAA+6/Ei1xN08SARERE1AyN/2dOpINX41HCBWxrjQGJiIioGXrW2Rxt9ORIyy7Emb/TxC6nyWFAIiIiaobkWlKM7Vm6gC3nRKo9BiQiIqJmqmxOpIBbqUjPKRS5mqaFAYmIiKiZ6mhhAFdbY5SoBBziAra1woBERETUjJUtYLuPC9jWCgMSERFRM/aSixUU2lLcTs1BaFyG2OU0GQxIREREzZihQhsjupUtYMs5kWqKAYmIiKiZK5sT6WhYIvKLlCJX0zQwIBERETVz7u1bo13rVsgpLMFvN7iAbU0wIBERETVzUqkEE/5ZwHYvF7CtEQYkIiKiFsDbrS0kEiAw5gHupueKXU6jx4BERETUAlgZ6WKIU+kCtgeCOVj7SRiQiIiIWoiyOZEOBMdDqeKcSI/DgERERNRCeHQxh3ErbSRnFeCv21zA9nEYkIiIiFoIHS0ZxriWLmC7n3MiPRYDEhERUQtS9pjtj/BkPMgtErmaxosBiYiIqAXpYm2I7jZGKFYKOBzCBWyrw4BERETUwpTNicQFbKvHgERERNTCjHKxgVxLiojkbNxIyBK7nEaJAYmIiKiFMWqljeFdLQGU3kWiyhiQiIiIWqCywdq/hCagoJgL2FbEgERERNQCDXBsAxtjXWQVlOD3m8lil9PoMCARERG1QFKpBOMfGaxN5TEgERERtVDj/lnA9nzUfcQ9yBO7nEaFAYmIiKiFamvSCgMdTQFwAduKRA9IGzduhL29PRQKBdzd3REUFFTttsXFxVi5ciUcHR2hUCjg4uKCEydOlNvm7Nmz8PLygrW1NSQSCQ4fPlzpOIIg4MMPP4SVlRV0dXXh4eGB27dv13fXiIiIGr2yx2wHguOh4gK2aqIGpL1792LBggVYvnw5rl69ChcXF3h6eiI1NbXK7ZctW4ZNmzZh/fr1CA8Px+zZszF27FiEhISot8nNzYWLiws2btxY7XnXrFmDr7/+Gt999x0CAwOhp6cHT09PFBQU1HsfiYiIGjPPrpYwVGghISMfF6Lvi11OoyERRJxC093dHX369MGGDRsAACqVCra2tnjrrbewePHiSttbW1tj6dKlmDdvnrrN29sburq62LFjR6XtJRIJDh06hDFjxqjbBEGAtbU13n33Xbz33nsAgMzMTFhYWGDbtm2YNGlSjWrPysqCkZERMjMzYWhoWJtuExERNSofHL6B7ZfuYZSLNb5+pafY5WhUTX9/i3YHqaioCMHBwfDw8Pi3GKkUHh4euHjxYpX7FBYWQqFQlGvT1dXFuXPnanzemJgYJCcnlzuvkZER3N3dqz1v2bmzsrLKfYiIiJqDsjmRTtxMRmZescjVNA6iBaT09HQolUpYWFiUa7ewsEByctXzMXh6emLt2rW4ffs2VCoV/P394efnh6SkpBqft+zYtTkvAKxevRpGRkbqj62tbY3PSURE1Jh1szFEZytDFJWo8EsYF7AFGsEg7dr46quv4OTkBGdnZ8jlcvj6+mL69OmQSjXfjSVLliAzM1P9iYvjnBFERNQ8SCSScgvYkogBydTUFDKZDCkpKeXaU1JSYGlpWeU+ZmZmOHz4MHJzc3Hv3j1ERERAX18fDg4ONT5v2bFrc14A0NHRgaGhYbkPERFRczHG1QZymRQ3ErJwMzFT7HJEJ1pAksvlcHNzQ0BAgLpNpVIhICAA/fv3f+y+CoUCNjY2KCkpwcGDBzF69Ogan7d9+/awtLQsd96srCwEBgY+8bxERETNlYmeHM93KR1+sv8K50QS9RHbggUL8MMPP+Cnn37CrVu3MGfOHOTm5mL69OkAAB8fHyxZskS9fWBgIPz8/HDnzh389ddfGD58OFQqFRYuXKjeJicnB6GhoQgNDQVQOig7NDQUsbGxAEpvI7799tv4+OOPceTIEVy/fh0+Pj6wtrYu97YbERFRS1M2J9Lh0AQUlrTsBWy1xDz5xIkTkZaWhg8//BDJyclwdXXFiRMn1AOoY2Njy40vKigowLJly3Dnzh3o6+tjxIgR2L59O4yNjdXbXLlyBcOGDVP/vGDBAgDA1KlTsW3bNgDAwoULkZubi1mzZiEjIwODBg3CiRMnKr0hR0RE1JIMdjKDlZECSZkF8A9PwUs9rMUuSTSizoPUlHEeJCIiao6++CMS6/+MwpCOZvh5Rl+xy6l3jX4eJCIiImp8xrmVPmb763YaEjPyRa5GPAxIREREpGbXRg/9HFpDEICDLXgBWwYkIiIiKqdsZu39LXgBWwYkIiIiKufFblbQ19FC7IM8BMY8ELscUTAgERERUTm6chm8XErfYNvfQmfWZkAiIiKiSsqWHvn1RhKyClreArYMSERERFSJq60xOlroo6BYhaNhiWKX0+AYkIiIiKiS0gVsSwdr72uBS48wIBEREVGVxvS0gZZUgrC4DEQmZ4tdToNiQCIiIqIqmerr4LnO5gBa3mBtBiQiIiKqVtljtkMhCSgqUYlcTcNhQCIiIqJqPdPRDOYGOrifW4Q/I1LELqfBMCARERFRtbRkUnj/sz5bSxqszYBEREREjzX+n4B0OjIVKVkFIlfTMBiQiIiI6LEczPTRx94EKgE4eLVl3EViQCIiIqInGl+2gO2VeAhC81/AlgGJiIiInmhkdyu0kssQk56LK/ceil2OxjEgERER0RPp6WjhpR5WAIC9l5v/nEgMSERERFQjZXMiHb+WhJzCEpGr0SwGJCIiIqoRNzsTOJjpIb9YiePXmvcCtgxIREREVCMtaQFbBiQiIiKqsZd72kAmlSD43kNEpeaIXY7GMCARERFRjZkbKjCskxkAYH9w8x2szYBEREREtVI2J9LB4AQUK5vnArYMSERERFQrzzqbw1RfjvScQpyOTBO7HI1gQCIiIqJa0ZZJ8XKvsgVsm+djNgYkIiIiqrWyBWz/jEhFanbzW8CWAYmIiIhqzcnCAD3bGUOpEnA4JEHscuodAxIRERHVyaNzIjW3BWwZkIiIiKhOXuphBYW2FFGpOQiJyxC7nHrFgERERER1YqDQxojupQvY7mtmC9gyIBEREVGdTfznMdvRsETkFTWfBWwZkIiIiKjO+rZvDfs2rZBbpMSv15PFLqfeMCARERFRnUkkEvXM2s1pTiQGJCIiInoqL/eygVQCBMU8QEx6rtjl1AsGJCIiInoqVka6GNKxdAHbA81kAVsGJCIiInpqZXMiHQiOR0kzWMCWAYmIiIie2nOdzWHSShspWYX463a62OU8NQYkIiIiemo6WjKM7dl8FrBlQCIiIqJ6MaFPaUA6eSsF93MKRa7m6TAgERERUb1wtjREj7ZGKFYKOByaKHY5T4UBiYiIiOpN2ZxI+6/ENekFbBmQiIiIqN6McrGGjpYUEcnZuJ6QKXY5dcaARERERPXGSFcbw7tZAgD2NuEFbBmQiIiIqF6VLWB7JDQR+UVKkaupGwYkIiIiqlf9HNqgrYkusgtL8PvNprmALQMSERER1SupVILxbk17AVsGJCIiIqp33m42kEiAC9H3EfcgT+xyao0BiYiIiOpdW5NWGNTBFACwPzhe5GpqjwGJiIiINKJsTqQDV+KgVDWtOZEYkIiIiEgjXuhiASNdbSRmFuB8VNNawJYBiYiIiDRCoS3DGFdrAE1vsDYDEhEREWlM2WO2P26mICOvSORqao4BiYiIiDSmm40RulgZokipwi9NaAFbBiQiIiLSqAm92wJoWo/ZGJCIiIhIo0a72kAuk+JmYhZuNJEFbBmQiIiISKNM9OR4vqsFAGB/E7mLxIBEREREGle2gO3h0EQUFDf+BWwZkIiIiEjjBnYwhbWRApn5xfAPTxG7nCdiQCIiIiKNk0klGOfWdAZrMyARERFRgxjnVvqY7VxUOhIy8kWu5vEYkIiIiKhBtGvTCv0d2kAQgIONfAFbBiQiIiJqMBP6/PuYTdWIF7BlQCIiIqIGM7yrFQx0tBD/MB+X7twXu5xqMSARERFRg9GVyzCqCSxgy4BEREREDWrCP3Mi/XYjGZn5xSJXUzUGJCIiImpQPdoaoZOFAQpLVDga1jgXsGVAIiIiogYlkUgw/p8FbBvr0iONIiBt3LgR9vb2UCgUcHd3R1BQULXbFhcXY+XKlXB0dIRCoYCLiwtOnDhR62MOHToUEomk3Gf27Nn13jciIiKqbGxPG2hJJQiLz0REcpbY5VQiekDau3cvFixYgOXLl+Pq1atwcXGBp6cnUlNTq9x+2bJl2LRpE9avX4/w8HDMnj0bY8eORUhISK2POXPmTCQlJak/a9as0WhfiYiIqFQbfR14dC5dwHbf5cY3J5JEEARRJyFwd3dHnz59sGHDBgCASqWCra0t3nrrLSxevLjS9tbW1li6dCnmzZunbvP29oauri527NhR42MOHToUrq6uWLduXZ3qzsrKgpGRETIzM2FoaFinYxAREbVkpyJSMX3bZZi00kbgfz0g19L8fZua/v4W9Q5SUVERgoOD4eHhoW6TSqXw8PDAxYsXq9ynsLAQCoWiXJuuri7OnTtX62Pu3LkTpqam6NatG5YsWYK8vLxqay0sLERWVla5DxEREdXdYCdTWBjq4GFeMQJuNa4FbEUNSOnp6VAqlbCwsCjXbmFhgeTk5Cr38fT0xNq1a3H79m2oVCr4+/vDz88PSUlJtTrm5MmTsWPHDpw6dQpLlizB9u3bMWXKlGprXb16NYyMjNQfW1vbunabiIiIAGjJpPDu1TgXsBV9DFJtffXVV3BycoKzszPkcjl8fX0xffp0SKW168qsWbPg6emJ7t2749VXX8XPP/+MQ4cOITo6usrtlyxZgszMTPUnLq5x/UESERE1ReP/mRPpzN9pSM4sELmaf4kakExNTSGTyZCSUv62WkpKCiwtLavcx8zMDIcPH0Zubi7u3buHiIgI6Ovrw8HBoc7HBErHLQFAVFRUld/r6OjA0NCw3IeIiIieTntTPfS1bw2VABy82ngGa4sakORyOdzc3BAQEKBuU6lUCAgIQP/+/R+7r0KhgI2NDUpKSnDw4EGMHj36qY4ZGhoKALCysnqKHhEREVFtlc2JtO9KHER+d0xN9EdsCxYswA8//ICffvoJt27dwpw5c5Cbm4vp06cDAHx8fLBkyRL19oGBgfDz88OdO3fw119/Yfjw4VCpVFi4cGGNjxkdHY1Vq1YhODgYd+/exZEjR+Dj44MhQ4agR48eDXsBiIiIWrgR3a2gJ5fh3v08BMU8ELscAICW2AVMnDgRaWlp+PDDD5GcnAxXV1ecOHFCPcg6Nja23PiigoICLFu2DHfu3IG+vj5GjBiB7du3w9jYuMbHlMvlOHnyJNatW4fc3FzY2trC29sby5Yta9C+ExEREaCnowUvF2vsuRyHfVfi4e7QRuySxJ8HqaniPEhERET1J/jeQ3h/ewG62jIELX0OBgptjZynScyDRERERAQAvdoZw9FMD/nFShy/liR2OQxIREREJD6JRIIJ/7zy3xjmRGJAIiIiokZhbC8byKQSXI3NQFRqtqi1MCARERFRo2BuoMCwTuYAgH1XxJ0TiQGJiIiIGo2JfUofs/ldjUexUiVaHQxIRERE1GgM7WQGU30dpOcU4VREqmh1MCARERFRo6Etk8K7lw30dbSQkl0oWh2cB6mOOA8SERGRZmTkFUGuJUUref3PZ13T39+iz6RNRERE9CjjVnKxS+AjNiIiIqKKGJCIiIiIKmBAIiIiIqqAAYmIiIioAgYkIiIiogoYkIiIiIgqYEAiIiIiqoABiYiIiKgCBiQiIiKiChiQiIiIiCpgQCIiIiKqgAGJiIiIqAIGJCIiIqIKtMQuoKkSBAEAkJWVJXIlREREVFNlv7fLfo9XhwGpjrKzswEAtra2IldCREREtZWdnQ0jI6Nqv5cIT4pQVCWVSoXExEQYGBhAIpHU23GzsrJga2uLuLg4GBoa1ttxm5KWfg1aev8BXoOW3n+A14D911z/BUFAdnY2rK2tIZVWP9KId5DqSCqVom3btho7vqGhYYv8j+JRLf0atPT+A7wGLb3/AK8B+6+Z/j/uzlEZDtImIiIiqoABiYiIiKgCBqRGRkdHB8uXL4eOjo7YpYimpV+Dlt5/gNegpfcf4DVg/8XvPwdpExEREVXAO0hEREREFTAgEREREVXAgERERERUAQMSERERUQUMSCLYuHEj7O3toVAo4O7ujqCgoMduv3//fjg7O0OhUKB79+749ddfG6hSzanNNbh58ya8vb1hb28PiUSCdevWNVyhGlKb/v/www8YPHgwTExMYGJiAg8Pjyf+nWkKanMN/Pz80Lt3bxgbG0NPTw+urq7Yvn17A1Zb/2r770CZPXv2QCKRYMyYMZotUMNq0/9t27ZBIpGU+ygUigasVjNq+3cgIyMD8+bNg5WVFXR0dNCxY8cm/fugNv0fOnRopb8DEokEI0eO1FyBAjWoPXv2CHK5XNiyZYtw8+ZNYebMmYKxsbGQkpJS5fbnz58XZDKZsGbNGiE8PFxYtmyZoK2tLVy/fr2BK68/tb0GQUFBwnvvvSfs3r1bsLS0FL788suGLbie1bb/kydPFjZu3CiEhIQIt27dEqZNmyYYGRkJ8fHxDVx5/antNTh16pTg5+cnhIeHC1FRUcK6desEmUwmnDhxooErrx+17X+ZmJgYwcbGRhg8eLAwevTohilWA2rb/61btwqGhoZCUlKS+pOcnNzAVdev2l6DwsJCoXfv3sKIESOEc+fOCTExMcLp06eF0NDQBq68ftS2//fv3y/353/jxg1BJpMJW7du1ViNDEgNrG/fvsK8efPUPyuVSsHa2lpYvXp1ldtPmDBBGDlyZLk2d3d34c0339RonZpU22vwKDs7uyYfkJ6m/4IgCCUlJYKBgYHw008/aapEjXvaayAIgtCzZ09h2bJlmihP4+rS/5KSEmHAgAHCjz/+KEydOrVJB6Ta9n/r1q2CkZFRA1XXMGp7Db799lvBwcFBKCoqaqgSNepp/w348ssvBQMDAyEnJ0dTJQp8xNaAioqKEBwcDA8PD3WbVCqFh4cHLl68WOU+Fy9eLLc9AHh6ela7fWNXl2vQnNRH//Py8lBcXIzWrVtrqkyNetprIAgCAgICEBkZiSFDhmiyVI2oa/9XrlwJc3NzvP766w1RpsbUtf85OTmws7ODra0tRo8ejZs3bzZEuRpRl2tw5MgR9O/fH/PmzYOFhQW6deuGTz75BEqlsqHKrjf18e/g5s2bMWnSJOjp6WmqTI5Bakjp6elQKpWwsLAo125hYYHk5OQq90lOTq7V9o1dXa5Bc1If/V+0aBGsra0rBeemoq7XIDMzE/r6+pDL5Rg5ciTWr1+P559/XtPl1ru69P/cuXPYvHkzfvjhh4YoUaPq0v9OnTphy5Yt+OWXX7Bjxw6oVCoMGDAA8fHxDVFyvavLNbhz5w4OHDgApVKJX3/9FR988AG++OILfPzxxw1Rcr162n8Hg4KCcOPGDbzxxhuaKhEAoKXRoxNRvfr000+xZ88enD59ulkMUq0NAwMDhIaGIicnBwEBAViwYAEcHBwwdOhQsUvTqOzsbLz22mv44YcfYGpqKnY5oujfvz/69++v/nnAgAHo3LkzNm3ahFWrVolYWcNRqVQwNzfH999/D5lMBjc3NyQkJOD//u//sHz5crHLa1CbN29G9+7d0bdvX42ehwGpAZmamkImkyElJaVce0pKCiwtLavcx9LSslbbN3Z1uQbNydP0//PPP8enn36KkydPokePHposU6Pqeg2kUik6dOgAAHB1dcWtW7ewevXqJheQatv/6Oho3L17F15eXuo2lUoFANDS0kJkZCQcHR01W3Q9qo9/A7S1tdGzZ09ERUVpokSNq8s1sLKygra2NmQymbqtc+fOSE5ORlFREeRyuUZrrk9P83cgNzcXe/bswcqVKzVZIgA+YmtQcrkcbm5uCAgIULepVCoEBASU+39Hj+rfv3+57QHA39+/2u0bu7pcg+akrv1fs2YNVq1ahRMnTqB3794NUarG1NffAZVKhcLCQk2UqFG17b+zszOuX7+O0NBQ9WfUqFEYNmwYQkNDYWtr25DlP7X6+PNXKpW4fv06rKysNFWmRtXlGgwcOBBRUVHqcAwAf//9N6ysrJpUOAKe7u/A/v37UVhYiClTpmi6TL7m39D27Nkj6OjoCNu2bRPCw8OFWbNmCcbGxupXVl977TVh8eLF6u3Pnz8vaGlpCZ9//rlw69YtYfny5c3iNf/aXIPCwkIhJCRECAkJEaysrIT33ntPCAkJEW7fvi1WF55Kbfv/6aefCnK5XDhw4EC511yzs7PF6sJTq+01+OSTT4Q//vhDiI6OFsLDw4XPP/9c0NLSEn744QexuvBUatv/ipr6W2y17f9HH30k/P7770J0dLQQHBwsTJo0SVAoFMLNmzfF6sJTq+01iI2NFQwMDARfX18hMjJSOHbsmGBubi58/PHHYnXhqdT1v4FBgwYJEydObJAaGZBEsH79eqFdu3aCXC4X+vbtK1y6dEn93TPPPCNMnTq13Pb79u0TOnbsKMjlcqFr167C8ePHG7ji+lebaxATEyMAqPR55plnGr7welKb/tvZ2VXZ/+XLlzd84fWoNtdg6dKlQocOHQSFQiGYmJgI/fv3F/bs2SNC1fWntv8OPKqpByRBqF3/3377bfW2FhYWwogRI4SrV6+KUHX9qu3fgQsXLgju7u6Cjo6O4ODgIPzvf/8TSkpKGrjq+lPb/kdERAgAhD/++KNB6pMIgiBo/j4VERERUdPBMUhEREREFTAgEREREVXAgERERERUAQMSERERUQUMSEREREQVMCARERERVcCARERERFQBAxIRNQrTpk3DmDFjxC6DiAgAwIkiiahRyMzMhCAIMDY2FruURk0ikeDQoUMMk0QapiV2AUTUdNXnKuJGRkb1chwxKJVKSCQSSKW8KU/UXPC/ZiICAAwdOhS+vr7w9fWFkZERTE1N8cEHH+DRm8z29vZYtWoVfHx8YGhoiFmzZuH06dOQSCTIyMhQbxcaGgqJRIK7d+8CALZt2wZjY2P8/vvv6Ny5M/T19TF8+HAkJSWp96n4iG3o0KH4z3/+g4ULF6J169awtLTEihUrytUcERGBQYMGQaFQoEuXLjh58iQkEgkOHz78VP0sLCzEe++9BxsbG+jp6cHd3R2nT59Wf1/WnyNHjqBLly7Q0dFBbGwsCgsLsWjRItja2kJHRwcdOnTA5s2b1fvduHEDL774IvT19WFhYYHXXnsN6enpNe6zvb09AGDs2LGQSCTqn6OjozF69GhYWFhAX18fffr0wcmTJ8v1OykpCSNHjoSuri7at2+PXbt2wd7eHuvWrVNvk5GRgTfeeANmZmYwNDTEs88+i7CwsGqvJVFzxoBERGo//fQTtLS0EBQUhK+++gpr167Fjz/+WG6bzz//HC4uLggJCcEHH3xQ42Pn5eXh888/x/bt23H27FnExsbivffee2I9enp6CAwMxJo1a7By5Ur4+/sDKL1rM2bMGLRq1QqBgYH4/vvvsXTp0nrpp6+vLy5evIg9e/bg2rVrGD9+PIYPH47bt2+X689nn32GH3/8ETdv3oS5uTl8fHywe/dufP3117h16xY2bdoEfX19AKXh49lnn0XPnj1x5coVnDhxAikpKZgwYUKN+3z58mUAwNatW5GUlKT+OScnByNGjEBAQABCQkIwfPhweHl5ITY2Vn1cHx8fJCYm4vTp0zh48CC+//57pKamljv3+PHjkZqait9++w3BwcHo1asXnnvuOTx48KBG15WoWWmQJXGJqNF75plnhM6dOwsqlUrdtmjRIqFz587qn+3s7IQxY8aU2+/UqVMCAOHhw4fqtpCQEAGAEBMTIwiCIGzdulUAIERFRam32bhxo2BhYaH+ueIK9c8884wwaNCgcufq06ePsGjRIkEQBOG3334TtLS0hKSkJPX3/v7+AgDh0KFDde7nvXv3BJlMJiQkJJTb77nnnhOWLFlSrj+hoaHq7yMjIwUAgr+/f5XnXbVqlfDCCy+Ua4uLixMACJGRkTXqsyAIT+xfma5duwrr168XBEEQbt26JQAQLl++rP7+9u3bAgDhyy+/FARBEP766y/B0NBQKCgoKHccR0dHYdOmTU88H1FzwzFIRKTWr18/SCQS9c/9+/fHF198AaVSCZlMBgDo3bt3nY7dqlUrODo6qn+2srKqdAejoh49epT7+dF9IiMjYWtrC0tLS/X3ffv2rVEtj+vn9evXoVQq0bFjx3L7FBYWok2bNuqf5XJ5ufpCQ0Mhk8nwzDPPVHnOsLAwnDp1Sn1H6VHR0dHq8z2uz9XJycnBihUrcPz4cSQlJaGkpAT5+fnqO0iRkZHQ0tJCr1691Pt06NABJiYm5erLyckp10cAyM/PR3R09GPPT9QcMSARUa3o6emV+7lsYLLwyBie4uLiSvtpa2uX+1kikZTbpypV7aNSqWpVb23l5ORAJpMhODhYHQrLPBpudHV1y4UsXV3dJx7Xy8sLn332WaXvrKys1P+7Ln1+77334O/vj88//xwdOnSArq4uxo0bh6KiosfuV7E+KyurcmOtyvDNQmqJGJCISC0wMLDcz5cuXYKTk1OloPAoMzMzAKWDgMvuSISGhmqsxjKdOnVCXFwcUlJSYGFhAeDfMTpP8rh+9uzZE0qlEqmpqRg8eHCN6+nevTtUKhXOnDkDDw+PSt/36tULBw8ehL29PbS06v5Pr7a2NpRKZbm28+fPY9q0aRg7diyA0rBTNkAeKL1WJSUlCAkJgZubGwAgKioKDx8+LFdfcnIytLS01IO/iVoyDtImIrXY2FgsWLAAkZGR2L17N9avX4/58+c/dp8OHTrA1tYWK1aswO3bt3H8+HF88cUXGq/1+eefh6OjI6ZOnYpr167h/PnzWLZsGQCUu7NTlcf1s2PHjnj11Vfh4+MDPz8/xMTEICgoCKtXr8bx48erPaa9vT2mTp2KGTNm4PDhw4iJicHp06exb98+AMC8efPw4MEDvPLKK7h8+TKio6Px+++/Y/r06ZUCz+PY29sjICAAycnJ6oDj5OQEPz8/hIaGIiwsDJMnTy5318nZ2RkeHh6YNWsWgoKCEBISglmzZpW7C+bh4YH+/ftjzJgx+OOPP3D37l1cuHABS5cuxZUrV2pcH1FzwYBERGo+Pj7Iz89H3759MW/ePMyfPx+zZs167D7a2trYvXs3IiIi0KNHD3z22Wf4+OOPNV6rTCbD4cOHkZOTgz59+uCNN95Qv8WmUCgeu++T+rl161b4+Pjg3XffRadOnTBmzBhcvnwZ7dq1e+xxv/32W4wbNw5z586Fs7MzZs6cidzcXACAtbU1zp8/D6VSiRdeeAHdu3fH22+/DWNj41rNn/TFF1/A398ftra26NmzJwBg7dq1MDExwYABA+Dl5QVPT89y440A4Oeff4aFhQWGDBmCsWPHYubMmTAwMFBfK4lEgl9//RVDhgzB9OnT0bFjR0yaNAn37t1T36Ejakk4kzYRASidg8fV1bXcvDhNzfnz5zFo0CBERUWVGxD+qObQz/oQHx8PW1tbnDx5Es8995zY5RA1OhyDRERN1qFDh6Cvrw8nJydERUVh/vz5GDhwYLXhqCX7888/kZOTg+7duyMpKQkLFy6Evb09hgwZInZpRI0SAxIRNVnZ2dlYtGgRYmNjYWpqCg8PjwYZ/9QUFRcX47///S/u3LkDAwMDDBgwADt37qz01hwRleIjNiIiIqIKOEibiIiIqAIGJCIiIqIKGJCIiIiIKmBAIiIiIqqAAYmIiIioAgYkIiIiogoYkIiIiIgqYEAiIiIiqoABiYiIiKiC/wdjTeRjp/Qo6wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "percent_arr = [0,0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "percent_accuracy_list = []\n",
    "percent_num_param_list = []\n",
    "percent_model_size_list = []\n",
    "percent_elapsed_time_list = []\n",
    "model_path = '/kaggle/working/model_best.pth.tar'\n",
    "save = 'pruned.pth.tar'\n",
    "\n",
    "for idx, percent in enumerate(percent_arr):\n",
    "    print('Iteration: ', idx, 'Percent: ', percent)\n",
    "    \n",
    "    depth = 164\n",
    "    model_path = '/kaggle/working/model_best.pth.tar'\n",
    "\n",
    "    model = resnet(depth=depth)\n",
    "\n",
    "    if cuda:\n",
    "        model.cuda()\n",
    "\n",
    "    if model_path:\n",
    "        if os.path.isfile(model_path):\n",
    "            print(\"=> loading checkpoint '{}'\".format(model_path))\n",
    "            checkpoint = torch.load(model_path)\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {}) Prec1: {:f}\"\n",
    "                  .format(model_path, checkpoint['epoch'], best_prec1))\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(resume))\n",
    "            \n",
    "    total = 0\n",
    "\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.BatchNorm2d):\n",
    "            total += m.weight.data.shape[0]\n",
    "\n",
    "    bn = torch.zeros(total)\n",
    "    index = 0\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.BatchNorm2d):\n",
    "            size = m.weight.data.shape[0]\n",
    "            bn[index:(index+size)] = m.weight.data.abs().clone()\n",
    "            index += size\n",
    "\n",
    "    y, i = torch.sort(bn)\n",
    "    thre_index = int(total * percent)\n",
    "    thre = y[thre_index]\n",
    "\n",
    "\n",
    "    pruned = 0\n",
    "    cfg = []\n",
    "    cfg_mask = []\n",
    "    for k, m in enumerate(model.modules()):\n",
    "        if isinstance(m, nn.BatchNorm2d):\n",
    "            weight_copy = m.weight.data.abs().clone()\n",
    "            mask = weight_copy.gt(thre).float().cuda()\n",
    "            pruned = pruned + mask.shape[0] - torch.sum(mask)\n",
    "            m.weight.data.mul_(mask)\n",
    "            m.bias.data.mul_(mask)\n",
    "            cfg.append(int(torch.sum(mask)))\n",
    "            cfg_mask.append(mask.clone())\n",
    "            print('layer index: {:d} \\t total channel: {:d} \\t remaining channel: {:d}'.\n",
    "                format(k, mask.shape[0], int(torch.sum(mask))))\n",
    "        elif isinstance(m, nn.MaxPool2d):\n",
    "            cfg.append('M')\n",
    "\n",
    "    pruned_ratio = pruned/total\n",
    "\n",
    "    print('Pre-processing Successful!')\n",
    "    \n",
    "    # simple test model after Pre-processing prune (simple set BN scales to zeros)\n",
    "    def test(model):\n",
    "        kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "        if dataset == 'cifar10':\n",
    "            test_loader = torch.utils.data.DataLoader(\n",
    "                datasets.CIFAR10('./data.cifar10', train=False, transform=transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])),\n",
    "                batch_size=test_batch_size, shuffle=False, **kwargs)\n",
    "        elif dataset == 'cifar100':\n",
    "            test_loader = torch.utils.data.DataLoader(\n",
    "                datasets.CIFAR100('./data.cifar100', train=False, transform=transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])),\n",
    "                batch_size=test_batch_size, shuffle=False, **kwargs)\n",
    "        else:\n",
    "            raise ValueError(\"No valid dataset is given.\")\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        for data, target in test_loader:\n",
    "            if cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            with torch.no_grad():\n",
    "                data, target = Variable(data), Variable(target)\n",
    "            output = model(data)\n",
    "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "        print('\\nTest set: Accuracy: {}/{} ({:.1f}%)\\n'.format(\n",
    "            correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n",
    "        return correct / float(len(test_loader.dataset))\n",
    "\n",
    "    acc = test(model)\n",
    "\n",
    "    print(\"Cfg:\")\n",
    "    print(cfg)\n",
    "    \n",
    "    save = ''\n",
    "    newmodel = resnet(depth=depth, cfg=cfg)\n",
    "    if cuda:\n",
    "        newmodel.cuda()\n",
    "\n",
    "    num_parameters = sum([param.nelement() for param in newmodel.parameters()])\n",
    "    savepath = os.path.join(save, \"prune.txt\")\n",
    "    with open(savepath, \"w\") as fp:\n",
    "        fp.write(\"Configuration: \\n\"+str(cfg)+\"\\n\")\n",
    "        fp.write(\"Number of parameters: \\n\"+str(num_parameters)+\"\\n\")\n",
    "        fp.write(\"Test accuracy: \\n\"+str(acc))\n",
    "\n",
    "    old_modules = list(model.modules())\n",
    "    new_modules = list(newmodel.modules())\n",
    "    layer_id_in_cfg = 0\n",
    "    start_mask = torch.ones(3)\n",
    "    end_mask = cfg_mask[layer_id_in_cfg]\n",
    "    conv_count = 0\n",
    "    \n",
    "    for layer_id in range(len(old_modules)):\n",
    "        m0 = old_modules[layer_id]\n",
    "        m1 = new_modules[layer_id]\n",
    "        if isinstance(m0, nn.BatchNorm2d):\n",
    "            idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
    "            if idx1.size == 1:\n",
    "                idx1 = np.resize(idx1,(1,))\n",
    "\n",
    "            if isinstance(old_modules[layer_id + 1], channel_selection):\n",
    "                # If the next layer is the channel selection layer, then the current batchnorm 2d layer won't be pruned.\n",
    "                m1.weight.data = m0.weight.data.clone()\n",
    "                m1.bias.data = m0.bias.data.clone()\n",
    "                m1.running_mean = m0.running_mean.clone()\n",
    "                m1.running_var = m0.running_var.clone()\n",
    "\n",
    "                # We need to set the channel selection layer.\n",
    "                m2 = new_modules[layer_id + 1]\n",
    "                m2.indexes.data.zero_()\n",
    "                m2.indexes.data[idx1.tolist()] = 1.0\n",
    "\n",
    "                layer_id_in_cfg += 1\n",
    "                start_mask = end_mask.clone()\n",
    "                if layer_id_in_cfg < len(cfg_mask):\n",
    "                    end_mask = cfg_mask[layer_id_in_cfg]\n",
    "            else:\n",
    "                m1.weight.data = m0.weight.data[idx1.tolist()].clone()\n",
    "                m1.bias.data = m0.bias.data[idx1.tolist()].clone()\n",
    "                m1.running_mean = m0.running_mean[idx1.tolist()].clone()\n",
    "                m1.running_var = m0.running_var[idx1.tolist()].clone()\n",
    "                layer_id_in_cfg += 1\n",
    "                start_mask = end_mask.clone()\n",
    "                if layer_id_in_cfg < len(cfg_mask):  # do not change in Final FC\n",
    "                    end_mask = cfg_mask[layer_id_in_cfg]\n",
    "        elif isinstance(m0, nn.Conv2d):\n",
    "            if conv_count == 0:\n",
    "                m1.weight.data = m0.weight.data.clone()\n",
    "                conv_count += 1\n",
    "                continue\n",
    "            if isinstance(old_modules[layer_id-1], channel_selection) or isinstance(old_modules[layer_id-1], nn.BatchNorm2d):\n",
    "                # This convers the convolutions in the residual block.\n",
    "                # The convolutions are either after the channel selection layer or after the batch normalization layer.\n",
    "                conv_count += 1\n",
    "                idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
    "                idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
    "                print('In shape: {:d}, Out shape {:d}.'.format(idx0.size, idx1.size))\n",
    "                if idx0.size == 1:\n",
    "                    idx0 = np.resize(idx0, (1,))\n",
    "                if idx1.size == 1:\n",
    "                    idx1 = np.resize(idx1, (1,))\n",
    "                w1 = m0.weight.data[:, idx0.tolist(), :, :].clone()\n",
    "\n",
    "                # If the current convolution is not the last convolution in the residual block, then we can change the \n",
    "                # number of output channels. Currently we use `conv_count` to detect whether it is such convolution.\n",
    "                if conv_count % 3 != 1:\n",
    "                    w1 = w1[idx1.tolist(), :, :, :].clone()\n",
    "                m1.weight.data = w1.clone()\n",
    "                continue\n",
    "\n",
    "            # We need to consider the case where there are downsampling convolutions. \n",
    "            # For these convolutions, we just copy the weights.\n",
    "            m1.weight.data = m0.weight.data.clone()\n",
    "        elif isinstance(m0, nn.Linear):\n",
    "            idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
    "            if idx0.size == 1:\n",
    "                idx0 = np.resize(idx0, (1,))\n",
    "\n",
    "            m1.weight.data = m0.weight.data[:, idx0].clone()\n",
    "            m1.bias.data = m0.bias.data.clone()\n",
    "\n",
    "    torch.save({'cfg': cfg, 'state_dict': newmodel.state_dict()}, os.path.join(save, 'pruned.pth.tar'))\n",
    "    \n",
    "    num_parameters = sum([param.nelement() for param in newmodel.parameters()])\n",
    "    percent_num_param_list.append(num_parameters)\n",
    "    \n",
    "    file_size = os.path.getsize('pruned.pth.tar')\n",
    "    percent_model_size_list.append(file_size)\n",
    "    \n",
    "    print(newmodel)\n",
    "    model = newmodel\n",
    "    test(model)\n",
    "    \n",
    "    \n",
    "    refine = '/kaggle/working/pruned.pth.tar'\n",
    "    epochs = 20\n",
    "    depth = 164\n",
    "\n",
    "    s = 0.0001\n",
    "    sr = ''\n",
    "    log_interval = 100\n",
    "\n",
    "    # additional subgradient descent on the sparsity-induced penalty term\n",
    "    def updateBN():\n",
    "        for m in model.modules():\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.grad.data.add_(s*torch.sign(m.weight.data))  # L1\n",
    "\n",
    "    def train(epoch):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            if cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            with torch.no_grad():\n",
    "                data, target = Variable(data), Variable(target)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.cross_entropy(output, target)\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            loss.backward()\n",
    "            if sr:\n",
    "                updateBN()\n",
    "            optimizer.step()\n",
    "            if batch_idx % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.1f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "    def test():\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        for data, target in test_loader:\n",
    "            if cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            with torch.no_grad():\n",
    "                data, target = Variable(data), Variable(target)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n'.format(\n",
    "            test_loss, correct, len(test_loader.dataset),\n",
    "            100. * correct / len(test_loader.dataset)))\n",
    "        return correct / float(len(test_loader.dataset))\n",
    "\n",
    "    def save_checkpoint(state, is_best, filepath):\n",
    "        torch.save(state, os.path.join(filepath, 'checkpoint_refined.pth.tar'))\n",
    "        if is_best:\n",
    "            shutil.copyfile(os.path.join(filepath, 'checkpoint_refined.pth.tar'), os.path.join(filepath, 'model_best_refined.pth.tar'))\n",
    "\n",
    "\n",
    "    if refine:\n",
    "        checkpoint = torch.load(refine)\n",
    "        model = resnet(dataset=dataset, depth=depth, cfg=checkpoint['cfg'])\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "    else:\n",
    "        model = resnet(dataset=dataset, depth=depth)\n",
    "\n",
    "    if cuda:\n",
    "        model.cuda()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "    resume = ''\n",
    "    start_epoch = 0\n",
    "\n",
    "    if resume:\n",
    "        if os.path.isfile(resume):\n",
    "            print(\"=> loading checkpoint '{}'\".format(resume))\n",
    "            checkpoint = torch.load(resume)\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {}) Prec1: {:f}\"\n",
    "                  .format(resume, checkpoint['epoch'], best_prec1))\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(resume))\n",
    "\n",
    "    epochs = 20\n",
    "    save = ''\n",
    "\n",
    "    elapsed_time = 0.\n",
    "    best_prec1 = 0.\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        start_time = time.time()\n",
    "        if epoch in [epochs*0.5, epochs*0.75]:\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] *= 0.1\n",
    "        train(epoch)\n",
    "        prec1 = test()\n",
    "        end_time = time.time()\n",
    "        is_best = prec1 > best_prec1\n",
    "        best_prec1 = max(prec1, best_prec1)\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_prec1': best_prec1,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, is_best, filepath=save)\n",
    "        elapsed_time += end_time - start_time\n",
    "    elapsed_time /= epochs\n",
    "    print(\"Best accuracy: \"+str(best_prec1))\n",
    "    print(\"Number of parameters: \"+str(num_parameters))\n",
    "    percent_elapsed_time_list.append(elapsed_time)\n",
    "    print(\"Average Time taken: \"+str(elapsed_time))\n",
    "    percent_accuracy_list.append(best_prec1)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "plt.plot(percent_arr, percent_accuracy_list)\n",
    "plt.xlabel('pruning percentage')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Accuracy Graph')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(percent_arr, percent_num_param_list)\n",
    "plt.xlabel('pruning percentage')\n",
    "plt.ylabel('number of parameters')\n",
    "plt.title('Parameter Count Graph')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(percent_arr, percent_elapsed_time_list)\n",
    "plt.xlabel('pruning percentage')\n",
    "plt.ylabel('time taken')\n",
    "plt.title('Speed up Graph')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(percent_arr, percent_model_size_list)\n",
    "plt.xlabel('pruning percentage')\n",
    "plt.ylabel('model size')\n",
    "plt.title('Model size Graph')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235eed7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T09:28:08.442598Z",
     "iopub.status.busy": "2024-03-31T09:28:08.442192Z",
     "iopub.status.idle": "2024-03-31T09:28:08.754654Z",
     "shell.execute_reply": "2024-03-31T09:28:08.753410Z",
     "shell.execute_reply.started": "2024-03-31T09:28:08.442567Z"
    },
    "papermill": {
     "duration": 0.182553,
     "end_time": "2024-03-31T22:49:30.441703",
     "exception": false,
     "start_time": "2024-03-31T22:49:30.259150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c7ec11",
   "metadata": {
    "papermill": {
     "duration": 0.192231,
     "end_time": "2024-03-31T22:49:30.822955",
     "exception": false,
     "start_time": "2024-03-31T22:49:30.630724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 29284.06279,
   "end_time": "2024-03-31T22:49:33.969725",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-31T14:41:29.906935",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
